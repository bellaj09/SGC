For autonomous driving it is important to detect obstacles in all scales accurately for safety consideration. In this paper we propose a new spatial attention fusion SAF method for obstacle detection using mmWave radar and vision sensor where the sparsity of radar points are considered in the proposed SAF. The proposed fusion method can be embedded in the feature-extraction stage which leverages the features of mmWave radar and vision sensor effectively. Based on the SAF an attention weight matrix is generated to fuse the vision features which is different from the concatenation fusion and element-wise add fusion. Moreover the proposed SAF can be trained by an end-to-end manner incorporated with the recent deep learning object detection framework. In addition we build a generation model which converts radar points to radar images for neural network training. Numerical results suggest that the newly developed fusion method achieves superior performance in public benchmarking. In addition the source code will be released in the GitHub. Spatial Attention Fusion for Obstacle Detection Using MmWave Radar and Vision Sensor.
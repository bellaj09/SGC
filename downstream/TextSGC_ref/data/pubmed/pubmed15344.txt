A new approach for efficiently exploring the configuration space and computing the free energy of large atomic and molecular systems is proposed motivated by an analogy with reinforcement learning. There are two major components in this new approach. Like metadynamics it allows for an efficient exploration of the configuration space by adding an adaptively computed biasing potential to the original dynamics. Like deep reinforcement learning this biasing potential is trained on the fly using deep neural networks with data collected judiciously from the exploration and an uncertainty indicator from the neural network model playing the role of the reward function. Parameterization using neural networks makes it feasible to handle cases with a large set of collective variables. This has the potential advantage that selecting precisely the right set of collective variables has now become less critical for capturing the structural transformations of the system. The method is illustrated by studying the full-atom explicit solvent models of alanine dipeptide and tripeptide as well as the system of a polyalanine-10 molecule with 20 collective variables. Reinforced dynamics for enhanced sampling in large atomic and molecular systems.
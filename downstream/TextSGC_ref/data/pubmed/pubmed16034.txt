Fabric defect detection is a necessary and essential step of quality control in the textile manufacturing industry. Traditional fabric inspections are usually performed by manual visual methods which are low in efficiency and poor in precision for long-term industrial applications. In this paper we propose an unsupervised learning-based automated approach to detect and localize fabric defects without any manual intervention. This approach is used to reconstruct image patches with a convolutional denoising autoencoder network at multiple Gaussian pyramid levels and to synthesize detection results from the corresponding resolution channels. The reconstruction residual of each image patch is used as the indicator for direct pixel-wise prediction. By segmenting and synthesizing the reconstruction residual map at each resolution level the final inspection result can be generated. This newly developed method has several prominent advantages for fabric defect detection. First it can be trained with only a small amount of defect-free samples. This is especially important for situations in which collecting large amounts of defective samples is difficult and impracticable. Second owing to the multi-modal integration strategy it is relatively more robust and accurate compared to general inspection methods the results at each resolution level can be viewed as a modality. Third according to our results it can address multiple types of textile fabrics from simple to more complex. Experimental results demonstrate that the proposed model is robust and yields good overall performance with high precision and acceptable recall rates. Automatic Fabric Defect Detection with a Multi-Scale Convolutional Denoising Autoencoder Network Model.
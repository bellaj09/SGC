Recently an upsurge of deep learning has provided a new direction for the field of computer vision and visual tracking. However expensive offline training time and the large number of images required by deep learning have greatly hindered progress. This paper aims to further improve the computational performance of CNT which is reported to deliver 5 fps performance in visual tracking we propose a method called Fast-CNT which differs from CNT in three aspects: firstly an adaptive k value rather than a constant 100 is determined for an input video; secondly background filters used in CNT are omitted in this work to save computation time without affecting performance; thirdly SURF feature points are used in conjunction with the particle filter to address the drift problem in CNT. Extensive experimental results on land and undersea video sequences show that Fast-CNT outperforms CNT by 2~10 times in terms of computational efficiency. Fast Visual Tracking Based on Convolutional Networks.
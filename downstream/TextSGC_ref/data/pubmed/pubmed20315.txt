The paper reviews nine robotic and virtual reality VR brain-computer interface BCI projects developed by the author in collaboration with his graduate students within the BCI-lab research group during its association with University of Tsukuba Japan. The nine novel approaches are discussed in applications to direct brain-robot and brain-virtual-reality-agent control interfaces using tactile and auditory BCI technologies. The BCI user intentions are decoded from the brainwaves in realtime using a non-invasive electroencephalography EEG and they are translated to a symbiotic robot or virtual reality agent thought-based only control. A communication protocol between the BCI output and the robot or the virtual environment is realized in a symbiotic communication scenario using an user datagram protocol UDP which constitutes an internet of things IoT control scenario. Results obtained from healthy users reproducing simple brain-robot and brain-virtual-agent control tasks in online experiments support the research goal of a possibility to interact with robotic devices and virtual reality agents using symbiotic thought-based BCI technologies. An offline BCI classification accuracy boosting method using a previously proposed information geometry derived approach is also discussed in order to further support the reviewed robotic and virtual reality thought-based control paradigms. Robotic and Virtual Reality BCIs Using Spatial Tactile and Auditory Oddball Paradigms.
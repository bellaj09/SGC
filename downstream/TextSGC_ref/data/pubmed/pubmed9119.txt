The phase extraction neural network PhENN Optica 4 1117 2017 is a computational architecture based on deep machine learning for lens-less quantitative phase retrieval from raw intensity data. PhENN is a deep convolutional neural network trained through examples consisting of pairs of true phase objects and their corresponding intensity diffraction patterns; thereafter given a test raw intensity pattern PhENN is capable of reconstructing the original phase object robustly in many cases even for objects outside the database where the training examples were drawn from. Here we show that the spatial frequency content of the training examples is an important factor limiting PhENN\s spatial frequency response. For example if the training database is relatively sparse in high spatial frequencies as most natural scenes are PhENN\s ability to resolve fine spatial features in test patterns will be correspondingly limited. To combat this issue we propose "flattening" the power spectral density of the training examples before presenting them to PhENN. For phase objects following the statistics of natural scenes we demonstrate experimentally that the spectral pre-modulation method enhances the spatial resolution of PhENN by a factor of 2. Spectral pre-modulation of training examples enhances the spatial resolution of the phase extraction neural network PhENN.
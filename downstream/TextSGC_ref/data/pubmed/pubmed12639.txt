The most significant barrier to success in human activity recognition is extracting and selecting the right features. In traditional methods the features are chosen by humans which requires the user to have expert knowledge or to do a large amount of empirical study. Newly developed deep learning technology can automatically extract and select features. Among the various deep learning methods convolutional neural networks CNNs have the advantages of local dependency and scale invariance and are suitable for temporal data such as accelerometer ACC signals. In this paper we propose an efficient human activity recognition method namely Iss2Image Inertial sensor signal to Image a novel encoding technique for transforming an inertial sensor signal into an image with minimum distortion and a CNN model for image-based activity classification. Iss2Image converts real number values from the X Y and Z axes into three color channels to precisely infer correlations among successive sensor signal values in three different dimensions. We experimentally evaluated our method using several well-known datasets and our own dataset collected from a smartphone and smartwatch. The proposed method shows higher accuracy than other state-of-the-art approaches on the tested datasets. Iss2Image: A Novel Signal-Encoding Technique for CNN-Based Human Activity Recognition.
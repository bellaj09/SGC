Semantic segmentation a pixel-level vision task is rapidly developed by using convolutional neural networks CNNs. Training CNNs requires a large amount of labeled data but manually annotating data is difficult. For emancipating manpower in recent years some synthetic datasets are released. However they are still different from real scenes which causes that training a model on the synthetic data source domain cannot achieve a good performance on real urban scenes target domain. In this paper we propose a weakly supervised adversarial domain adaptation to improve the segmentation performance from synthetic data to real scenes which consists of three deep neural networks. A detection and segmentation DS model focuses on detecting objects and predicting segmentation map; a pixel-level domain classifier PDC tries to distinguish the image features from which domains; and an object-level domain classifier ODC discriminates the objects from which domains and predicts object classes. PDC and ODC are treated as the discriminators and DS is considered as the generator. By the adversarial learning DS is supposed to learn domain-invariant features. In experiments our proposed method yields the new record of mIoU metric in the same problem. Weakly Supervised Adversarial Domain Adaptation for Semantic Segmentation in Urban Scenes.
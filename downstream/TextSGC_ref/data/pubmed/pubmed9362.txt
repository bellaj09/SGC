Quantitative features are generated from a tumor phenotype by various data characterization feature-extraction approaches and have been used successfully as a biomarker. These features give us information about a nodule for example nodule size pixel intensity histogram-based information and texture information from wavelets or a convolution kernel. Semantic features on the other hand can be generated by an experienced radiologist and consist of the common characteristics of a tumor for example location of a tumor fissure or pleural wall attachment presence of fibrosis or emphysema concave cut on nodule surface. These features have been derived for lung nodules by our group. Semantic features have also shown promise in predicting malignancy. Deep features from images are generally extracted from the last layers before the classification layer of a convolutional neural network CNN. By training with the use of different types of images the CNN learns to recognize various patterns and textures. But when we extract deep features there is no specific naming approach for them other than denoting them by the feature column number position of a neuron in a hidden layer. In this study we tried to relate and explain deep features with respect to traditional quantitative features and semantic features. We discovered that 26 deep features from the Vgg-S neural network and 12 deep features from our trained CNN could be explained by semantic or traditional quantitative features. From this we concluded that those deep features can have a recognizable definition via semantic or quantitative features. Explaining Deep Features Using Radiologist-Defined Semantic Features and Traditional Quantitative Features.
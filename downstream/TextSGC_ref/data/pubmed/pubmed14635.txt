Fusing multichannel neurophysiological signals to recognize human emotion states becomes increasingly attractive. The conventional methods ignore the complementarity between time domain characteristics frequency domain characteristics and time-frequency characteristics of electroencephalogram EEG signals and cannot fully capture the correlation information between different channels. In this paper an integrated deep learning framework based on improved deep belief networks with glia chains DBN-GCs is proposed. In the framework the member DBN-GCs are employed for extracting intermediate representations of EEG raw features from multiple domains separately as well as mining interchannel correlation information by glia chains. Then the higher level features describing time domain characteristics frequency domain characteristics and time-frequency characteristics are fused by a discriminative restricted Boltzmann machine RBM to implement emotion recognition task. Experiments conducted on the DEAP benchmarking dataset achieve averaged accuracy of 75.92% and 76.83% for arousal and valence states classification respectively. The results show that the proposed framework outperforms most of the above deep classifiers. Thus potential of the proposed framework is demonstrated. Recognition of Emotions Using Multichannel EEG Data and DBN-GC-Based Ensemble Deep Learning Framework.
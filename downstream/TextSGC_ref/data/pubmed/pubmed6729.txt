"Deep Neural Networks DNNs have been extensively used in multiple disciplines due to their superior performance. However in most cases DNNs are considered as black-boxes and the interpretation of their internal working mechanism is usually challenging. Given that model trust is often built on the understanding of how a model works the interpretation of DNNs becomes more important especially in safety-critical applications e.g. medical diagnosis autonomous driving. In this paper we propose DeepVID a Deep learning approach to Visually Interpret and Diagnose DNN models especially image classifiers. In detail we train a small locally-faithful model to mimic the behavior of an original cumbersome DNN around a particular data instance of interest and the local model is sufficiently simple such that it can be visually interpreted e.g. a linear model. Knowledge distillation is used to transfer the knowledge from the cumbersome DNN to the small model and a deep generative model i.e. variational auto-encoder is used to generate neighbors around the instance of interest. Those neighbors which come with small feature variances and semantic meanings can effectively probe the DNNs behaviors around the interested instance and help the small model to learn those behaviors. Through comprehensive evaluations as well as case studies conducted together with deep learning experts we validate the effectiveness of DeepVID." DeepVID: Deep Visual Interpretation and Diagnosis for Image Classifiers via Knowledge Distillation.
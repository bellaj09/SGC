Recent advancements in mobile devices data analysis and wearable sensors render the capability of in-place health monitoring. Supervised machine learning algorithms the core intelligence of these systems learn from labeled training data. However labeling vast amount of data is time-consuming and expensive. Moreover sensor data often contains personal information that a user may not be comfortable sharing. Therefore there is a strong need to develop methods for generating realistic labeled sensor data. In this paper we propose a supervised generative adversarial network architecture that learns from feedback from both a discriminator and a classifier in order to create synthetic sensor data. We demonstrate the effectiveness of the architecture on a publicly available human activity dataset. We show that our generator learns to output diverse samples that are similar but not identical to the training data. Synthetic Sensor Data Generation for Health Applications: A Supervised Deep Learning Approach.
"The main goal of this study is to build an artificial intelligence AI architecture for automated extraction of dual-modal image features from both shear-wave elastography SWE and B-mode ultrasound and to evaluate the AI architecture for classification between benign and malignant breast tumors. In this AI architecture ultrasound images were segmented by the reaction diffusion level set model combined with the Gabor-based anisotropic diffusion algorithm. Then morphological features and texture features were extracted from SWE and B-mode ultrasound images at the contourlet domain. Finally we employed a framework for feature learning and classification with the deep polynomial network DPN on dual-modal features to distinguish between malignant and benign breast tumors. With the leave-one-out cross validation the DPN method on dual-modal features achieved a sensitivity of 97.8% a specificity of 94.1% an accuracy of 95.6% a Youdens index of 91.9% and an area under the receiver operating characteristic curve of 0.961 which was superior to the classic single-modal methods and the dual-modal methods using the principal component analysis and multiple kernel learning. These results have demonstrated that the dual-modal AI-based technique with DPN has the potential for breast tumor classification in future clinical practice." Dual-mode artificially-intelligent diagnosis of breast tumours in shear-wave elastography and B-mode ultrasound using deep polynomial networks.
One of the challenging problems in understanding high-resolution remote sensing images is aerial scene classification. A well-designed feature representation method and classifier can improve classification accuracy. In this paper we construct a new two-stream deep architecture for aerial scene classification. First we use two pretrained convolutional neural networks CNNs as feature extractor to learn deep features from the original aerial image and the processed aerial image through saliency detection respectively. Second two feature fusion strategies are adopted to fuse the two different types of deep convolutional features extracted by the original RGB stream and the saliency stream. Finally we use the extreme learning machine ELM classifier for final classification with the fused features. The effectiveness of the proposed architecture is tested on four challenging datasets: UC-Merced dataset with 21 scene categories WHU-RS dataset with 19 scene categories AID dataset with 30 scene categories and NWPU-RESISC45 dataset with 45 challenging scene categories. The experimental results demonstrate that our architecture gets a significant classification accuracy improvement over all state-of-the-art references. A Two-Stream Deep Fusion Framework for High-Resolution Aerial Scene Classification.
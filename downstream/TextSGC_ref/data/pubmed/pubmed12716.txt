Medical imaging examination on patients usually involves more than one imaging modalities such as Computed Tomography CT Magnetic Resonance MR and Positron Emission TomographyPET imaging. Multimodal imaging allows examiners to benefit from the advantage of each modalities. For example for Abdominal Aortic Aneurysm CT imaging shows calcium deposits in the aorta clearly while MR imaging distinguishes thrombus and soft tissues better.1 Analysing and segmenting both CT and MR images to combine the results will greatly help radiologists and doctors to treat the disease. In this work we present methods on using deep neural network models to perform such multi-modal medical image segmentation. As CT image and MR image of the abdominal area cannot be well registered due to non-affine deformations a naive approach is to train CT and MR segmentation network separately. However such approach is time-consuming and resource-inefficient. We propose a new approach to fuse the high-level part of the CT and MR network together hypothesizing that neurons recognizing the high level concepts of Aortic Aneurysm can be shared across multiple modalities. Such network is able to be trained end-to-end with non-registered CT and MR image using shorter training time. Moreover network fusion allows a shared representation of Aorta in both CT and MR images to be learnt. Through experiments we discovered that for parts of Aorta showing similar aneurysm conditions their neural presentations in neural network has shorter distances. Such distances on the feature level is helpful for registering CT and MR image. Neural network fusion: a novel CT-MR Aortic Aneurysm image segmentation method.
Using an ensemble of neural networks with consistency regularization is effective for improving performance and stability of deep learning compared to the case of a single network. In this paper we present a semi-supervised Deep Coupled Ensemble DCE model which contributes to ensemble learning and classification landmark exploration for better locating the final decision boundaries in the learnt latent space. First multiple complementary consistency regularizations are integrated into our DCE model to enable the ensemble members to learn from each other and themselves such that training experience from different sources can be shared and utilized during training. Second in view of the possibility of producing incorrect predictions on a number of difficult instances we adopt class-wise mean feature matching to explore important unlabeled instances as classification landmarks on which the model predictions are more reliable. Minimizing the weighted conditional entropy on unlabeled data is able to force the final decision boundaries to move away from important training data points which facilitates semi-supervised learning. Ensemble members could eventually have similar performance due to consistency regularization and thus only one of these members is needed during the test stage such that the efficiency of our model is the same as the non-ensemble case. Extensive experimental results demonstrate the superiority of our proposed DCE model over existing state-of-the-art semi-supervised learning methods. Semi-Supervised Deep Coupled Ensemble Learning with Classification Landmark Exploration.
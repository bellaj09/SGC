When navigating through the environment our brain needs to infer how far we move and in which direction we are heading. In this estimation process the brain may rely on multiple sensory modalities including the visual and vestibular systems. Previous research has mainly focused on heading estimation showing that sensory cues are combined by weighting them in proportion to their reliability consistent with statistically optimal integration. But while heading estimation could improve with the ongoing motion due to the constant flow of information the estimate of how far we move requires the integration of sensory information across the whole displacement. In this study we investigate whether the brain optimally combines visual and vestibular information during a displacement estimation task even if their reliability varies from trial to trial. Participants were seated on a linear sled immersed in a stereoscopic virtual reality environment. They were subjected to a passive linear motion involving visual and vestibular cues with different levels of visual coherence to change relative cue reliability and with cue discrepancies to test relative cue weighting. Participants performed a two-interval two-alternative forced-choice task indicating which of two sequentially perceived displacements was larger. Our results show that humans adapt their weighting of visual and vestibular information from trial to trial in proportion to their reliability. These results provide evidence that humans optimally integrate visual and vestibular information in order to estimate their body displacement. Reliability-Based Weighting of Visual and Vestibular Cues in Displacement Estimation.
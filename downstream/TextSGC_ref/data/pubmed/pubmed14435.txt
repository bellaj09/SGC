"A paradigm shift is required to prevent the increasing automobile accident deaths that are mostly due to the inattentive behavior of drivers. Knowledge of gaze region can provide valuable information regarding a drivers point of attention. Accurate and inexpensive gaze classification systems in cars can improve safe driving. However monitoring real-time driving behaviors and conditions presents some challenges: dizziness due to long drives extreme lighting variations glasses reflections and occlusions. Past studies on gaze detection in cars have been chiefly based on head movements. The margin of error in gaze detection increases when drivers gaze at objects by moving their eyes without moving their heads. To solve this problem a pupil center corneal reflection PCCR-based method has been considered. However the error of accurately detecting the pupil center and corneal reflection center is increased in a car environment due to various environment light changes reflections on glasses surface and motion and optical blurring of captured eye image. In addition existing PCCR-based methods require initial user calibration which is difficult to perform in a car environment. To address this issue we propose a deep learning-based gaze detection method using a near-infrared NIR camera sensor considering driver head and eye movement that does not require any initial user calibration. The proposed system is evaluated on our self-constructed database as well as on open Columbia gaze dataset CAVE-DB. The proposed method demonstrated greater accuracy than the previous gaze classification methods." Deep Learning-Based Gaze Detection System for Automobile Drivers Using a NIR Camera Sensor.
"Person re-identification re-ID is among the essential components that play an integral role in constituting an automated surveillance environment. Majorly the problem is tackled using data acquired from vision sensors using appearance-based features which are strongly dependent on visual cues such as color texture etc. consequently limiting the precise re-identification of an individual. To overcome such strong dependence on visual features many researchers have tackled the re-identification problem using human gait which is believed to be unique and provide a distinctive biometric signature that is particularly suitable for re-ID in uncontrolled environments. However image-based gait analysis often fails to extract quality measurements of an individuals motion patterns owing to problems related to variations in viewpoint illumination daylight clothing worn accessories etc. To this end in contrast to relying on image-based motion measurement this paper demonstrates the potential to re-identify an individual using inertial measurements units IMU based on two common sensors namely gyroscope and accelerometer. The experiment was carried out over data acquired using smartphones and wearable IMUs from a total of 86 randomly selected individuals including 49 males and 37 females between the ages of 17 and 72 years. The data signals were first segmented into single steps and strides which were separately fed to train a sequential deep recurrent neural network to capture implicit arbitrary long-term temporal dependencies. The experimental setup was devised in a fashion to train the network on all the subjects using data related to half of the step and stride sequences only while the inference was performed on the remaining half for the purpose of re-identification. The obtained experimental results demonstrate the potential to reliably and accurately re-identify an individual based on ones inertial sensor data." Person Re-Identification Using Deep Modeling of Temporally Correlated Inertial Motion Patterns.
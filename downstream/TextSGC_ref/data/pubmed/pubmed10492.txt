The click feature of an image defined as the user-click-frequency vector of the image on a pre-defined word vocabulary is known to effectively reduce the semantic gap for fine-grained image recognition. Unfortunately user-click-frequency data are usually absent in practice. It remains challenging to predict the click feature from the visual feature because the user-click-frequency vector of an image is always noisy and sparse. In this paper we devise a Hierarchical Deep Word Embedding HDWE model by integrating sparse constraints and an improved RELU operator to address click feature prediction from visual features. HDWE is a coarse-to-fine click feature predictor that is learned with the help of an auxiliary image dataset containing click information. It can therefore discover the hierarchy of word semantics. We evaluate HDWE on three dog and one bird image datasets in which Clickture-Dog and Clickture-Bird are respectively utilized as auxiliary datasets to provide click data. Our empirical studies show that HDWE has 1 higher recognition accuracy 2 a larger compression ratio and 3 good one-shot learning ability and scalability to unseen categories. Hierarchical Deep Click Feature Prediction for Fine-grained Image Recognition.
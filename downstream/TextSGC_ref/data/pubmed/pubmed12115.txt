Various deep learning models have been developed for different healthcare predictive tasks using Electronic Health Records and have shown promising performance. In these models medical codes are often aggregated into visit representation without considering their heterogeneity e.g. the same diagnosis might imply different healthcare concerns with different procedures or medications. Then the visits are often fed into deep learning models such as recurrent neural networks sequentially without considering the irregular temporal information and dependencies among visits. To address these limitations we developed a Multilevel Self-Attention Model MSAM that can capture the underlying relationships between medical codes and between medical visits. We compared MSAM with various baseline models on two predictive tasks i.e. future disease prediction and future medical cost prediction with two large datasets i.e. MIMIC-3 and PFK. In the experiments MSAM consistently outperformed baseline models. Additionally for future medical cost prediction we used disease prediction as an auxiliary task which not only guides the model to achieve a stronger and more stable financial prediction but also allows managed care organizations to provide a better care coordination. Multilevel Self-Attention Model and its Use on Medical Risk Prediction.
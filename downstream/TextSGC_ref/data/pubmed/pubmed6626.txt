Segmentation of prostate in medical imaging data e.g. CT MRI TRUS is often considered as a critical yet challenging task for radiotherapy treatment. It is relatively easier to segment prostate from MR images than from CT images due to better soft tissue contrast of the MR images. For segmenting prostate from CT images most previous methods mainly used CT alone and thus their performances are often limited by low tissue contrast in the CT images. In this paper we explore the possibility of using indirect guidance from MR images for improving prostate segmentation in the CT images. In particular we propose a novel deep transfer learning approach i.e. MR-guided CT network training namely MICS-NET which can employ MR images to help better learning of features in CT images for prostate segmentation. In MICS-NET the guidance from MRI consists of two steps: 1 learning informative and transferable features from MRI and then transferring them to CT images in a cascade manner and 2 adaptively transferring the prostate likelihood of MRI model i.e. well-trained convnet by purely using MR images with a view consistency constraint. To illustrate the effectiveness of our approach we evaluate MICS-NET on a real CT prostate image set with the manual delineations available as the ground truth for evaluation. Our methods generate promising segmentation results which achieve 1 six percentages higher Dice Ratio than the CT model purely using CT images and 2 comparable performance with the MRI model purely using MR images. An Effective MR-Guided CT Network Training for Segmenting Prostate in CT Images.
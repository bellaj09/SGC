Better features have been driving the progress of pedestrian detection over the past years. However as features become richer and higher dimensional noise and redundancy in the feature sets become bigger problems. These problems slow down learning and can even reduce the performance of the learned model. Current solutions typically exploit dimension reduction techniques. In this paper we propose a simple but effective feature selection framework for pedestrian detection. Moreover we introduce occluded pedestrian samples into the training process and combine it with a new feature selection criterion which enables improved performances for occlusion handling problems. Experimental results on the Caltech Pedestrian dataset demonstrate the efficiency of our method over the state-of-art methods especially for the occluded pedestrians. An Occlusion-Robust Feature Selection Framework in Pedestrian Detection .
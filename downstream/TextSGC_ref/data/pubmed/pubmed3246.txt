Auditory speech comprehension is the result of neural computations that occur in a broad network that includes the temporal lobe auditory cortex and the left inferior frontal cortex. It remains unclear how representations in this network differentially contribute to speech comprehension. Here we recorded high-density direct cortical activity during a sine-wave speech SWS listening task to examine detailed neural speech representations when the exact same acoustic input is comprehended versus not comprehended. Listeners heard SWS sentences pre-exposure followed by clear versions of the same sentences which revealed the content of the sounds exposure and then the same SWS sentences again post-exposure. Across all three task phases high-gamma neural activity in the superior temporal gyrus was similar distinguishing different words based on bottom-up acoustic features. In contrast frontal regions showed a more pronounced and sudden increase in activity only when the input was comprehended which corresponded with stronger representational separability among spatiotemporal activity patterns evoked by different words. We observed this effect only in participants who were not able to comprehend the stimuli during the pre-exposure phase indicating a relationship between frontal high-gamma activity and speech understanding. Together these results demonstrate that both frontal and temporal cortical networks are involved in spoken language understanding and that under certain listening conditions frontal regions are involved in discriminating speech sounds. Neural correlates of sine-wave speech intelligibility in human frontal and temporal cortex.
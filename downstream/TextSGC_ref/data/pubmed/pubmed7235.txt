Internet-of-things applications that use machine-learning algorithms have increased the demand for application-specific energy-efficient hardware that can perform both learning and inference tasks to adapt to endpoint users or environmental changes. This paper presents a multilayer-learning neuromorphic system with analog-based multiplier-accumulator MAC which can learn training data by stochastic gradient descent algorithm. As a component of the proposed system a current-mode MAC processor fabricated in 28-nm CMOS technology performs both forward and backward processing in a crossbar structure of 500\xa0\xa0500 6-b transposable SRAM arrays. The proposed system is verified in a two-layer neural network by using two prototype chips and an FPGA. Without any calibration circuit for the analog-based MAC the proposed system compensates for non-idealities from analog operations by learning training data with the analog-based MAC. With 1-b +1 0 -1 batch update of 6-b synaptic weights the proposed system achieves a recognition rate of 96.6% with a peak energy efficiency of 2.99 TOPS/W 1 OP = one unsigned 8-b\xa0\xa0signed 6-b MAC operation in the classification of the MNIST dataset. A Multilayer-Learning Current-Mode Neuromorphic System With Analog-Error Compensation.
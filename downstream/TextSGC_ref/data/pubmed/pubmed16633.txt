"Visual search behaviour and the interpretation of mammograms have been studied for errors in breast cancer detection. We aim to ascertain whether machine-learning models can learn about radiologists attentional level and the interpretation of mammograms. We seek to determine whether these models are practical and feasible for use in training and teaching programmes. Eight radiologists of varying experience levels in reading mammograms reviewed 120 two-view digital mammography cases 59 cancers. Their search behaviour and decisions were captured using a head-mounted eye-tracking device and software allowing them to record their decisions. This information from radiologists was used to build an ensembled machine-learning model using top-down hierarchical deep convolution neural network. Separately a model to determine type of missed cancer search perception or decision-making was also built. Analysis and comparison of variants of these models using different convolution networks with and without transfer learning were also performed. Our ensembled deep-learning network architecture can be trained to learn about radiologists attentional level and decisions. High accuracy 95% p value\u2009\u20090 better than dumb/random model and high agreement between true and predicted values kappa\u2009=\u20090.83 in such modelling can be achieved. Transfer learning techniques improve by <\u200910% with the performance of this model. We also show that spatial convolution neural networks are insufficient in determining the type of missed cancers. Ensembled hierarchical deep convolution machine-learning models are plausible in modelling radiologists attentional level and their interpretation of mammograms. However deep convolution networks fail to characterise the type of false-negative decisions." "Can a Machine Learn from Radiologists Visual Search Behaviour and Their Interpretation of Mammograms-a Deep-Learning Study."
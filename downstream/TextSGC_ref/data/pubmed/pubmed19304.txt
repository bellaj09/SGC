Video see-through Augmented Reality adds computer graphics to the real world in real time by overlaying graphics onto a live video feed. To achieve a realistic integration of the virtual and real imagery the rendered images should have a similar appearance and quality to those produced by the video camera. This paper describes a compositing method which models the artifacts produced by a small low-cost camera and adds these effects to an ideal pinhole image produced by conventional rendering methods. We attempt to model and simulate each step of the imaging process including distortions chromatic aberrations blur Bayer masking noise sharpening and color-space compression all while requiring only an RGBA image and an estimate of camera velocity as inputs. Simulating low-cost cameras for augmented reality compositing.
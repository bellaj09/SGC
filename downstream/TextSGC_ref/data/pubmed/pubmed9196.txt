We implemented a mobile phone application of the pentagon drawing test PDT called mPDT with a novel automatic and qualitative scoring method for the application based on U-Net a convolutional network for biomedical image segmentation coupled with mobile sensor data obtained with the mPDT. For the scoring protocol the U-Net was trained with 199 PDT hand-drawn images of 512512 resolution obtained via the mPDT in order to generate a trained model Deep5 for segmenting a drawn right or left pentagon. The U-Net was also trained with 199 images of 512512 resolution to attain the trained model DeepLock for segmenting an interlocking figure. Here the epochs were iterated until the accuracy was greater than 98% and saturated. The mobile senor data primarily consisted of x and y coordinates timestamps and touch-events of all the samples with a 20 ms sampling period. The velocities were then calculated using the primary sensor data. With Deep5 DeepLock and the sensor data four parameters were extracted. These included the number of angles 0-4 points distance/intersection between the two drawn figures 0-4 points closure/opening of the drawn figure contours 0-2 points and tremors detected 0-1 points. The parameters gave a scaling of 11 points in total. The performance evaluation for the mPDT included 230 images from subjects and their associated sensor data. The results of the performance test indicated respectively a sensitivity specificity accuracy and precision of 97.53% 92.62% 94.35% and 87.78% for the number of angles parameter; 93.10% 97.90% 96.09% and 96.43% for the distance/intersection parameter; 94.03% 90.63% 92.61% and 93.33% for the closure/opening parameter; and 100.00% 100.00% 100.00% and 100.00% for the detected tremor parameter. These results suggest that the mPDT is very robust in differentiating dementia disease subtypes and is able to contribute to clinical practice and field studies. Automatic Qualitative Scoring of the Interlocking Pentagon Drawing Test PDT based on U-Net and Mobile Sensor Data.
Traditional brain machine interfaces for control of a prosthesis have typically focused on the kinematics of movement rather than the dynamics. BMI decoders that extract the forces and/or torques to be applied by a prosthesis have the potential for giving the patient a much richer level of control across different dynamic scenarios or even scenarios in which the dynamics of the limb/environment are changing. However it is a challenge to train a decoder that is able to capture this richness given the small amount of calibration data that is usually feasible to collect a priori. In this work we propose that kinetic decoders should be continuously calibrated based on how they are used by the subject. Both intended hand position and joint torques are decoded simultaneously as a monkey performs a random target pursuit task. The deviation between intended and actual hand position is used as an estimate of error in the recently decoded joint torques. In turn these errors are used to drive a gradient descent algorithm for improving the torque decoder parameters. We show that this approach is able to quickly restore the functionality of a torque decoder following substantial corruption with Gaussian noise. Online adaptive decoding of intended movements with a hybrid kinetic and kinematic brain machine interface.
Current deep supervised learning methods typically require large amounts of labeled data for training. Since there is a significant cost associated with clinical data acquisition and labeling medical datasets used for training these models are relatively small in size. In this paper we aim to alleviate this limitation by proposing a variational generative model along with an effective data augmentation approach that utilizes the generative model to synthesize data. In our approach the model learns the probability distribution of image data conditioned on a latent variable and the corresponding labels. The trained model can then be used to synthesize new images for data augmentation. We demonstrate the effectiveness of the approach on two independent clinical datasets consisting of ultrasound images of the spine and magnetic resonance images of the brain. For the spine dataset a baseline and a residual model achieve an accuracy of 85% and 92% respectively using our method compared to 78% and 83% using a conventional training approach for image classification task. For the brain dataset a baseline and a U-net network achieve an accuracy of 84% and 88% respectively in Dice coefficient in tumor segmentation compared to 80% and 83% for the convention training approach. Adaptive Augmentation of Medical Data Using Independently Conditional Variational Auto-Encoders.
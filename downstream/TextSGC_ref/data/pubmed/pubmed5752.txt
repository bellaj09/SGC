The need for robust unsupervised anomaly detection in streaming data is increasing rapidly in the current era of smart devices where enormous data are gathered from numerous sensors. These sensors record the internal state of a machine the external environment and the interaction of machines with other machines and humans. It is of prime importance to leverage this information in order to minimize downtime of machines or even avoid downtime completely by constant monitoring. Since each device generates a different type of streaming data it is normally the case that a specific kind of anomaly detection technique performs better than the others depending on the data type. For some types of data and use-cases statistical anomaly detection techniques work better whereas for others deep learning-based techniques are preferred. In this paper we present a novel anomaly detection technique FuseAD which takes advantage of both statistical and deep-learning-based approaches by fusing them together in a residual fashion. The obtained results show an increase in area under the curve AUC as compared to state-of-the-art anomaly detection methods when FuseAD is tested on a publicly available dataset Yahoo Webscope benchmark. The obtained results advocate that this fusion-based technique can obtain the best of both worlds by combining their strengths and complementing their weaknesses. We also perform an ablation study to quantify the contribution of the individual components in FuseAD i.e. the statistical ARIMA model as well as the deep-learning-based convolutional neural network CNN model. FuseAD: Unsupervised Anomaly Detection in Streaming Sensors Data by Fusing Statistical and Deep Learning Models.
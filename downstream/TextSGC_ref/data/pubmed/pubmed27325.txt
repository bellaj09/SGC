"Speech production is a hierarchical mechanism involving the synchronization of the brain and the oral articulators where the intention of linguistic concepts is transformed into meaningful sounds. Individuals with locked-in syndrome fully paralyzed but aware lose their motor ability completely including articulation and even eyeball movement. The neural pathway may be the only option to resume a certain level of communication for these patients. Current brain-computer interfaces BCIs use patients visual and attentional correlates to build communication resulting in a slow communication rate a few words per minute. Direct decoding of imagined speech from the neural signals and then driving a speech synthesizer has the potential for a higher communication rate. In this study we investigated the decoding of five imagined and spoken phrases from single-trial non-invasive magnetoencephalography MEG signals collected from eight adult subjects. Two machine learning algorithms were used. One was an artificial neural network ANN with statistical features as the baseline approach. The other was convolutional neural networks CNNs applied on the spatial spectral and temporal features extracted from the MEG signals. Experimental results indicated the possibility to decode imagined and spoken phrases directly from neuromagnetic signals. CNNs were found to be highly effective with an average decoding accuracy of up to 93% for the imagined and 96% for the spoken phrases." Decoding Imagined and Spoken Phrases From Non-invasive Neural MEG Signals.
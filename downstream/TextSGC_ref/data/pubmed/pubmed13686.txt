Cryosection brain images in Chinese Visible Human CVH dataset contain rich anatomical structure information of tissues because of its high resolution e.g. 0.167 mm per pixel. Fast and accurate segmentation of these images into white matter gray matter and cerebrospinal fluid plays a critical role in analyzing and measuring the anatomical structures of human brain. However most existing automated segmentation methods are designed for computed tomography or magnetic resonance imaging data and they may not be applicable for cryosection images due to the imaging difference. In this paper we propose a supervised learning-based CVH brain tissues segmentation method that uses stacked autoencoder SAE to automatically learn the deep feature representations. Specifically our model includes two successive parts where two three-layer SAEs take image patches as input to learn the complex anatomical feature representation and then these features are sent to Softmax classifier for inferring the labels. Experimental results validated the effectiveness of our method and showed that it outperformed four other classical brain tissue detection strategies. Furthermore we reconstructed three-dimensional surfaces of these tissues which show their potential in exploring the high-resolution anatomical structures of human brain. Segmenting Brain Tissues from Chinese Visible Human Dataset by Deep-Learned Features with Stacked Autoencoder.
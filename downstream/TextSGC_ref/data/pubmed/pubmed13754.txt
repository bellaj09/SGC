Person re-identification re-ID is a cross-camera retrieval task that suffers from image style variations caused by different cameras. The art implicitly addresses this problem by learning a camera-invariant descriptor subspace. In this paper we explicitly consider this challenge by introducing camera style CamStyle. CamStyle can serve as a data augmentation approach that reduces the risk of deep network overfitting and that smooths the CamStyle disparities. Specifically with a style transfer model labeled training images can be style transferred to each camera and along with the original training samples form the augmented training set. This method while increasing data diversity against overfitting also incurs a considerable level of noise. In the effort to alleviate the impact of noise the label smooth regularization LSR is adopted. The vanilla version of our method without LSR performs reasonably well on few camera systems in which overfitting often occurs. With LSR we demonstrate consistent improvement in all systems regardless of the extent of overfitting. We also report competitive accuracy compared with the state of the art on Market-1501 and DukeMTMC-re-ID. Importantly CamStyle can be employed to the challenging problems of one view learning and unsupervised domain adaptation UDA in person re-identification re-ID both of which have critical research and application significance. The former only has labeled data in one camera view and the latter only has labeled data in the source domain. Experimental results show that CamStyle significantly improves the performance of the baseline in the two problems. Specially for UDA CamStyle achieves state-of-the-art accuracy based on a baseline deep re-ID model on Market-1501 and DukeMTMC-reID. Our code is available at: https://github.com/zhunzhong07/CamStyle . CamStyle: A Novel Data Augmentation Method for Person Re-Identification.
Computed Tomography Perfusion CTP imaging is a cost-effective and fast approach to provide diagnostic images for acute stroke treatment. Its cine scanning mode allows the visualization of anatomic brain structures and blood flow; however it requires contrast agent injection and continuous CT scanning over an extended time. In fact the accumulative radiation dose to patients will increase health risks such as skin irritation hair loss cataract formation and even cancer. Solutions for reducing radiation exposure include reducing the tube current and/or shortening the X-ray radiation exposure time. However images scanned at lower tube currents are usually accompanied by higher levels of noise and artifacts. On the other hand shorter X-ray radiation exposure time with longer scanning intervals will lead to image information that is insufficient to capture the blood flow dynamics between frames. Thus it is critical for us to seek a solution that can preserve the image quality when the tube current and the temporal frequency are both low. We propose STIR-Net in this paper an end-to-end spatial-temporal convolutional neural network structure which exploits multi-directional automatic feature extraction and image reconstruction schema to recover high-quality CT slices effectively. With the inputs of low-dose and low-resolution patches at different cross-sections of the spatio-temporal data STIR-Net blends the features from both spatial and temporal domains to reconstruct high-quality CT volumes. In this study we finalize extensive experiments to appraise the image restoration performance at different levels of tube current and spatial and temporal resolution scales.The results demonstrate the capability of our STIR-Net to restore high-quality scans at as low as 11% of absorbed radiation dose of the current imaging protocol yielding an average of 10% improvement for perfusion maps compared to the patch-based log likelihood method. STIR-Net: Deep Spatial-Temporal Image Restoration Net for Radiation Reduction in CT Perfusion.
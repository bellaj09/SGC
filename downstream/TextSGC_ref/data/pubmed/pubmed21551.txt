This paper presents an EEG-based brain-computer interface system for classifying eleven motor imagery MI tasks within the same hand. The proposed system utilizes the Choi-Williams time-frequency distribution CWD to construct a time-frequency representation TFR of the EEG signals. The constructed TFR is used to extract five categories of time-frequency features TFFs. The TFFs are processed using a hierarchical classification model to identify the MI task encapsulated within the EEG signals. To evaluate the performance of the proposed approach EEG data were recorded for eighteen intact subjects and four amputated subjects while imagining to perform each of the eleven hand MI tasks. Two performance evaluation analyses namely channel- and TFF-based analyses are conducted to identify the best subset of EEG channels and the TFFs category respectively that enable the highest classification accuracy between the MI tasks. In each evaluation analysis the hierarchical classification model is trained using two training procedures namely subject-dependent and subject-independent procedures. These two training procedures quantify the capability of the proposed approach to capture both intra- and inter-personal variations in the EEG signals for different MI tasks within the same hand. The results demonstrate the efficacy of the approach for classifying the MI tasks within the same hand. In particular the classification accuracies obtained for the intact and amputated subjects are as high as 88 . 8 % and 90 . 2 %  respectively for the subject-dependent training procedure and 80 . 8 % and 87 . 8 %  respectively for the subject-independent training procedure. These results suggest the feasibility of applying the proposed approach to control dexterous prosthetic hands which can be of great benefit for individuals suffering from hand amputations. EEG-Based Brain-Computer Interface for Decoding Motor Imagery Tasks within the Same Hand Using Choi-Williams Time-Frequency Distribution.
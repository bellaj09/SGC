In this paper the classic momentum algorithm for stochastic optimization is considered. A method is introduced that adjusts coefficients for this algorithm during its operation. The method does not depend on any preliminary knowledge of the optimization problem. In the experimental study the method is applied to on-line learning in feed-forward neural networks including deep auto-encoders and outperforms any fixed coefficients. The method eliminates coefficients that are difficult to determine with profound influence on performance. While the method itself has some coefficients they are ease to determine and sensitivity of performance to them is low. Consequently the method makes on-line learning a\xa0practically parameter-free process and broadens the area of potential application of this technology. ASD+M: Automatic parameter tuning in stochastic optimization and on-line learning.
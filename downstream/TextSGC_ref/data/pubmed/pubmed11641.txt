Multi-atlas-based methods are commonly used for MR brain image labeling which alleviates the burdening and time-consuming task of manual labeling in neuroimaging analysis studies. Traditionally multi-atlas-based methods first register multiple atlases to the target image and then propagate the labels from the labeled atlases to the unlabeled target image. However the registration step involves non-rigid alignment which is often time-consuming and might lack high accuracy. Alternatively patch-based methods have shown promise in relaxing the demand for accurate registration but they often require the use of hand-crafted features. Recently deep learning techniques have demonstrated their effectiveness in image labeling by automatically learning comprehensive appearance features from training images. In this paper we propose a multi-atlas guided fully convolutional network MA-FCN for automatic image labeling which aims at further improving the labeling performance with the aid of prior knowledge from the training atlases. Specifically we train our MA-FCN model in a patch-based manner where the input data consists of not only a training image patch but also a set of its neighboring i.e. most similar affine-aligned atlas patches. The guidance information from neighboring atlas patches can help boost the discriminative ability of the learned FCN. Experimental results on different datasets demonstrate the effectiveness of our proposed method by significantly outperforming the conventional FCN and several state-of-the-art MR brain labeling methods. Automatic brain labeling via multi-atlas guided fully convolutional networks.
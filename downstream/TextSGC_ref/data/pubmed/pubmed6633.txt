One-class classification OCC poses as an essential component in many machine learning and computer vision applications including novelty anomaly and outlier detection systems. With a known definition for a target or normal set of data one-class classifiers can determine if any given new sample spans within the distribution of the target class. Solving for this task in a general setting is particularly very challenging due to the high diversity of samples from the target class and the absence of any supervising signal over the novelty nontarget concept which makes designing end-to-end models unattainable. In this article we propose an adversarial training approach to detect out-of-distribution samples in an end-to-end trainable deep model. To this end we jointly train two deep neural networks R and D. The latter plays as the discriminator while the former during training helps D characterize a probability distribution for the target class by creating adversarial examples and during testing collaborates with it to detect novelties. Using our OCC we first test outlier detection on two image data sets Modified National Institute of Standards and Technology MNIST and Caltech-256. Then several experiments for video anomaly detection are performed on University of Minnesota UMN and University of California San Diego UCSD data sets. Our proposed method can successfully learn the target class underlying distribution and outperforms other approaches. Deep End-to-End One-Class Classifier.
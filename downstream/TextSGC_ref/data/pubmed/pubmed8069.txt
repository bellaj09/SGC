Given a low-resolution LR image multi-modal image super-resolution MISR aims to find the high-resolution HR version of this image with the guidance of an HR image from another modality. In this paper we use a model-based approach to design a new deep network architecture for MISR. We first introduce a novel joint multi-modal dictionary learning JMDL algorithm to model cross-modality dependency. In JMDL we simultaneously learn three dictionaries and two transform matrices to combine the modalities. Then by unfolding the iterative shrinkage and thresholding algorithm ISTA we turn the JMDL model into a deep neural network called deep coupled ISTA network. Since the network initialization plays an important role in deep network training we further propose a layer-wise optimization algorithm LOA to initialize the parameters of the network before running back-propagation strategy. Specifically we model the network initialization as a multi-layer dictionary learning problem and solve it through convex optimization. The proposed LOA is demonstrated to effectively decrease the training loss and increase the reconstruction accuracy. Finally we compare our method with other state-of-the-art methods in the MISR task. The numerical results show that our method consistently outperforms others both quantitatively and qualitatively at different upscaling factors for various multi-modal scenarios. Deep Coupled ISTA Network for Multi-modal Image Super-Resolution.
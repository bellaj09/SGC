The ability of Baboons papio papio to distinguish between English words and nonwords has been modeled using a deep learning convolutional network model that simulates a ventral pathway in which lexical representations of different granularity develop. However given that pigeons columba livia whose brain morphology is drastically different can also be trained to distinguish between English words and nonwords it appears that a less species-specific learning algorithm may be required to explain this behavior. Accordingly we examined whether the learning model of Rescorla and Wagner which has proved to be amazingly fruitful in understanding animal and human learning could account for these data. We show that a discrimination learning network using gradient orientation features as input units and word and nonword units as outputs succeeds in predicting baboon lexical decision behavior-including key lexical similarity effects and the ups and downs in accuracy as learning unfolds-with surprising precision. The models performance in which words are not explicitly represented is remarkable because it is usually assumed that lexicality decisions including the decisions made by baboons and pigeons are mediated by explicit lexical representations. By contrast our results suggest that in learning to perform lexical decision tasks baboons and pigeons do not construct a hierarchy of lexical units. Rather they make optimal use of low-level information obtained through the massively parallel processing of gradient orientation features. Accordingly we suggest that reading in humans first involves initially learning a high-level system building on letter representations acquired from explicit instruction in literacy which is then integrated into a conventionalized oral communication system and that like the latter fluent reading involves the massively parallel processing of the low-level features encoding semantic contrasts. Are baboons learning "orthographic" representations? Probably not.
Computer vision models that can recognize plant diseases in the field would be valuable tools for disease management and resistance breeding. Generating enough data to train these models is difficult however since only trained experts can accurately identify symptoms. In this study we describe and implement a two-step method for generating a large amount of high-quality training data with minimal expert input. First experts located symptoms of northern leaf blight NLB in field images taken by unmanned aerial vehicles UAVs annotating them quickly at low resolution. Second non-experts were asked to draw polygons around the identified diseased areas producing high-resolution ground truths that were automatically screened based on agreement between multiple workers. We then used these crowdsourced data to train a convolutional neural network CNN feeding the output into a conditional random field CRF to segment images into lesion and non-lesion regions with accuracy of 0.9979 and F1 score of 0.7153. The CNN trained on crowdsourced data showed greatly improved spatial resolution compared to one trained on expert-generated data despite using only one fifth as many expert annotations. The final model was able to accurately delineate lesions down to the millimeter level from UAV-collected images the finest scale of aerial plant disease detection achieved to date. The two-step approach to generating training data is a promising method to streamline deep learning approaches for plant disease detection and for complex plant phenotyping tasks in general. Millimeter-Level Plant Disease Detection From Aerial Photographs via Deep Learning and Crowdsourced Data.
"Robotic-assisted minimally invasive surgeries have gained a lot of popularity over conventional procedures as they offer many benefits to both surgeons and patients. Nonetheless they still suffer from some limitations that affect their outcome. One of them is the lack of force feedback which restricts the surgeons sense of touch and might reduce precision during a procedure. To overcome this limitation we propose a novel force estimation approach that combines a vision based solution with supervised learning to estimate the applied force and provide the surgeon with a suitable representation of it. The proposed solution starts with extracting the geometry of motion of the hearts surface by minimizing an energy functional to recover its 3D deformable structure. A deep network based on a LSTM-RNN architecture is then used to learn the relationship between the extracted visual-geometric information and the applied force and to find accurate mapping between the two. Our proposed force estimation solution avoids the drawbacks usually associated with force sensing devices such as biocompatibility and integration issues. We evaluate our approach on phantom and realistic tissues in which we report an average root-mean square error of 0.02 N." Towards Retrieving Force Feedback in Robotic-Assisted Surgery: A Supervised Neuro-Recurrent-Vision Approach.
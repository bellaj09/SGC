We present a computational model of intermittent visual sampling and locomotor control in a simple yet representative task of a car driver following another vehicle. The model has a number of features that take it beyond the current state of the art in modelling natural tasks and driving in particular. First unlike most control theoretical models in vision science and engineering-where control is directly based on observable optical variables-actions are based on a temporally enduring internal representation. Second unlike the more sophisticated engineering driver models based on internal representations our model explicitly aims to be psychologically plausible in particular in modelling perceptual processes and their limitations. Third unlike most psychological models it is implemented as an actual simulation model capable of full task performance visual sampling and longitudinal control. The model is developed and validated using a dataset from a simplified car-following experiment N = 40 in both three-dimensional virtual reality and a real instrumented vehicle. The results replicate our previously reported connection between time headway and visual attention. The model reproduces this connection and predicts that it emerges from control of action uncertainty. Implications for traffic psychological models and future developments for psychologically plausible yet computationally rigorous models of full natural task performance are discussed. "A computational model for drivers cognitive state visual perception and intermittent attention in a distracted car following task."
Despite the promising progress made in recent years person reidentification re-ID remains a challenging task due to the complex variations in human appearances from different camera views. This paper proposes to tackle this task by jointly learning feature representation and distance metric in an end-to-end manner. Existing deep metric learning-based re-ID methods usually encounter the following two weaknesses: 1 most works based on pairwise or triplet constraints often suffer from slow convergence and poor local optima partially because they use very limited samples for each update and 2 hard negative sample mining has been widely applied in existing works. However hard positive samples which also contribute to the training of network have not received enough attention. To alleviate these problems we develop a novel structural metric learning objective for person re-ID in which each positive pair is allowed to be compared against all negative pairs in a minibatch and each positive pair is adaptively assigned a hardness-aware weight to modulate its contribution. The introduced positive pair weighting strategy enables the algorithm to focus more on the hard positive samples. Furthermore we propose to enhance the proposed loss function by adding a global loss term to reduce the variances of positive/negative pair distances which is able to improve the generalization capability of the network model. By this approach person images can be nonlinearly mapped into a low-dimensional embedding space where similar samples are kept closer and dissimilar samples are pushed farther apart. We implement the proposed algorithm using the inception architecture and evaluate it on three large-scale re-ID data sets. Experiment results demonstrate that our approach is able to outperform most state of the arts while using much lower dimensional deep features. Person Reidentification via Structural Deep Metric Learning.
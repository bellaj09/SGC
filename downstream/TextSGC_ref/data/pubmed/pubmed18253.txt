"Human gaze awareness is important for social and collaborative interactions. Recent technological advances in augmented reality AR displays and sensors provide us with the means to extend collaborative spaces with real-time dynamic AR indicators of ones gaze for example via three-dimensional cursors or rays emanating from a partners head. However such gaze cues are only as useful as the quality of the underlying gaze estimation and the accuracy of the display mechanism. Depending on the type of the visualization and the characteristics of the errors AR gaze cues could either enhance or interfere with collaborations. In this paper we present two human-subject studies in which we investigate the influence of angular and depth errors target distance and the type of gaze visualization on participants performance and subjective evaluation during a collaborative task with a virtual human partner where participants identified targets within a dynamically walking crowd. First our results show that there is a significant difference in performance for the two gaze visualizations ray and cursor in conditions with simulated angular and depth errors: the ray visualization provided significantly faster response times and fewer errors compared to the cursor visualization. Second our results show that under optimal conditions among four different gaze visualization methods a ray without depth information provides the worst performance and is rated lowest while a combination of a ray and cursor with depth information is rated highest. We discuss the subjective and objective performance thresholds and provide guidelines for practitioners in this field." Effects of Depth Information on Visual Target Identification Task Performance in Shared Gaze Environments.
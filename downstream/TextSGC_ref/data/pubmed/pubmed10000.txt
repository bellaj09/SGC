Recently deep learning based speech segregation has been shown to improve human speech intelligibility in noisy environments. However one important factor not yet considered is room reverberation which characterizes typical daily environments. The combination of reverberation and background noise can severely degrade speech intelligibility for hearing-impaired HI listeners. In the current study a deep learning based time-frequency masking algorithm was proposed to address both room reverberation and background noise. Specifically a deep neural network was trained to estimate the ideal ratio mask where anechoic-clean speech was considered as the desired signal. Intelligibility testing was conducted under reverberant-noisy conditions with reverberation time T 60\u2009=\u20090.6\u2009s plus speech-shaped noise or babble noise at various signal-to-noise ratios. The experiments demonstrated that substantial speech intelligibility improvements were obtained for HI listeners. The algorithm was also somewhat beneficial for normal-hearing NH listeners. In addition sentence intelligibility scores for HI listeners with algorithm processing approached or matched those of young-adult NH listeners without processing. The current study represents a step toward deploying deep learning algorithms to help the speech understanding of HI listeners in everyday conditions. A deep learning based segregation algorithm to increase speech intelligibility for hearing-impaired listeners in reverberant-noisy conditions.
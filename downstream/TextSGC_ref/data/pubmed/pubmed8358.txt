The level set based deformable models LDM are commonly used for medical image segmentation. However they rely on a handcrafted curve evolution velocity that needs to be adapted for each segmentation task. The Convolutional Neural Networks CNN address this issue by learning robust features in a supervised end-to-end manner. However CNNs employ millions of network parameters which require a large amount of data during training to prevent over-fitting and increases the memory requirement and computation time during testing. Moreover since CNNs pose segmentation as a region-based pixel labeling they cannot explicitly model the high-level dependencies between the points on the object boundary to preserve its overall shape smoothness or the regional homogeneity within and outside the boundary. We present a Recurrent Neural Network based solution called the RACE-net to address the above issues. RACE-net models a generalized LDM evolving under a constant and mean curvature velocity. At each time-step the curve evolution velocities are approximated using a feed-forward architecture inspired by the multiscale image pyramid. RACE-net allows the curve evolution velocities to be learned in an end-to-end manner while minimizing the number of network parameters computation time and memory requirements. The RACE-net was validated on three different segmentation tasks: optic disc and cup in color fundus images cell nuclei in histopathological images and the left atrium in cardiac MRI volumes. Assessment on public datasets was seen to yield high Dice values between 0.87 and 0.97 which illustrates its utility as a generic off-the-shelf architecture for biomedical segmentation. RACE-Net: A Recurrent Neural Network for Biomedical Image Segmentation.
This paper aims to present a new framework to train people with severe motor disabilities steering an assisted mobile robot AMR such as a powered wheelchair. Users with high level of motor disabilities are not able to use standard HMIs which provide a continuous command signal e. g. standard joystick. For this reason HMIs providing a small set of simple commands which are sparse and discrete in time must be used e. g. scanning interface or brain computer interface making very difficult to steer the AMR. In this sense the assisted navigation training framework ANTF is designed to train users driving the AMR in indoor structured environments using this type of HMIs. Additionally it provides user characterization on steering the robot which will later be used to adapt the AMR navigation system to human competence steering the AMR. A rule-based lens RBL model is used to characterize users on driving the AMR. Individual judgment performance choosing the best manoeuvres is modeled using a genetic-based policy capturing GBPC technique characterized to infer non-compensatory judgment strategies from human decision data. Three user models at three different learning stages using the RBL paradigm are presented. An assisted navigation training framework based on judgment theory using sparse and discrete human-machine interfaces.
Image denoising and high-level vision tasks are usually handled independently in the conventional practice of computer vision and their connection is fragile. In this paper we cope with the two jointly and explore the mutual influence between them with the focus on two questions namely 1 how image denoising can help improving high-level vision tasks and 2 how the semantic information from high-level vision tasks can be used to guide image denoising. First for image denoising we propose a convolutional neural network in which convolutions are conducted in various spatial resolutions via downsampling and upsampling operations in order to fuse and exploit contextual information on different scales. Second we propose a deep neural network solution that cascades two modules for image denoising and various high-level tasks respectively and use the joint loss for updating only the denoising network via backpropagation. We experimentally show that on one hand the proposed denoiser has the generality to overcome the performance degradation of different high-level vision tasks. On the other hand with the guidance of high-level vision information the denoising network produces more visually appealing results. Extensive experiments demonstrate the benefit of exploiting image semantics simultaneously for image denoising and highlevel vision tasks via deep learning. The code is available online: https://github.com/Ding-Liu/DeepDenoising. Connecting Image Denoising and High-Level Vision Tasks via Deep Learning.
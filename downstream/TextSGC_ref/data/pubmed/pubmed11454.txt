Given the world-wide prevalence of heart disease the robust and automatic detection of abnormal heart sounds could have profound effects on patient care and outcomes. In this regard a comparison of conventional and state-of-theart deep learning based computer audition paradigms for the audio classification task of normal mild abnormalities and moderate/severe abnormalities as present in phonocardiogram recordings is presented herein. In particular we explore the suitability of deep feature representations as learnt by sequence to sequence autoencoders based on the auDeep toolkit. Key results gained on the new Heart Sounds Shenzhen corpus indicate that a fused combination of deep unsupervised features is well suited to the three-way classification problem achieving our highest unweighted average recall of 47.9% on the test partition. Deep Unsupervised Representation Learning for Abnormal Heart Sound Classification.
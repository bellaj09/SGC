"We present a deep learning method used in conjunction with dual-modal microwave-ultrasound imaging to produce tomographic reconstructions of the complex-valued permittivity of numerical breast phantoms. We also assess tumor segmentation performance using the reconstructed permittivity as a feature. The contrast source inversion CSI technique is used to create the complex-permittivity images of the breast with ultrasound-derived tissue regions utilized as prior information. However imaging artifacts make the detection of tumors difficult. To overcome this issue we train a convolutional neural network CNN that takes in as input the dual-modal CSI reconstruction and attempts to produce the true image of the complex tissue permittivity. The neural network consists of successive convolutional and downsampling layers followed by successive deconvolutional and upsampling layers based on the U-Net architecture. To train the neural network the input-output pairs consist of CSIs dual-modal reconstructions along with the true numerical phantom images from which the microwave scattered field was synthetically generated. The reconstructed permittivity images produced by the CNN show that the network is not only able to remove the artifacts that are typical of CSI reconstructions but can also improve the detectability of tumors. The performance of the CNN is assessed using a four-fold cross-validation on our dataset that shows improvement over CSI both in terms of reconstruction error and tumor segmentation performance." Enhancement of Multimodal Microwave-Ultrasound Breast Imaging Using a Deep-Learning Technique.
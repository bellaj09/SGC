In recent years the deep reinforcement learning DRL algorithms have been developed rapidly and have achieved excellent performance in many challenging tasks. However due to the complexity of network structure and a large amount of network parameters the training of deep network is time-consuming and consequently the learning efficiency of DRL is limited. In this paper aiming to speed up the learning process of DRL agent we propose a novel approximate policy-based accelerated APA algorithm from the viewpoint of the error analysis of approximate policy iteration reinforcement learning algorithms. The proposed APA is proven to be convergent even with a more aggressive learning rate making the DRL agent have a faster learning speed. Furthermore to combine the accelerated algorithm with deep Q-network DQN Double DQN and deep deterministic policy gradient DDPG we proposed three novel DRL algorithms: APA-DQN APA-Double DQN and APA-DDPG which demonstrates the adaptability of the accelerated algorithm with DRL algorithms. We have tested the proposed algorithms on both discrete-action and continuous-action tasks. Their superior performance demonstrates their great potential in the practical applications. Approximate Policy-Based Accelerated Deep Reinforcement Learning.
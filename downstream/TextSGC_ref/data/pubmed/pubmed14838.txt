Autonomously following a man-made trail in the wild is a challenging problem for robotic systems. Recently deep learning-based approaches have cast the trail following problem as an image classification task and have achieved great success in the vision-based trail-following problem. However the existing research only focuses on the trail-following task with a single-robot system. In contrast many robotic tasks in reality such as search and rescue are conducted by a group of robots. While these robots are grouped to move in the wild they can cooperate to lead to a more robust performance and perform the trail-following task in a better manner. Concretely each robot can periodically exchange the vision data with other robots and make decisions based both on its local view and the information from others. This paper proposes a sensor fusion-based cooperative trail-following method which enables a group of robots to implement the trail-following task by fusing the sensor data of each robot. Our method allows each robot to face the same direction from different altitudes to fuse the vision data feature on the collective level and then take action respectively. Besides considering the quality of service requirement of the robotic software our method limits the condition to implementing the sensor data fusion process by using the "threshold" mechanism. Qualitative and quantitative experiments on the real-world dataset have shown that our method can significantly promote the recognition accuracy and lead to a more robust performance compared with the single-robot system. Sensor Fusion-Based Cooperative Trail Following for Autonomous Multi-Robot System.
Epidemiological studies demonstrate that dimensions of retinal vessels change with ocular diseases coronary heart disease and stroke. Different metrics have been described to quantify these changes in fundus images with arteriolar and venular calibers among the most widely used. The analysis often includes a manual procedure during which a trained grader differentiates between arterioles and venules. This step can be time-consuming and can introduce variability especially when large volumes of images need to be analyzed. In light of the recent successes of fully convolutional networks FCNs applied to biomedical image segmentation we assess its potential in the context of retinal artery-vein A/V discrimination. To the best of our knowledge a deep learning DL architecture for simultaneous vessel extraction and A/V discrimination has not been previously employed. With the aim of improving the automation of vessel analysis a novel application of the U-Net semantic segmentation architecture based on FCNs on the discrimination of arteries and veins in fundus images is presented. By utilizing DL results are obtained that exceed accuracies reported in the literature. Our model was trained and tested on the public DRIVE and HRF datasets. For DRIVE measuring performance on vessels wider than two pixels the FCN achieved accuracies of 94.42% and 94.11% on arteries and veins respectively. This represents a decrease in error of 25% over the previous state of the art reported by Xu et al. 2017. Additionally we introduce the HRF A/V ground truth on which our model achieves 96.98% accuracy on all discovered centerline pixels. HRF A/V ground truth validated by an ophthalmologist predicted A/V annotations and evaluation code are available at https://github.com/rubenhx/av-segmentation. Artery-vein segmentation in fundus images using a fully convolutional network.
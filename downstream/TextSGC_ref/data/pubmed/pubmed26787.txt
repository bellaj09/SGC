Speech interfaces have become widely accepted and are nowadays integrated in various real-life applications and devices. They have become a part of our daily life. However speech interfaces presume the ability to produce intelligible speech which might be impossible due to either loud environments bothering bystanders or incapabilities to produce speech i.e. patients suffering from locked-in syndrome. For these reasons it would be highly desirable to not speak but to simply envision oneself to say words or sentences. Interfaces based on imagined speech would enable fast and natural communication without the need for audible speech and would give a voice to otherwise mute people. This focused review analyzes the potential of different brain imaging techniques to recognize speech from neural signals by applying Automatic Speech Recognition technology. We argue that modalities based on metabolic processes such as functional Near Infrared Spectroscopy and functional Magnetic Resonance Imaging are less suited for Automatic Speech Recognition from neural signals due to low temporal resolution but are very useful for the investigation of the underlying neural mechanisms involved in speech processes. In contrast electrophysiologic activity is fast enough to capture speech processes and is therefor better suited for ASR. Our experimental results indicate the potential of these signals for speech recognition from neural data with a focus on invasively measured brain activity electrocorticography. As a first example of Automatic Speech Recognition techniques used from neural signals we discuss the Brain-to-text system. Automatic Speech Recognition from Neural Signals: A Focused Review.
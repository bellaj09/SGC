Building spiking neural networks SNNs based on biological synaptic plasticities holds a promising potential for accomplishing fast and energy-efficient computing which is beneficial to mobile robotic applications. However the implementations of SNNs in robotic fields are limited due to the lack of practical training methods. In this paper we therefore introduce both indirect and direct end-to-end training methods of SNNs for a lane-keeping vehicle. First we adopt a policy learned using the Deep Q-Learning DQN algorithm and then subsequently transfer it to an SNN using supervised learning. Second we adopt the reward-modulated spike-timing-dependent plasticity R-STDP for training SNNs directly since it combines the advantages of both reinforcement learning and the well-known spike-timing-dependent plasticity STDP. We examine the proposed approaches in three scenarios in which a robot is controlled to keep within lane markings by using an event-based neuromorphic vision sensor. We further demonstrate the advantages of the R-STDP approach in terms of the lateral localization accuracy and training time steps by comparing them with other three algorithms presented in this paper. Indirect and direct training of spiking neural networks for end-to-end control of a lane-keeping vehicle.
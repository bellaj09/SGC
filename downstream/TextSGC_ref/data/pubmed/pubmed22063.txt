"Traditional brain-state classifications are primarily based on two well-known neural biomarkers: P300 and motor imagery / event-related frequency modulation. Currently many brain-computer interface BCI systems have successfully helped patients with severe neuromuscular disabilities to regain independence. In order to translate this neural engineering success to hearing aid applications we must be able to capture brain waves across the population reliably in cortical regions that have not previously been incorporated in these systems before for example dorsolateral prefrontal cortex DLPFC and right temporoparietal junction. Here we present a brain-state classification framework that incorporates individual anatomical information and accounts for potential anatomical and functional differences across subjects by applying appropriate cortical weighting functions prior to the classification stage. Using an inverse imaging approach use simulated EEG data to show that our method can outperform the traditional brain-state classification approach that trains only on individual subjects data without considering data available at a population level." Towards a next-generation hearing aid through brain state classification and modeling.
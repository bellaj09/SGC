In this paper we propose a learning-based depth estimation framework suitable for both densely and sparsely sampled light fields. The proposed framework consists of three processing steps: initial depth estimation fusion with occlusion handling and refinement. The estimation can be performed from a flexible subset of input views. The fusion of initial disparity estimates relying on two warping error measures allows us to have an accurate estimation in occluded regions and along the contours. In contrast with methods relying on the computation of cost volumes the proposed approach does not need any prior information on the disparity range. Experimental results show that the proposed method outperforms state-of-the-art light fields depth estimation methods including prior methods based on deep neural architectures. A Framework for Learning Depth From a Flexible Subset of Dense and Sparse Light Field Views.
The goal of network representation learning also called network embedding is to encode the network structure information into a continuous low-dimensionality embedding space where geometric relationships among the vectors can reflect the relationships of nodes in the original network. The existing network representation learning methods are always single-task learning in which case these methods focus on preserving the proximity of nodes from one aspect. However the proximity of nodes is dependent on both the local and global structure resulting in a limitation on the node embeddings learned by these methods. In order to solve this problem in this paper we propose a novel method Multi-Task Learning-Based Network Embedding termed MLNE. There are two tasks in this method so as to preserve the proximity of nodes. The aim of the first task is to preserve the high-order proximity between pairwise nodes in the whole network. The second task is to preserve the low-order proximity in the one-hop area of each node. By jointly learning these tasks in the supervised deep learning model our method can obtain node embeddings that can sufficiently reflect the roles that nodes play in networks. In order to demonstrate the efficacy of our MLNE method over existing state-of-the-art methods we conduct experiments on multi-label classification link prediction and visualization in five real-world networks. The experimental results show that our method performs competitively. Multi-Task Learning Based Network Embedding.
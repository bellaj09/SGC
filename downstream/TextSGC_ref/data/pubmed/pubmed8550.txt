Hashing plays a pivotal role in nearest-neighbor searching for large-scale image retrieval. Recently deep learning-based hashing methods have achieved promising performance. However most of these deep methods involve discriminative models which require large-scale labeled training datasets thus hindering their real-world applications. In this paper we propose a novel strategy to exploit the semantic similarity of the training data and design an efficient generative adversarial framework to learn binary hash codes in an unsupervised manner. Specifically our model consists of three different neural networks: an encoder network to learn hash codes from images a generative network to generate images from hash codes and a discriminative network to distinguish between pairs of hash codes and images. By adversarially training these networks we successfully learn mutually coherent encoder and generative networks and can output efficient hash codes from the encoder network. We also propose a novel strategy which utilizes both feature and neighbor similarities to construct a semantic similarity matrix then use this matrix to guide the hash code learning process. Integrating the supervision of this semantic similarity matrix into the adversarial learning framework can efficiently preserve the semantic information of training data in Hamming space. The experimental results on three widely used benchmarks show that our method not only significantly outperforms several state-of-the-art unsupervised hashing methods but also achieves comparable performance with popular supervised hashing methods. Unsupervised Semantic-Preserving Adversarial Hashing for Image Search.
A multitude of imaging and vision tasks have seen recently a major transformation by deep learning methods and in particular by the application of convolutional neural networks. These methods achieve impressive results even for applications where it is not apparent that convolutions are suited to capture the underlying physics. In this work we develop a network architecture based on nonlinear diffusion processes named DiffNet. By design we obtain a nonlinear network architecture that is well suited for diffusion-related problems in imaging. Furthermore the performed updates are explicit by which we obtain better interpretability and generalisability compared to classical convolutional neural network architectures. The performance of DiffNet is tested on the inverse problem of nonlinear diffusion with the Perona-Malik filter on the STL-10 image dataset. We obtain competitive results to the established U-Net architecture with a fraction of parameters and necessary training data. Networks for Nonlinear Diffusion Problems in Imaging.
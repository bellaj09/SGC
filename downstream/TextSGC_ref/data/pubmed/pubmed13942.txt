Degraded image semantic segmentation is of great importance in autonomous driving highway navigation systems and many other safety-related applications and it was not systematically studied before. In general image degradations increase the difficulty of semantic segmentation usually leading to decreased semantic segmentation accuracy. Therefore performance on the underlying clean images can be treated as an upper bound of degraded image semantic segmentation. While the use of supervised deep learning has substantially improved the state of the art of semantic image segmentation the gap between the feature distribution learned using the clean images and the feature distribution learned using the degraded images poses a major obstacle in improving the degraded image semantic segmentation performance. The conventional strategies for reducing the gap include: 1 Adding image-restoration based pre-processing modules; 2 Using both clean and the degraded images for training; 3 Fine-tuning the network pre-trained on the clean image. In this paper we propose a novel Dense-Gram Network to more effectively reduce the gap than the conventional strategies and segment degraded images. Extensive experiments demonstrate that the proposed Dense-Gram Network yields stateof-the-art semantic segmentation performance on degraded images synthesized using PASCAL VOC 2012 SUNRGBD CamVid and CityScapes datasets. Degraded Image Semantic Segmentation with Dense-Gram Networks.
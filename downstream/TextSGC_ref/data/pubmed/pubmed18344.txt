Despite the growing popularity of virtual reality environments few laboratories are equipped to investigate eye movements within these environments. This primer is intended to reduce the time and effort required to incorporate eye-tracking equipment into a virtual reality environment. We discuss issues related to the initial startup and provide algorithms necessary for basic analysis. Algorithms are provided for the calculation of gaze angle within a virtual world using a monocular eye-tracker in a three-dimensional environment. In addition we provide algorithms for the calculation of the angular distance between the gaze and a relevant virtual object and for the identification of fixations saccades and pursuit eye movements. Finally we provide tools that temporally synchronize gaze data and the visual stimulus and enable real-time assembly of a video-based record of the experiment using the Quicktime MOV format available at http://sourceforge.net/p/utdvrlibraries/. This record contains the visual stimulus the gaze cursor and associated numerical data and can be used for data exportation visual inspection and validation of calculated gaze movements. Real-time recording and classification of eye movements in an immersive virtual environment.
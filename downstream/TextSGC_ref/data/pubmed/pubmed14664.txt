Machine learning approaches hold great potential for the automated detection of lung nodules on chest radiographs but training algorithms requires very large amounts of manually annotated radiographs which are difficult to obtain. The increasing availability of PACS Picture Archiving and Communication System is laying the technological foundations needed to make available large volumes of clinical data and images from hospital archives. Binary labels indicating whether a radiograph contains a pulmonary lesion can be extracted at scale using natural language processing algorithms. In this study we propose two novel neural networks for the detection of chest radiographs containing pulmonary lesions. Both architectures make use of a large number of weakly-labelled images combined with a smaller number of manually annotated x-rays. The annotated lesions are used during training to deliver a type of visual attention feedback informing the networks about their lesion localisation performance. The first architecture extracts saliency maps from high-level convolutional layers and compares the inferred position of a lesion against the true position when this information is available; a localisation error is then back-propagated along with the softmax classification error. The second approach consists of a recurrent attention model that learns to observe a short sequence of smaller image portions through reinforcement learning; the reward function penalises the exploration of areas within an image that are unlikely to contain nodules. Using a repository of over 430000 historical chest radiographs we present and discuss the proposed methods over related architectures that use either weakly-labelled or annotated images only. Learning to detect chest radiographs containing pulmonary lesions using visual attention networks.
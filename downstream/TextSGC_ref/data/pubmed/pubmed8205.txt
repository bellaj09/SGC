Aerial imagery is regularly used by crop researchers growers and farmers to monitor crops during the growing season. To extract meaningful information from large-scale aerial images collected from the field high-throughput phenotypic analysis solutions are required which not only produce high-quality measures of key crop traits but also support professionals to make prompt and reliable crop management decisions. Here we report AirSurf an automated and open-source analytic platform that combines modern computer vision up-to-date machine learning and modular software engineering in order to measure yield-related phenotypes from ultra-large aerial imagery. To quantify millions of in-field lettuces acquired by fixed-wing light aircrafts equipped with normalised difference vegetation index NDVI sensors we customised AirSurf by combining computer vision algorithms and a deep-learning classifier trained with over 100000 labelled lettuce signals. The tailored platform AirSurf-Lettuce is capable of scoring and categorising iceberg lettuces with high accuracy >98%. Furthermore novel analysis functions have been developed to map lettuce size distribution across the field based on which associated global positioning system GPS tagged harvest regions have been identified to enable growers and farmers to conduct precision agricultural practises in order to improve the actual yield as well as crop marketability before the harvest. Combining computer vision and deep learning to enable ultra-scale aerial phenotyping and precision agriculture: A case study of lettuce production.
Machine learning algorithms for the analysis of time-series often depend on the assumption that utilised data are temporally aligned. Any temporal discrepancies arising in the data is certain to lead to ill-generalisable models which in turn fail to correctly capture properties of the task at hand. The temporal alignment of time-series is thus a crucial challenge manifesting in a multitude of applications. Nevertheless the vast majority of algorithms oriented towards temporal alignment are either applied directly on the observation space or simply utilise linear projections-thus failing to capture complex hierarchical non-linear representations that may prove beneficial especially when dealing with multi-modal data e.g. visual and acoustic information. To this end we present Deep Canonical Time Warping DCTW a method that automatically learns non-linear representations of multiple time-series that are i maximally correlated in a shared subspace and ii temporally aligned. Furthermore we extend DCTW to a supervised setting where during training available labels can be utilised towards enhancing the alignment process. By means of experiments on four datasets we show that the representations learnt significantly outperform state-of-the-art methods in temporal alignment elegantly handling scenarios with heterogeneous feature sets such as the temporal alignment of acoustic and visual information. Deep Canonical Time Warping for Simultaneous Alignment and Representation Learning of Sequences.
Reinforcement learning RL-based brain machine interfaces BMIs enable the user to learn from the environment through interactions to complete the task without desired signals which is promising for clinical applications. Previous studies exploited Q-learning techniques to discriminate neural states into simple directional actions providing the trial initial timing. However the movements in BMI applications can be quite complicated and the action timing explicitly shows the intention when to move. The rich actions and the corresponding neural states form a large state-action space imposing generalization difficulty on Q-learning. In this paper we propose to adopt attention-gated reinforcement learning AGREL as a new learning scheme for BMIs to adaptively decode high-dimensional neural activities into seven distinct movements directional moves holdings and resting due to the efficient weight-updating. We apply AGREL on neural data recorded from M1 of a monkey to directly predict a seven-action set in a time sequence to reconstruct the trajectory of a center-out task. Compared to Q-learning techniques AGREL could improve the target acquisition rate to 90.16% in average with faster convergence and more stability to follow neural activity over multiple days indicating the potential to achieve better online decoding performance for more complicated BMI tasks. Neural Control of a Tracking Task via Attention-Gated Reinforcement Learning for Brain-Machine Interfaces.
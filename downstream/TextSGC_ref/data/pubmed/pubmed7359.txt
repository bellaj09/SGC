Multiple kernel learning MKL is a widely used technique for kernel design. Its principle consists in learning for a given support vector classifier the most suitable convex or sparse linear combination of standard elementary kernels. However these combinations are shallow and often powerless to capture the actual similarity between highly semantic data especially for challenging classification tasks such as image annotation. In this paper we redefine multiple kernels using deep multi-layer networks. In this new contribution a deep multiple kernel is recursively defined as a multi-layered combination of nonlinear activation functions each one involves a combination of several elementary or intermediate kernels and results into a positive semi-definite deep kernel. We propose four different frameworks in order to learn the weights of these networks: supervised unsupervised kernel-based semisupervised and Laplacian-based semi-supervised. When plugged into support vector machines SVMs the resulting deep kernel networks show clear gain compared to several shallow kernels for the task of image annotation. Extensive experiments and analysis on the challenging ImageCLEF photo annotation benchmark the COREL5k database and the Banana dataset validate the effectiveness of the proposed method. Nonlinear Deep Kernel Learning for Image Annotation.
Deep learning is the driving force behind many recent technologies; however deep neural networks are often viewed as "black-boxes" due to their internal complexity that is hard to understand. Little research focuses on helping people explore and understand the relationship between a user\s data and the learned representations in deep learning models. We present our ongoing work ShapeShop an interactive system for visualizing and understanding what semantics a neural network model has learned. Built using standard web technologies ShapeShop allows users to experiment with and compare deep learning models to help explore the robustness of image classifiers. ShapeShop: Towards Understanding Deep Learning Representations via Interactive Experimentation.
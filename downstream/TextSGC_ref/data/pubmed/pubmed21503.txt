In human perception the ability to determine eye height is essential because eye height is used to scale heights of objects velocities affordances and distances all of which allow for successful environmental interaction. It is well understood that eye height is fundamental to determine many of these percepts. Yet how eye height itself is provided is still largely unknown. While the information potentially specifying eye height in the real world is naturally coincident in an environment with a regular ground surface these sources of information can be easily divergent in similar and common virtual reality scenarios. Thus we conducted virtual reality experiments where we manipulated the virtual eye height in a distance perception task to investigate how eye height might be determined in such a scenario. We found that humans rely more on their postural cues for determining their eye height if there is a conflict between visual and postural information and little opportunity for perceptual-motor calibration is provided. This is demonstrated by the predictable variations in their distance estimates. Our results suggest that the eye height in such circumstances is informed by postural cues when estimating egocentric distances in virtual reality and consequently does not depend on an internalized value for eye height. The importance of postural cues for determining eye height in immersive virtual reality.
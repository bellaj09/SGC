Background and objectivesAutomated segmentation and tracking of surgical instruments and catheters under X-ray fluoroscopy hold the potential for enhanced image guidance in catheter-based endovascular procedures. This article presents a novel method for real-time segmentation of catheters and guidewires in 2d X-ray images. We employ Convolutional Neural Networks CNNs and propose a transfer learning approach using synthetic fluoroscopic images to develop a lightweight version of the U-Net architecture. Our strategy requiring a small amount of manually annotated data streamlines the training process and results in a U-Net model which achieves comparable performance to the state-of-the-art segmentation with a decreased number of trainable parameters. MethodsThe proposed transfer learning approach exploits high-fidelity synthetic images generated from real fluroscopic backgrounds. We implement a two-stage process initial end-to-end training and fine-tuning to develop two versions of our model using synthetic and phantom fluoroscopic images independently. A small number of manually annotated in-vivo images is employed to fine-tune the deepest 7 layers of the U-Net architecture producing a network specialized for pixel-wise catheter/guidewire segmentation. The network takes as input a single grayscale image and outputs the segmentation result as a binary mask against the background. ResultsEvaluation is carried out with images from in-vivo fluoroscopic video sequences from six endovascular procedures with different surgical setups. We validate the effectiveness of developing the U-Net models using synthetic data in tests where fine-tuning and testing in-vivo takes place both by dividing data from all procedures into independent fine-tuning/testing subsets as well as by using different in-vivo sequences. Accurate catheter/guidewire segmentation average Dice coefficient of \xa0~\xa00.55 \xa0~\xa00.26 and \xa0~\xa00.17 is obtained with both U-Net models. Compared to the state-of-the-art CNN models the proposed U-Net achieves comparable performance \xa0\xa05% average Dice coefficients in terms of segmentation accuracy while yielding a 84% reduction of the testing time. This adds flexibility for real-time operation and makes our network adaptable to increased input resolution. ConclusionsThis work presents a new approach in the development of CNN models for pixel-wise segmentation of surgical catheters in X-ray fluoroscopy exploiting synthetic images and transfer learning. Our methodology reduces the need for manually annotating large volumes of data for training. This represents an important advantage given that manual pixel-wise annotations is a key bottleneck in developing CNN segmentation models. Combined with a simplified U-Net model our work yields significant advantages compared to current state-of-the-art solutions. Catheter segmentation in X-ray fluoroscopy using synthetic data and transfer learning with light U-nets.
"A recently developed light projection technique can add dynamic impressions to static real objects without changing their original visual attributes such as surface colors and textures. It produces illusory motion impressions in the projection target by projecting gray-scale motion-inducer patterns that selectively drive the motion detectors in the human visual system. Since a compelling illusory motion can be produced by an inducer pattern weaker than necessary to perfectly reproduce the shift of the original pattern on an objects surface the technique works well under bright environmental light conditions. However determining the best deformation sizes is often difficult: When users try to add a large deformation the deviation in the projected patterns from the original surface pattern on the target object becomes apparent. Therefore to obtain satisfactory results they have to spend much time and effort to manually adjust the shift sizes. Here to overcome this limitation we propose an optimization framework that adaptively retargets the displacement vectors based on a perceptual model. The perceptual model predicts the subjective inconsistency between a projected pattern and an original one by simulating responses in the human visual system. The displacement vectors are adaptively optimized so that the projection effect is maximized within the tolerable range predicted by the model. We extensively evaluated the perceptual model and optimization method through a psychophysical experiment as well as user studies." Perceptually Based Adaptive Motion Retargeting to Animate Real Objects by Light Projection.
Individuals with hearing impairment have particular difficulty perceptually segregating concurrent voices and understanding a talker in the presence of a competing voice. In contrast individuals with normal hearing perform this task quite well. This listening situation represents a very different problem for both the human and machine listener when compared to perceiving speech in other types of background noise. A machine learning algorithm is introduced here to address this listening situation. A deep neural network was trained to estimate the ideal ratio mask for a male target talker in the presence of a female competing talker. The monaural algorithm was found to produce sentence-intelligibility increases for hearing-impaired HI and normal-hearing NH listeners at various signal-to-noise ratios SNRs. This benefit was largest for the HI listeners and averaged 59%-points at the least-favorable SNR with a maximum of 87%-points. The mean intelligibility achieved by the HI listeners using the algorithm was equivalent to that of young NH listeners without processing under conditions of identical interference. Possible reasons for the limited ability of HI listeners to perceptually segregate concurrent voices are reviewed as are possible implementation considerations for algorithms like the current one. An algorithm to increase intelligibility for hearing-impaired listeners in the presence of a competing talker.
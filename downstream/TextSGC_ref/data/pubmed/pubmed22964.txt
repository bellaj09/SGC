The automotive industry is rapidly developing new in-vehicle technologies that can provide drivers with information to aid awareness and promote quicker response times. Particularly vehicles with augmented reality AR graphics delivered via head-up displays HUDs are nearing mainstream commercial feasibility and will be widely implemented over the next decade. Though AR graphics have been shown to provide tangible benefits to drivers in scenarios like forward collision warnings and navigation they also create many new perceptual and sensory issues for drivers. For some time now designers have focused on increasing the realism and quality of virtual graphics delivered via HUDs and recently have begun testing more advanced 3D HUD systems that deliver volumetric spatial information to drivers. However the realization of volumetric graphics adds further complexity to the design and delivery of AR cues and moreover parameters in this new design space must be clearly and operationally defined and explored. In this work we present two user studies that examine how driver performance and visual attention are affected when using fixed and animated AR HUD interface design approaches in driving scenarios that require top-down and bottom-up cognitive processing. Results demonstrate that animated design approaches can produce some driving gains e.g. in goal-directed navigation tasks but often come at the cost of response time and distance. Our discussion yields AR HUD design recommendations and challenges some of the existing assumptions of world-fixed conformal graphic approaches to design. Augmented Reality Interface Design Approaches for Goal-directed and Stimulus-driven Driving Tasks.
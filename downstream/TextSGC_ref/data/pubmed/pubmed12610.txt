This paper explores cutting-edge deep learning methods for information extraction from medical imaging free text reports at a multi-institutional scale and compares them to the state-of-the-art domain-specific rule-based system - PEFinder and traditional machine learning methods - SVM and Adaboost. We proposed two distinct deep learning models - i CNN Word - Glove and ii Domain phrase attention-based hierarchical recurrent neural network DPA-HNN for synthesizing information on pulmonary emboli PE from over 7370 clinical thoracic computed tomography CT free-text radiology reports collected from four major healthcare centers. Our proposed DPA-HNN model encodes domain-dependent phrases into an attention mechanism and represents a radiology report through a hierarchical RNN structure composed of word-level sentence-level and document-level representations. Experimental results suggest that the performance of the deep learning models that are trained on a single institutional dataset are better than rule-based PEFinder on our multi-institutional test sets. The best F1 score for the presence of PE in an adult patient population was 0.99 DPA-HNN and for a pediatrics population was 0.99 HNN which shows that the deep learning models being trained on adult data demonstrated generalizability to pediatrics population with comparable accuracy. Our work suggests feasibility of broader usage of neural network models in automated classification of multi-institutional imaging text reports for a variety of applications including evaluation of imaging utilization imaging yield clinical decision support tools and as part of automated classification of large corpus for medical imaging deep learning work. Comparative effectiveness of convolutional neural network CNN and recurrent neural network RNN architectures for radiology text report classification.
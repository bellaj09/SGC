We perform an extensive study of the performance of different classification approaches on twenty-five datasets fourteen image datasets and eleven UCI data mining datasets. The aim is to find General-Purpose GP heterogeneous ensembles requiring little to no parameter tuning that perform competitively across multiple datasets. The state-of-the-art classifiers examined in this study include the support vector machine Gaussian process classifiers random subspace of adaboost random subspace of rotation boosting and deep learning classifiers. We demonstrate that a heterogeneous ensemble based on the simple fusion by sum rule of different classifiers performs consistently well across all twenty-five datasets. The most important result of our investigation is demonstrating that some very recent approaches including the heterogeneous ensemble we propose in this paper are capable of outperforming an SVM classifier implemented with LibSVM even when both kernel selection and SVM parameters are carefully tuned for each dataset. Toward a General-Purpose Heterogeneous Ensemble for Pattern Classification.
Restricted Boltzmann machines RBMs which apply graphical models to learning probability distribution over a set of inputs have attracted much attention recently since being proposed as building blocks of multi-layer learning systems called deep belief networks DBNs. Note that temperature is a key factor of the Boltzmann distribution that RBMs originate from. However none of existing schemes have considered the impact of temperature in the graphical model of DBNs. In this work we propose temperature based restricted Boltzmann machines TRBMs which reveals that temperature is an essential parameter controlling the selectivity of the firing neurons in the hidden layers. We theoretically prove that the effect of temperature can be adjusted by setting the parameter of the sharpness of the logistic function in the proposed TRBMs. The performance of RBMs can be improved by adjusting the temperature parameter of TRBMs. This work provides a comprehensive insights into the deep belief networks and deep learning architectures from a physical point of view. Temperature based Restricted Boltzmann Machines.
Understanding navigating and performing goal-oriented actions in Mixed Reality MR environments is a challenging task and requires adequate information conveyance about the location of all virtual objects in a scene. Current Head-Mounted Displays HMDs have a limited field-of-view where augmented objects may be displayed. Furthermore complex MR environments may be comprised of a large number of objects which can be distributed in the extended surrounding space of the user. This paper presents two novel techniques for visually guiding the attention of users towards out-of-view objects in HMD-based MR: the 3D Radar and the Mirror Ball. We evaluate our approaches against existing techniques during three different object collection scenarios which simulate real-world exploratory and goal-oriented visual search tasks. To better understand how the different visualizations guide the attention of users we analyzed the head rotation data for all techniques and introduce a novel method to evaluate and classify head rotation trajectories. Our findings provide supporting evidence that the type of visual guidance technique impacts the way users search for virtual objects in MR. Towards Efficient Visual Guidance in Limited Field-of-View Head-Mounted Displays.
Visual and vestibular signals are the primary sources of sensory information for self-motion. Conflict among these signals can be seriously debilitating resulting in vertigo 1 inappropriate postural responses 2 and motion simulator or cyber sickness 3-8. Despite this significance the mechanisms mediating conflict detection are poorly understood. Here we model conflict detection simply as crossmodal discrimination with benchmark performance limited by variabilities of the signals being compared. In a series of psychophysical experiments conducted in a virtual reality motion simulator we measure these variabilities and assess conflict detection relative to this benchmark. We also examine the impact of eye movements on visual-vestibular conflict detection. In one condition observers fixate a point that is stationary in the simulated visual environment by rotating the eyes opposite head rotation thereby nulling retinal image motion. In another condition eye movement is artificially minimized via fixation of a head-fixed fixation point thereby maximizing retinal image motion. Visual-vestibular integration performance is also measured similar to previous studies 9-12. We observe that there is a tradeoff between integration and conflict detection that is mediated by eye movements. Minimizing eye movements by fixating a head-fixed target leads to optimal integration but highly impaired conflict detection. Minimizing retinal motion by fixating a scene-fixed target improves conflict detection at the cost of impaired integration performance. The common tendency to fixate scene-fixed targets during self-motion 13 may indicate that conflict detection is typically a higher priority than the increase in precision of self-motion estimation that is obtained through integration. Visual-Vestibular Conflict Detection Depends on Fixation.
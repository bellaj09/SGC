A fundamental operation in many vision tasks including motion understanding stereopsis visual odometry or invariant recognition is establishing correspondences between images or between images and data from other modalities. Recently there has been increasing interest in learning to infer correspondences from data using relational spatiotemporal and bilinear variants of deep learning methods. These methods use multiplicative interactions between pixels or between features to represent correlation patterns across multiple images. In this paper we review the recent work on relational feature learning and we provide an analysis of the role that multiplicative interactions play in learning to encode relations. We also discuss how square-pooling and complex cell models can be viewed as a way to represent multiplicative interactions and thereby as a way to encode relations. Learning to relate images.
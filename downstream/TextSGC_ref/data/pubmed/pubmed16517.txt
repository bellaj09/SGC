Most of the current state-of-the-art methods for tumor segmentation are based on machine learning models trained manually on segmented images. This type of training data is particularly costly as manual delineation of tumors is not only time-consuming but also requires medical expertise. On the other hand images with a provided global label indicating presence or absence of a tumor are less informative but can be obtained at a substantially lower cost. We propose to use both types of training data fully annotated and weakly annotated to train a deep learning model for segmentation. The idea of our approach is to extend segmentation networks with an additional branch performing image-level classification. The model is jointly trained for segmentation and classification tasks to exploit the information contained in weakly annotated images while preventing the network from learning features that are irrelevant for the segmentation task. We evaluate our method on the challenging task of brain tumor segmentation in magnetic resonance images from the Brain Tumor Segmentation 2018 Challenge. We show that the proposed approach provides a significant improvement in segmentation performance compared to the standard supervised learning. The observed improvement is proportional to the ratio between weakly annotated and fully annotated images available for training. Deep learning with mixed supervision for brain tumor segmentation.
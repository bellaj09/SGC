The ability to provide sensory feedback is desired to enhance the functionality of neuroprosthetics. Somatosensory feedback provides closed-loop control to the motor system which is lacking in feedforward neuroprosthetics. In the case of existing somatosensory function a template of the natural response can be used as a template of desired response elicited by electrical microstimulation. In the case of no initial training data microstimulation parameters that produce responses close to the template must be selected in an online manner. We propose using reinforcement learning as a framework to balance the exploration of the parameter space and the continued selection of promising parameters for further stimulation. This approach avoids an explicit model of the neural response from stimulation. We explore a preliminary architecture--treating the task as a k-armed bandit--using offline data recorded for natural touch and thalamic microstimulation and we examine the methods efficiency in exploring the parameter space while concentrating on promising parameter forms. The best matching stimulation parameters from k = 68 different forms are selected by the reinforcement learning algorithm consistently after 334 realizations. Optimizing microstimulation using a reinforcement learning framework.
In this paper we propose to detect the running applications in a server by classifying the observed power consumption series for the purpose of data center energy consumption monitoring and analysis. Time series classification problem has been extensively studied with various distance measurements developed; also recently the deep learning-based sequence models have been proved to be promising. In this paper we propose a novel distance measurement and build a time series classification algorithm hybridizing nearest neighbor and long short term memory LSTM neural network. More specifically first we propose a new distance measurement termed as local time warping LTW which utilizes a user-specified index set for local warping and is designed to be noncommutative and nondynamic programming. Second we hybridize the 1-nearest neighbor 1NN-LTW and LSTM together. In particular we combine the prediction probability vector of 1NN-LTW and LSTM to determine the label of the test cases. Finally using the power consumption data from a real data center we show that the proposed LTW can improve the classification accuracy of dynamic time warping DTW from about 84% to 90%. Our experimental results prove that the proposed LTW is competitive on our data set compared with existed DTW variants and its noncommutative feature is indeed beneficial. We also test a linear version of LTW and find out that it can perform similar to state-of-the-art DTW-based method while it runs as fast as the linear runtime lower bound methods like LB_Keogh for our problem. With the hybrid algorithm for the power series classification task we achieve an accuracy up to about 93%. Our research can inspire more studies on time series distance measurement and the hybrid of the deep learning models with other traditional models. Can We Speculate Running Application With Server Power Consumption Trace?
An extensive study on the in-loop filter has been proposed for a high efficiency video coding HEVC standard to reduce compression artifacts thus improving coding efficiency. However in the existing approaches the in-loop filter is always applied to each single frame without exploiting the content correlation among multiple frames. In this paper we propose a multi-frame in-loop filter MIF for HEVC which enhances the visual quality of each encoded frame by leveraging its adjacent frames. Specifically we first construct a large-scale database containing encoded frames and their corresponding raw frames of a variety of content which can be used to learn the in-loop filter in HEVC. Furthermore we find that there usually exist a number of reference frames of higher quality and of similar content for an encoded frame. Accordingly a reference frame selector RFS is designed to identify these frames. Then a deep neural network for MIF known as MIF-Net is developed to enhance the quality of each encoded frame by utilizing the spatial information of this frame and the temporal information of its neighboring higher-quality frames. The MIF-Net is built on the recently developed DenseNet benefiting from its improved generalization capacity and computational efficiency. In addition a novel block-adaptive convolutional layer is designed and applied in the MIF-Net for handling the artifacts influenced by coding tree unit CTU structure in HEVC. Extensive experiments show that our MIF approach achieves on average 11.621% saving of the Bjntegaard delta bit-rate BD-BR on the standard test set significantly outperforming the standard in-loop filter in HEVC and other state-of-the-art approaches. A Deep Learning Approach for Multi-Frame In-Loop Filter of HEVC.
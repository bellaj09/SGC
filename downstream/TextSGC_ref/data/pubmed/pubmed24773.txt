Brain-computer interfaces provide a means for controlling a device by brain activity alone. One major drawback of noninvasive BCIs is their low information transfer rate obstructing a wider deployment outside the lab. BCIs based on codebook visually evoked potentials cVEP outperform all other state-of-the-art systems in that regard. Previous work investigated cVEPs for spelling applications. We present the first cVEP-based BCI for use in real-world settings to accomplish everyday tasks such as navigation or action selection. To this end we developed and evaluated a cVEP-based on-line BCI that controls a virtual agent in a simulated but realistic 3-D kitchen scenario. We show that cVEPs can be reliably triggered with stimuli in less restricted presentation schemes such as on dynamic changing backgrounds. We introduce a novel dynamic repetition algorithm that allows for optimizing the balance between accuracy and speed individually for each user. Using these novel mechanisms in a 12-command cVEP-BCI in the 3-D simulation results in ITRs of 50 bits/min on average and 68 bits/min maximum. Thus this work supports the notion of cVEP-BCIs as a particular fast and robust approach suitable for real-world use. Using a cVEP-Based Brain-Computer Interface to Control a Virtual Agent.
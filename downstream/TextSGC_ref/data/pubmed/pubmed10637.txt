This paper presents a neural system-based technique for segmenting short impaired speech utterances into silent unvoiced and voiced sections. Moreover the proposed technique identifies those points of the voiced speech where the spectrum becomes steady. The resulting technique thus aims at detecting that limited section of the speech which contains the information about the potential impairment of the speech. This section is of interest to the speech therapist as it corresponds to the possibly incorrect movements of speech organs lower lip and tongue with respect to the vocal tract. Two segmentation models to detect and identify the various sections of the disordered impaired speech signals have been developed and compared. The first makes use of a combination of four artificial neural networks. The second is based on a support vector machine SVM. The SVM has been trained by means of an ad hoc nested algorithm whose outer layer is a metaheuristic while the inner layer is a convex optimization algorithm. Several metaheuristics have been tested and compared leading to the conclusion that some variants of the compact differential evolution CDE algorithm appears to be well-suited to address this problem. Numerical results show that the SVM model with a radial basis function is capable of effective detection of the portion of speech that is of interest to a therapist. The best performance has been achieved when the system is trained by the nested algorithm whose outer layer is hybrid-population-based/CDE. A population-based approach displays the best performance for the isolation of silence/noise sections and the detection of unvoiced sections. On the other hand a compact approach appears to be clearly well-suited to detect the beginning of the steady state of the voiced signal. Both the proposed segmentation models display outperformed two modern segmentation techniques based on Gaussian mixture model and deep learning. Towards Artificial Speech Therapy: A Neural System for Impaired Speech Segmentation.
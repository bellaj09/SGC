We present a framework which we call Molecule Deep Q-Networks MolDQN for molecule optimization by combining domain knowledge of chemistry and state-of-the-art reinforcement learning techniques double Q-learning and randomized value functions. We directly define modifications on molecules thereby ensuring 100% chemical validity. Further we operate without pre-training on any dataset to avoid possible bias from the choice of that set. MolDQN achieves comparable or better performance against several other recently published algorithms for benchmark molecular optimization tasks. However we also argue that many of these tasks are not representative of real optimization problems in drug discovery. Inspired by problems faced during medicinal chemistry lead optimization we extend our model with multi-objective reinforcement learning which maximizes drug-likeness while maintaining similarity to the original molecule. We further show the path through chemical space to achieve optimization for a molecule to understand how the model works. Optimization of Molecules via Deep Reinforcement Learning.
Automation of agricultural processes requires systems that can accurately detect and classify produce in real industrial environments that include variation in fruit appearance due to illumination occlusion seasons weather conditions etc. In this paper we combine a visual processing approach inspired by colour-opponent theory in humans with recent advancements in one-stage deep learning networks to accurately rapidly and robustly detect ripe soft fruits strawberries in real industrial settings and using standard RGB camera input. The resultant system was tested on an existent data-set captured in controlled conditions as well our new real-world data-set captured on a real strawberry farm over two months. We utilise F 1 score the harmonic mean of precision and recall to show our system matches the state-of-the-art detection accuracy  F 1 : 0.793 vs. 0.799 in controlled conditions; has greater generalisation and robustness to variation of spatial parameters camera viewpoint in the real-world data-set  F 1 : 0.744; and at a fraction of the computational cost allowing classification at almost 30fps. We propose that the L*a*b*Fruits system addresses some of the most pressing limitations of current fruit detection systems and is well-suited to application in areas such as yield forecasting and harvesting. Beyond the target application in agriculture this work also provides a proof-of-principle whereby increased performance is achieved through analysis of the domain data capturing features at the input level rather than simply increasing model complexity. L*a*b*Fruits: A Rapid and Robust Outdoor Fruit Detection System Combining Bio-Inspired Features with One-Stage Deep Learning Networks.
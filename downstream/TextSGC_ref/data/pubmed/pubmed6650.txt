Visual saliency is a fundamental problem in both cognitive and computational sciences including computer vision. In this paper we discover that a high-quality visual saliency model can be learned from multiscale features extracted using deep convolutional neural networks CNNs which have had many successes in visual recognition tasks. For learning such saliency models we introduce a neural network architecture which has fully connected layers on top of CNNs responsible for feature extraction at three different scales. The penultimate layer of our neural network has been confirmed to be a discriminative high-level feature vector for saliency detection which we call deep contrast feature. To generate a more robust feature we integrate handcrafted low-level features with our deep contrast feature. To promote further research and evaluation of visual saliency models we also construct a new large database of 4447 challenging images and their pixelwise saliency annotations. Experimental results demonstrate that our proposed method is capable of achieving the state-of-the-art performance on all public benchmarks improving the F-measure by 6.12% and 10% respectively on the DUT-OMRON data set and our new data set HKU-IS and lowering the mean absolute error by 9% and 35.3% respectively on these two data sets. Visual Saliency Detection Based on Multiscale Deep CNN Features.
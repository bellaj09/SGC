Availability of accurate land cover information over large areas is essential to the global environment sustainability; digital classification using medium-resolution remote sensing data would provide an effective method to generate the required land cover information. However low accuracy of existing per-pixel based classification methods for medium-resolution data is a fundamental limiting factor. While convolutional neural networks CNNs with deep layers have achieved unprecedented improvements in object recognition applications that rely on fine image structures they cannot be applied directly to medium-resolution data due to lack of such fine structures. In this paper considering the spatial relation of a pixel to its neighborhood we propose a new deep patch-based CNN system tailored for medium-resolution remote sensing data. The system is designed by incorporating distinctive characteristics of medium-resolution data; in particular the system computes patch-based samples from multidimensional top of atmosphere reflectance data. With a test site from the Florida Everglades area with a size of 771 square kilometers the proposed new system has outperformed pixel-based neural network pixel-based CNN and patch-based neural network by 24.36% 24.23% and 11.52% respectively in overall classification accuracy. By combining the proposed deep CNN and the huge collection of medium-resolution remote sensing data we believe that much more accurate land cover datasets can be produced over large areas. A patch-based convolutional neural network for remote sensing image classification.
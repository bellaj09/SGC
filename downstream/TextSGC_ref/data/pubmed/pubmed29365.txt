Word production begins with high-Gamma automatic linguistic processing functions followed by speech motor planning and articulation. Phonetic properties are processed in both linguistic and motor stages of word production. Four phonetically dissimilar phonemic structures "BA" "FO" "LE" and "RY" were chosen as covert speech tasks. Ten neurologically healthy volunteers with the age range of 21-33 participated in this experiment. Participants were asked to covertly speak a phonemic structure when they heard an auditory cue. EEG was recorded with 64 electrodes at 2048 samples/s. Initially one-second trials were used which contained linguistic and motor imagery activities. The four-class true positive rate was calculated. In the next stage 312\xa0ms trials were used to exclude covert articulation from analysis. By eliminating the covert articulation stage the four-class grand average classification accuracy dropped from 96.4% to 94.5%. The most valuable features emerge after Auditory cue recognition ~100\xa0ms post onset and within the 70-128\xa0Hz frequency range. The most significant identified brain regions were the Prefrontal Cortex linked to stimulus driven executive control Wernicke\s area linked to Phonological code retrieval the right IFG and Broca\s area linked to syllabification. Alpha and Beta band oscillations associated with motor imagery do not contain enough information to fully reflect the complexity of speech movements. Over 90% of the most class-dependent features were in the 30-128\xa0Hz range even during the covert articulation stage. As a result compared to linguistic functions the contribution of motor imagery of articulation in class separability of covert speech tasks from EEG data is negligible. The Relative Contribution of High-Gamma Linguistic Processing Stages of Word Production and Motor Imagery of Articulation in Class Separability of Covert Speech Tasks in EEG Data.
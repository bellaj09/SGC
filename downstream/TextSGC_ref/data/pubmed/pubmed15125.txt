In this paper we propose an efficient inter prediction scheme by introducing the deep virtual reference frame VRF which serves better reference in the temporal redundancy removal process of video coding. In particular the high quality VRF is generated with the deep learning-based frame rate up conversion FRUC algorithm from two reconstructed bi-directional frames which is subsequently incorporated into the reference list serving as the high quality reference. Moreover to alleviate the compression artifacts of VRF we develop a convolutional neural network CNN-based enhancement model to further improve its quality. To facilitate better utilization of the VRF a CTU level coding mode termed as direct virtual reference frame DVRF is devised which achieves better trade-off between compression performance and complexity. The proposed scheme is integrated into HM-16.6 and JEM-7.1 software platforms and the simulation results under random access RA configuration demonstrate significant superiority of the proposed method. When adding VRF to RPS more than 6% average BD-rate gain is achieved for HEVC test sequences on HM-16.6 and 0.8% BD-rate gain is observed based on JEM-7.1 software. Regarding the DVRF mode 3.6% bitrate saving is achieved on HM-16.6 with the computational complexity effectively reduced. Enhanced Motion-Compensated Video Coding With Deep Virtual Reference Frame Generation.
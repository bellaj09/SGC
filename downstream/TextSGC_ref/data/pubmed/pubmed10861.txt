"There is an essential requirement to support people with speech and communication disabilities. A brain-computer interface using electroencephalography EEG is applied to satisfy this requirement. A number of research studies to recognize brain signals using machine learning and deep neural networks DNNs have been performed to increase the brain signal detection rate yet there are several defects and limitations in the techniques. Among them is the use in specific circumstances of machine learning. On the one hand DNNs extract the features well and automatically. On the other hand their use results in overfitting and vanishing problems. Consequently in this research a deep network is designed on the basis of an autoencoder neural Turing machine DN-AE-NTM to resolve the problems by the use of NTM external memory. In addition the DN-AE-NTM copes with all kinds of signals with high detection rates. The data were collected by P300 EEG devices from several individuals under the same conditions. During the test each individual was requested to skim images with one to six labels and focus on only one of the images. Not to focus on some images is analogous to producing unimportant information in the individuals brain which provides unfamiliar signals. Besides the main P300 EEG dataset EEG recordings of individuals with alcoholism and control individuals and the EEGMMIDB MNIST and ORL datasets were implemented and tested. The proposed DN-AE-NTM method classifies data with an average detection rate of 97.5% 95% 98% 99.4% and 99.1% respectively in situations where the signals are noisy so that only 20% of the data are reliable and include useful information." Recognition of words from brain-generated signals of speech-impaired people: Application of autoencoders as a neural Turing machine controller in deep neural networks.
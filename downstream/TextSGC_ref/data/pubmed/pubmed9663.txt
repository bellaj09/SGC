Learning effective representations that exhibit semantic content is crucial to image retrieval applications. Recent advances in deep learning have made significant improvements in performance on a number of visual recognition tasks. Studies have also revealed that visual features extracted from a deep network learned on a large-scale image data set e.g. ImageNet for classification are generic and perform well on new recognition tasks in different domains. Nevertheless when applied to image retrieval such deep representations do not attain performance as impressive as used for classification. This is mainly because the deep features are optimized for classification rather than for the desired retrieval task. We introduce the cross-batch reference CBR a novel training mechanism that enables the optimization of deep networks with a retrieval criterion. With the CBR the networks leverage both the samples in a single minibatch and the samples in the others for weight updates enhancing the stochastic gradient descent SGD training by enabling interbatch information passing. This interbatch communication is implemented as a cross-batch retrieval process in which the networks are trained to maximize the mean average precision mAP that is a popular performance measure in retrieval. Maximizing the cross-batch mAP is equivalent to centralizing the samples relevant to each other in the feature space and separating the samples irrelevant to each other. The learned features can discriminate between relevant and irrelevant samples and thus are suitable for retrieval. To circumvent the discrete nondifferentiable mAP maximization we derive an approximate differentiable lower bound that can be easily optimized in deep networks. Furthermore the mAP loss can be used alone or with a classification loss. Experiments on several data sets demonstrate that our CBR learning provides favorable performance validating its effectiveness. Cross-Batch Reference Learning for Deep Retrieval.
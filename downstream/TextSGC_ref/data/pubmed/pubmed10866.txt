The automatic recognition of human falls is currently an important topic of research for the computer vision and artificial intelligence communities. In image analysis it is common to use a vision-based approach for fall detection and classification systems due to the recent exponential increase in the use of cameras. Moreover deep learning techniques have revolutionized vision-based approaches. These techniques are considered robust and reliable solutions for detection and classification problems mostly using convolutional neural networks CNNs. Recently our research group released a public multimodal dataset for fall detection called the UP-Fall Detection dataset and studies on modality approaches for fall detection and classification are required. Focusing only on a vision-based approach in this paper we present a fall detection system based on a 2D CNN inference method and multiple cameras. This approach analyzes images in fixed time windows and extracts features using an optical flow method that obtains information on the relative motion between two consecutive images. We tested this approach on our public dataset and the results showed that our proposed multi-vision-based approach detects human falls and achieves an accuracy of 95.64% compared to state-of-the-art methods with a simple CNN network architecture. A vision-based approach for fall detection using multiple cameras and convolutional neural networks: A case study using the UP-Fall detection dataset.
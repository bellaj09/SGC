In humans efficient recognition of written symbols is thought to rely on a hierarchical processing system where simple features are progressively combined into more abstract high-level representations. Here we present a computational model of Persian character recognition based on deep belief networks where increasingly more complex visual features emerge in a completely unsupervised manner by fitting a hierarchical generative model to the sensory data. Crucially high-level internal representations emerging from unsupervised deep learning can be easily read out by a linear classifier achieving state-of-the-art recognition accuracy. Furthermore we tested the hypothesis that handwritten digits and letters share many common visual features: A generative model that captures the statistical structure of the letters distribution should therefore also support the recognition of written digits. To this aim deep networks trained on Persian letters were used to build high-level representations of Persian digits which were indeed read out with high accuracy. Our simulations show that complex visual features such as those mediating the identification of Persian symbols can emerge from unsupervised learning in multilayered neural networks and can support knowledge transfer across related domains. Learning representation hierarchies by sharing visual features: a computational investigation of Persian character recognition with unsupervised deep learning.
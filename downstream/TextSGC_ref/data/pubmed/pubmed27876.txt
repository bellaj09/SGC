The auditory Brain-Computer Interface BCI using electroencephalograms EEG is a subject of intensive study. As a cue auditory BCIs can deal with many of the characteristics of stimuli such as tone pitch and voices. Spatial information on auditory stimuli also provides useful information for a BCI. However in a portable system virtual auditory stimuli have to be presented spatially through earphones or headphones instead of loudspeakers. We investigated the possibility of an auditory BCI using the out-of-head sound localization technique which enables us to present virtual auditory stimuli to users from any direction through earphones. The feasibility of a BCI using this technique was evaluated in an EEG oddball experiment and offline analysis. A virtual auditory stimulus was presented to the subject from one of six directions. Using a support vector machine we were able to classify whether the subject attended the direction of a presented stimulus from EEG signals. The mean accuracy across subjects was 70.0% in the single-trial classification. When we used trial-averaged EEG signals as inputs to the classifier the mean accuracy across seven subjects reached 89.5% for 10-trial averaging. Further analysis showed that the P300 event-related potential responses from 200 to 500 ms in central and posterior regions of the brain contributed to the classification. In comparison with the results obtained from a loudspeaker experiment we confirmed that stimulus presentation by out-of-head sound localization achieved similar event-related potential responses and classification performances. These results suggest that out-of-head sound localization enables us to provide a high-performance and loudspeaker-less portable BCI system. Estimating the intended sound direction of the user: toward an auditory brain-computer interface using out-of-head sound localization.
The reconstruction of 4D images from 2D navigator and data slices requires sufficient observations per motion state to avoid blurred images and motion artifacts between slices. Especially images from rare motion states like deep inhalations during free-breathing suffer from too few observations. To address this problem we propose to actively generate more suitable images instead of only selecting from the available images. The method is based on learning the relationship between navigator and data-slice motion by linear regression after dimensionality reduction. This can then be used to predict new data slices for a given navigator by warping existing data slices by their predicted displacement field. The method was evaluated for 4D-MRIs of the liver under free-breathing where sliding boundaries pose an additional challenge for image registration. Leave-one-out tests for five short sequences of ten volunteers showed that the proposed prediction method improved on average the residual mean 95% motion between the ground truth and predicted data slice from 0.9mm 1.9mm to 0.8mm 1.6mm in comparison to the best selection method. The approach was particularly suited for unusual motion states where the mean error was reduced by 40% 2.2mm vs. 1.3mm. Improved reconstruction of 4D-MR images by motion predictions.
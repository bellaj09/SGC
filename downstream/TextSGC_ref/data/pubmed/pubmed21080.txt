This research explores different ways to use features of one\s own body for interacting with computers. Such "body-based" interfaces may find good uses in wearable computing or virtual reality systems as part of a 3D multi-modal interface in the future freeing the user from holding interaction devices. Four types of body-based interfaces have been identified: Body-inspired metaphor BIM; Body-as-interaction-surface BAIS; Mixed mode MM; and Object mapping OM. These four body-based interfaces were applied to a few different applications and associated tasks and were tested for their performance and preference. It was generally found that among the four the BIM exhibited low error rates but produced relatively longer task completion times and significant fatigue. The BAIS method had the contrasting character of higher error rates but shorter task completion times and lower intuitiveness. The OM method exhibited high error rates longer completion times and much fatigue. Overall the MM was superior in terms of both performance and preference as it combined the merits of the above three methods. Thus it is expected for applications with many associated tasks a careful division of tasks among those that have natural semantic links to body parts and those that do not is necessary to design the most performing body-based interface. Body-based interfaces.
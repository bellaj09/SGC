Human behavior modeling is a key component in application domains such as healthcare and social behavior research. In addition to accurate prediction having the capacity to understand the roles of human behavior determinants and to provide explanations for the predicted behaviors is also important. Having this capacity increases trust in the systems and the likelihood that the systems actually will be adopted thus driving engagement and loyalty. However most prediction models do not provide explanations for the behaviors they predict. In this paper we study the research problem human behavior prediction with explanations for healthcare intervention systems in health social networks. We propose an ontology-based deep learning model ORBM+ for human behavior prediction over undirected and nodes-attributed graphs. We first propose a bottom-up algorithm to learn the user representation from health ontologies. Then the user representation is utilized to incorporate self-motivation social influences and environmental events together in a human behavior prediction model which extends a well-known deep learning method the Restricted Boltzmann Machine. ORBM+ not only predicts human behaviors accurately but also it generates explanations for each predicted behavior. Experiments conducted on both real and synthetic health social networks have shown the tremendous effectiveness of our approach compared with conventional methods. Ontology-based Deep Learning for Human Behavior Prediction with Explanations in Health Social Networks.
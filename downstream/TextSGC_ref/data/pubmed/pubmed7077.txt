Recurrent neural network RNN and Long Short-term Memory LSTM networks are the common go-to architecture for exploiting sequential information where the output is dependent on a sequence of inputs. However in most considered problems the dependencies typically lie in the latent domain which may not be suitable for applications involving the prediction of a step-wise transformation sequence that is dependent on the previous states only in the visible domain with a known terminal state. We propose a hybrid architecture of convolution neural networks CNN and stacked autoencoders SAE to learn a sequence of causal actions that nonlinearly transform an input visual pattern or distribution into a target visual pattern or distribution with the same support and demonstrated its practicality in a real-world engineering problem involving the physics of fluids. We solved a high-dimensional one-to-many inverse mapping problem concerning microfluidic flow sculpting where the use of deep learning methods as an inverse map is very seldom explored. This work serves as a fruitful use-case to applied scientists and engineers in how deep learning can be beneficial as a solution for high-dimensional physical problems and potentially opening doors to impactful advance in fields such as material sciences and medical biology where multistep topological transformations is a key element. A deep learning framework for causal shape transformation.
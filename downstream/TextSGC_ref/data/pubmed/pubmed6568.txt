Person re-identification re-id aims to match people across non-overlapping camera views in a public space. This is a challenging problem because the people captured in surveillance videos often wear similar clothing. Consequently the differences in their appearance are typically subtle and only detectable at particular locations and scales. In this paper we propose a deep re-id network MuDeep that is composed of two novel types of layers - a multi-scale deep learning layer and a leader-based attention learning layer. Specifically the former learns deep discriminative feature representations at different scales while the latter utilizes the information from multiple scales to lead and determine the optimal weightings for each scale. The importance of different spatial locations for extracting discriminative features is learned explicitly via our leader-based attention learning layer. Extensive experiments are carried out to demonstrate that the proposed MuDeep outperforms the state-of-the-art on a number of benchmarks and has a better generalization ability under a domain generalization setting. Leader-Based Multi-Scale Attention Deep Architecture for Person Re-Identification.
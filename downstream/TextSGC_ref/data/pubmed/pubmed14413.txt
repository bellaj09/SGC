Developments in deep learning have seen the use of layerwise unsupervised learning combined with supervised learning for fine-tuning. With this layerwise approach a deep network can be seen as a more modular system that lends itself well to learning representations. In this paper we investigate whether such modularity can be useful to the insertion of background knowledge into deep networks whether it can improve learning performance when it is available and to the extraction of knowledge from trained deep networks and whether it can offer a better understanding of the representations learned by such networks. To this end we use a simple symbolic language-a set of logical rules that we call confidence rules-and show that it is suitable for the representation of quantitative reasoning in deep networks. We show by knowledge extraction that confidence rules can offer a low-cost representation for layerwise networks or restricted Boltzmann machines. We also show that layerwise extraction can produce an improvement in the accuracy of deep belief networks. Furthermore the proposed symbolic characterization of deep networks provides a novel method for the insertion of prior knowledge and training of deep networks. With the use of this method a deep neural-symbolic system is proposed and evaluated with the experimental results indicating that modularity through the use of confidence rules and knowledge insertion can be beneficial to network performance. Deep Logic Networks: Inserting and Extracting Knowledge From Deep Belief Networks.
Speech is our most natural form of communication and even though functional Near Infrared Spectroscopy fNIRS is an increasingly popular modality for Brain Computer Interfaces BCIs there are to the best of our knowledge no previous studies on speech related tasks in fNIRS-based BCI. We conducted experiments on 5 subjects producing audible silently uttered and imagined speech or do not produce any speech. For each of these speaking modes we recorded fNIRS signals from the subjects performing these tasks and distinguish segments containing speech from those not containing speech solely based on the fNIRS signals. Accuracies between 69% and 88% were achieved using support vector machines and a Mutual Information based Best Individual Feature approach. We are also able to discriminate the three speaking modes with 61% classification accuracy. We thereby demonstrate that speech is a very promising paradigm for fNIRS based BCI as classification accuracies compare very favorably to those achieved in motor imagery BCIs with fNIRS. Speaking mode recognition from functional Near Infrared Spectroscopy.
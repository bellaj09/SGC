"Since there are complex geometric variations with 3D shapes extracting efficient 3D shape features is one of the most challenging tasks in shape matching and retrieval. In this paper we propose a deep shape descriptor by learning shape distributions at different diffusion time via a progressive shape-distribution-encoder PSDE. First we develop a shape distribution representation with the kernel density estimator to characterize the intrinsic geometry structures of 3D shapes. Then we propose to learn a deep shape feature through an unsupervised PSDE. Specially the unsupervised PSDE aims at modeling the complex non-linear transform of the estimated shape distributions between consecutive diffusion time. In order to characterize the intrinsic structures of 3D shapes more efficiently we stack multiple PSDEs to form a network structure. Finally we concatenate all neurons in the middle hidden layers of the unsupervised PSDE network to form an unsupervised shape descriptor for retrieval. Furthermore by imposing an additional constraint on the outputs of all hidden layers we propose a supervised PSDE to form a supervised shape descriptor. For each hidden layer the similarity between a pair of outputs from the same class is as large as possible and the similarity between a pair of outputs from different classes is as small as possible. The proposed method is evaluated on three benchmark 3D shape data sets with large geometric variations i.e. McGill SHREC10 ShapeGoogle and SHREC14 Human data sets and the experimental results demonstrate the superiority of the proposed method to the existing approaches." Progressive Shape-Distribution-Encoder for Learning 3D Shape Representation.
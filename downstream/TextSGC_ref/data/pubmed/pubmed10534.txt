Visual textures have played a key role in image understanding because they convey important semantics of images and because texture representations that pool local image descriptors in an orderless manner have had a tremendous impact in diverse applications. In this paper we make several contributions to texture understanding. First instead of focusing on texture instance and material category recognition we propose a human-interpretable vocabulary of texture attributes to describe common texture patterns complemented by a new describable texture dataset for benchmarking. Second we look at the problem of recognizing materials and texture attributes in realistic imaging conditions including when textures appear in clutter developing corresponding benchmarks on top of the recently proposed OpenSurfaces dataset. Third we revisit classic texture represenations including bag-of-visual-words and the Fisher vectors in the context of deep learning and show that these have excellent efficiency and generalization properties if the convolutional layers of a deep model are used as filter banks. We obtain in this manner state-of-the-art performance in numerous datasets well beyond textures an efficient method to apply deep features to image regions as well as benefit in transferring features from one domain to another. Deep Filter Banks for Texture Recognition Description and Segmentation.
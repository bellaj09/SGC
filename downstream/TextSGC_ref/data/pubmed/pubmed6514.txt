"This paper presents a hierarchical deep reinforcement learning DRL method for the scheduling of energy consumptions of smart home appliances and distributed energy resources DERs including an energy storage system ESS and an electric vehicle EV. Compared to Q-learning algorithms based on a discrete action space the novelty of the proposed approach is that the energy consumptions of home appliances and DERs are scheduled in a continuous action space using an actor-critic-based DRL method. To this end a two-level DRL framework is proposed where home appliances are scheduled at the first level according to the consumers preferred appliance scheduling and comfort level while the charging and discharging schedules of ESS and EV are calculated at the second level using the optimal solution from the first level along with the consumer environmental characteristics. A simulation study is performed in a single home with an air conditioner a washing machine a rooftop solar photovoltaic system an ESS and an EV under a time-of-use pricing. Numerical examples under different weather conditions weekday/weekend and driving patterns of the EV confirm the effectiveness of the proposed approach in terms of total cost of electricity state of energy of the ESS and EV and consumer preference." Energy Management of Smart Home with Home Appliances Energy Storage System and Electric Vehicle: A Hierarchical Deep Reinforcement Learning Approach.
Eating behavior can have an important effect on and be correlated with obesity and eating disorders. Eating behavior is usually estimated through self-reporting measures despite their limitations in reliability based on ease of collection and analysis. A better and widely used alternative is the objective analysis of eating during meals based on human annotations of in-meal behavioral events e.g. bites. However this methodology is time-consuming and often affected by human error limiting its scalability and cost-effectiveness for large-scale research. To remedy the latter a novel "Rapid Automatic Bite Detection" RABiD algorithm that extracts and processes skeletal features from videos was trained in a video meal dataset 59 individuals; 85 meals; three different foods to automatically measure meal duration and bites. In these settings RABiD achieved near perfect agreement between algorithmic and human annotations Cohen\s kappa  = 0.894; F1-score: 0.948. Moreover RABiD was used to analyze an independent eating behavior experiment 18 female participants; 45 meals; three different foods and results showed excellent correlation between algorithmic and human annotations. The analyses revealed that despite the changes in food hash vs. meatballs the total meal duration remained the same while the number of bites were significantly reduced. Finally a descriptive meal-progress analysis revealed that different types of food affect bite frequency although overall bite patterns remain similar the outcomes were the same for RABiD and manual. Subjects took bites more frequently at the beginning and the end of meals but were slower in-between. On a methodological level RABiD offers a valid fully automatic alternative to human meal-video annotations for the experimental analysis of human eating behavior at a fraction of the cost and the required time without any loss of information and data fidelity. Validation of a Deep Learning System for the Full Automation of Bite and Meal Duration Analysis of Experimental Meal Videos.
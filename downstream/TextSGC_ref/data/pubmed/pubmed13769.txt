The purpose of this study is to improve human emotional classification accuracy using a convolution neural networks CNN model and to suggest an overall method to classify emotion based on multimodal data. We improved classification performance by combining electroencephalogram EEG and galvanic skin response GSR signals. GSR signals are preprocessed using by the zero-crossing rate. Sufficient EEG feature extraction can be obtained through CNN. Therefore we propose a suitable CNN model for feature extraction by tuning hyper parameters in convolution filters. The EEG signal is preprocessed prior to convolution by a wavelet transform while considering time and frequency simultaneously. We use a database for emotion analysis using the physiological signals open dataset to verify the proposed process achieving 73.4% accuracy showing significant performance improvement over the current best practice models. Electroencephalography Based Fusion Two-Dimensional 2D-Convolution Neural Networks CNN Model for Emotion Recognition System.
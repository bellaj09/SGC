Multimodal systems are a workaround to enhance the robustness and effectiveness of biometric systems. A proper multimodal dataset is of the utmost importance to build such systems. The literature presents some multimodal datasets although to the best of our knowledge there are no previous studies combining face iris/eye and vital signals such as the Electrocardiogram ECG. Moreover there is no methodology to guide the construction and evaluation of a chimeric dataset. Taking that fact into account we propose to create a chimeric dataset from three modalities in this work: ECG eye and face. Based on the Doddington Zoo criteria we also propose a generic and systematic protocol imposing constraints for the creation of homogeneous chimeric individuals which allow us to perform a fair and reproducible benchmark. Moreover we have proposed a multimodal approach for these modalities based on state-of-the-art deep representations built by convolutional neural networks. We conduct the experiments in the open-world verification mode and on two different scenarios intra-session and inter-session using three modalities from two datasets: CYBHi ECG and FRGC eye and face. Our multimodal approach achieves impressive decidability of 7.20  0.18 yielding an almost perfect verification system i.e. Equal Error Rate EER of 0.20%  0.06 on the intra-session scenario with unknown data. On the inter-session scenario we achieve a decidability of 7.78  0.78 and an EER of 0.06%  0.06. In summary these figures represent a gain of over 28% in decidability and a reduction over 11% of the EER on the intra-session scenario for unknown data compared to the best-known unimodal approach. Besides we achieve an improvement greater than 22% in decidability and an EER reduction over 6% in the inter-session scenario. ChimericalDataset Creation Protocol Based on Doddington Zoo: A Biometric Application with Face Eye and ECG.
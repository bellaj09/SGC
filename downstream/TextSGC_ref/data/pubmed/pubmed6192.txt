We investigate the addition of symmetry and temporal context information to a deep convolutional neural network CNN with the purpose of detecting malignant soft tissue lesions in mammography. We employ a simple linear mapping that takes the location of a mass candidate and maps it to either the contralateral or prior mammogram and regions of interest ROIs are extracted around each location. Two different architectures are subsequently explored: 1\xa0a fusion model employing two datastreams where both ROIs are fed to the network during training and testing and 2\xa0a stagewise approach where a single ROI CNN is trained on the primary image and subsequently used as a feature extractor for both primary and contralateral or prior ROIs. A "shallow" gradient boosted tree classifier is then trained on the concatenation of these features and used to classify the joint representation. The baseline yielded an AUC of 0.87 with confidence interval 0.853 0.893. For the analysis of symmetrical differences the first architecture where both primary and contralateral patches are presented during training obtained an AUC of 0.895 with confidence interval 0.877 0.913 and the second architecture where a new classifier is retrained on the concatenation an AUC of 0.88 with confidence interval 0.859 0.9. We found a significant difference between the first architecture and the baseline at high specificity with Formula: see text. When using the same architectures to analyze temporal change we yielded an AUC of 0.884 with confidence interval 0.865 0.902 for the first architecture and an AUC of 0.879 with confidence interval 0.858 0.898 in the second setting. Although improvements for temporal analysis were consistent they were not found to be significant. The results show our proposed method is promising and we suspect performance can greatly be improved when more temporal data become available. Classifying symmetrical differences and temporal change for the detection of malignant masses in mammography using deep neural networks.
Breast density is widely adopted to reflect the likelihood of early breast cancer development. Existing methods of mammographic density classification either require steps of manual operations or achieve only moderate classification accuracy due to the limited model capacity. In this study we present a radiomics approach based on dilated and attention-guided residual learning for the task of mammographic density classification. The proposed method was instantiated with two datasets one clinical dataset and one publicly available dataset and classification accuracies of 88.7% and 70.0% were obtained respectively. Although the classification accuracy of the public dataset was lower than the clinical dataset which was very likely related to the dataset size our proposed model still achieved a better performance than the naive residual networks and several recently published deep learning-based approaches. Furthermore we designed a multi-stream network architecture specifically targeting at analyzing the multi-view mammograms. Utilizing the clinical dataset we validated that multi-view inputs were beneficial to the breast density classification task with an increase of at least 2.0% in accuracy and the different views lead to different model classification capacities. Our method has a great potential to be further developed and applied in computer-aided diagnosis systems. Multi-View Mammographic Density Classification by Dilated and Attention-Guided Residual Learning.
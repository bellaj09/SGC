The perceptual organization of auditory scenes is a hard but important problem to solve for human listeners. It is thus likely that cues from several modalities are pooled for auditory scene analysis including sensory-motor cues related to the active exploration of the scene. We previously reported a strong effect of head motion on auditory streaming. Streaming refers to an experimental paradigm where listeners hear sequences of pure tones and rate their perception of one or more subjective sources called streams. To disentangle the effects of head motion changes in acoustic cues at the ear subjective location cues and motor cues we used a robotic telepresence system Telehead. We found that head motion induced perceptual reorganization even when the acoustic scene had not changed. Here we reanalyzed the same data to probe the time course of sensory-motor integration. We show that motor cues had a different time course compared to acoustic or subjective location cues: motor cues impacted perceptual organization earlier and for a shorter time than other cues with successive positive and negative contributions to streaming. An additional experiment controlled for the effects of volitional anticipatory components and found that arm or leg movements did not have any impact on scene analysis. These data provide a first investigation of the time course of the complex integration of sensory-motor cues in an auditory scene analysis task and they suggest a loose temporal coupling between the different mechanisms involved. Probing the time course of head-motion cues integration during auditory scene analysis.
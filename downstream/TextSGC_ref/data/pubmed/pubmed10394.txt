In this paper we propose a novel object detection algorithm named "Deep Regionlets" by integrating deep neural networks and conventional detection schema for accurate generic object detection. Motivated by the advantages of regionlets on modeling object deformation and multiple aspect ratios we incorporate regionlets into an end-to-end trainable deep learning framework. The deep regionlets framework consists of a region selection network and a deep regionlet learning module. Specifically given a detection bounding box proposal the region selection network provides guidance on where to select sub-regions from which features can be learned from. An object proposal typically contains 3-16 sub-regions. The regionlet learning module focuses on local feature selection and transformation to alleviate the effects of appearance variations. To this end we first realize non-rectangular region selection within the detection framework to accommodate variations in object appearance. Moreover we design a "gating network" within the regionlet leaning module to enable instance dependent soft feature selection and pooling. The Deep Regionlets framework is trained end-to-end without additional efforts. We present ablation studies and extensive experiments on the PASCAL VOC dataset and the Microsoft COCO dataset. The proposed method outperforms state-of-the-art algorithms such as RetinaNet and Mask R-CNN even without additional segmentation labels. Deep Regionlets: Blended Representation and Deep Learning for Generic Object Detection.
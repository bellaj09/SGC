"Directivity and gain in microphone array systems for hearing aids or hearable devices allow users to acoustically enhance the information of a source of interest. This source is usually positioned directly in front. This feature is called acoustic beamforming. The current study aimed to improve users interactions with beamforming via a virtual prototyping approach in immersive virtual environments VEs. Eighteen participants took part in experimental sessions composed of a calibration procedure and a selective auditory attention voice-pairing task. Eight concurrent speakers were placed in an anechoic environment in two virtual reality VR scenarios. The scenarios were a purely virtual scenario and a realistic 360 audio-visual recording. Participants were asked to find an individual optimal parameterization for three different virtual beamformers: i head-guided ii eye gaze-guided and iii a novel interaction technique called dual beamformer where head-guided is combined with an additional hand-guided beamformer. None of the participants were able to complete the task without a virtual beamformer i.e. in normal hearing condition due to the high complexity introduced by the experimental design. However participants were able to correctly pair all speakers using all three proposed interaction metaphors. Providing superhuman hearing abilities in the form of a dual acoustic beamformer guided by head and hand movements resulted in statistically significant improvements in terms of pairing time suggesting the task-relevance of interacting with multiple points of interests." Superhuman Hearing - Virtual Prototyping of Artificial Hearing: a Case Study on Interactions and Acoustic Beamforming.
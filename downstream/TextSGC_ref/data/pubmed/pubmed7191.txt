Face alignment aims at localizing multiple facial landmarks for a given facial image which usually suffers from large variances of diverse facial expressions aspect ratios and partial occlusions especially when face images were captured in wild conditions. Conventional face alignment methods extract local features and then directly concatenate these features for global shape regression. Unlike these methods which cannot explicitly model the correlation of neighbouring landmarks and motivated by the fact that individual landmarks are usually correlated we propose a deep sharable and structural detectors DSSD method for face alignment. To achieve this we firstly develop a structural feature learning method to explicitly exploit the correlation of neighbouring landmarks which learns to cover semantic information to disambiguate the neighbouring landmarks. Moreover our model selectively learns a subset of sharable latent tasks across neighbouring landmarks under the paradigm of the multi-task learning framework so that the redundancy information of the overlapped patches can be efficiently removed. To better improve the performance we extend our DSSD to a recurrent DSSD R-DSSD architecture by integrating with the complementary information from multi-scale perspectives. Experimental results on the widely used benchmark datasets show that our methods achieve very competitive performance compared to the state-of-the-arts. Learning Deep Sharable and Structural Detectors for Face Alignment.
We argue that objective fidelity evaluation of virtual environments such as flight simulation should be human-performance-centred and task-specific rather than measure the match between simulation and physical reality. We show how principled experimental paradigms and behavioural models to quantify human performance in simulated environments that have emerged from research in multisensory perception provide a framework for the objective evaluation of the contribution of individual cues to human performance measures of fidelity. We present three examples in a flight simulation environment as a case study: Experiment 1: Detection and categorisation of auditory and kinematic motion cues; Experiment 2: Performance evaluation in a target-tracking task; Experiment 3: Transferrable learning of auditory motion cues. We show how the contribution of individual cues to human performance can be robustly evaluated for each task and that the contribution is highly task dependent. The same auditory cues that can be discriminated and are optimally integrated in experiment 1 do not contribute to target-tracking performance in an in-flight refuelling simulation without training experiment 2. In experiment 3 however we demonstrate that the auditory cue leads to significant transferrable performance improvements with training. We conclude that objective fidelity evaluation requires a task-specific analysis of the contribution of individual cues. Objective fidelity evaluation in multisensory virtual environments: auditory cue fidelity in flight simulation.
"Nowadays camera networks are part of our every-day life environments consequently they represent a massive source of information for monitoring human activities and to propose new services to the building users. To perform human activity monitoring people must be detected and the analysis has to be done according to the information relative to the environment and the context. Available multi-camera datasets furnish videos with few or none information of the environment where the network was deployed. The proposed dataset provides multi-camera multi-space video sets along with the complete contextual information of the environment. The dataset regroups 11 video sets composed of 62 single videos recorded using 6 indoor cameras deployed on multiple spaces. The video sets represent more than 1\xa0h of video footage include 77 people tracks and captured different human actions such as walking around standing/sitting motionless entering/leaving a space and group merging/splitting. Moreover each video has been manually and automatically annotated to include people detection and tracking meta-information. The automatic people detection annotations were obtained by using different complexity and robustness detectors from machine learning to state-of-art deep Convolutional Neural Network CNN models. Concerning the contextual information the Industry Foundation Classes IFC file that represents the environments Building Information Modeling BIM data is also provided. The BIM/IFC file describes the complete structure of the environment its topology and the elements contained in it. To our knowledge the WiseNET dataset is the first to provide a set of videos along with the complete information of the environment. The WiseNET dataset is publicly available at https://doi.org/10.4121/uuid:c1fb5962-e939-4c51-bfd5-eac6f2935d44 as well as at the projects website http://wisenet.checksem.fr/#/dataset." WiseNET: An indoor multi-camera multi-space dataset with contextual information and annotations for people detection and tracking.
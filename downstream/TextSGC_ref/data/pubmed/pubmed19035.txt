Associative reinforcement provides a powerful explanation of learned behavior. However an unproven but long-held conjecture holds that spatial learning can occur incidentally rather than by reinforcement. Using a carefully controlled virtual-reality object-location memory task we formally demonstrate that locations are concurrently learned relative to both local landmarks and local boundaries but that landmark-learning obeys associative reinforcement showing "overshadowing" and "blocking" or "learned irrelevance" whereas boundary-learning is incidental showing neither overshadowing nor blocking nor learned irrelevance. Crucially both types of learning occur at similar rates and do not reflect differences in levels of performance cue salience or instructions. These distinct types of learning likely reflect the distinct neural systems implicated in processing of landmarks and boundaries: the striatum and hippocampus respectively Doeller CF King JA Burgess N 2008 Proc Natl Acad Sci USA 105:5915-5920. In turn our results suggest the use of fundamentally different learning rules by these two systems potentially explaining their differential roles in procedural and declarative memory more generally. Our results suggest a privileged role for surface geometry in determining spatial context and support the idea of a "geometric module" albeit for location rather than orientation. Finally the demonstration that reinforcement learning applies selectively to formally equivalent aspects of task-performance supports broader consideration of two-system models in analyses of learning and decision making. Distinct error-correcting and incidental learning of location relative to landmarks and boundaries.
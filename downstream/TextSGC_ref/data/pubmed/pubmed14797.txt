Traditionally medical discoveries are made by observing associations making hypotheses from them and then designing and running experiments to test the hypotheses. However with medical images observing and quantifying associations can often be difficult because of the wide variety of features patterns colours values and shapes that are present in real data. Here we show that deep learning can extract new knowledge from retinal fundus images. Using deep-learning models trained on data from 284335 patients and validated on two independent datasets of 12026 and 999 patients we predicted cardiovascular risk factors not previously thought to be present or quantifiable in retinal images such as age mean absolute error within 3.26 years gender area under the receiver operating characteristic curve AUC\u2009=\u20090.97 smoking status AUC\u2009=\u20090.71 systolic blood pressure mean absolute error within 11.23\u2009mmHg and major adverse cardiac events AUC\u2009=\u20090.70. We also show that the trained deep-learning models used anatomical features such as the optic disc or blood vessels to generate each prediction. Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning.
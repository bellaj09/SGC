Connectionist models can be characterized within the more general framework of probabilistic graphical models which allow to efficiently describe complex statistical distributions involving a large number of interacting variables. This integration allows building more realistic computational models of cognitive functions which more faithfully reflect the underlying neural mechanisms at the same time providing a useful bridge to higher-level descriptions in terms of Bayesian computations. Here we discuss a powerful class of graphical models that can be implemented as stochastic generative neural networks. These models overcome many limitations associated with classic connectionist models for example by exploiting unsupervised learning in hierarchical architectures deep networks and by taking into account top-down predictive processing supported by feedback loops. We review some recent cognitive models based on generative networks and we point out promising research directions to investigate neuropsychological disorders within this approach. Though further efforts are required in order to fill the gap between structured Bayesian models and more realistic biophysical models of neuronal dynamics we argue that generative neural networks have the potential to bridge these levels of analysis thereby improving our understanding of the neural bases of cognition and of pathologies caused by brain damage. Probabilistic Models and Generative Neural Networks: Towards an Unified Framework for Modeling Normal and Impaired Neurocognitive Functions.
The link between visual information and postural control was investigated based on a multi-degree-of-freedom model using the framework of the uncontrolled manifold UCM hypothesis. The hypothesis was that because visual information specifies the position of the body in space it would couple preferentially into those combinations of degrees of freedom DOFs that move the body in space and not into combinations of DOFs that do not move the body in space. Subjects stood quietly in a virtual reality cave for 4-min trials with or without a 0.2 2.0\xa0Hz or combined 0.2 and 2.0\xa0Hz visual field perturbation that was below perceptual threshold. Motion analysis was used to compute six sagittal plane joint angles. Variance across time of the angular motion was partitioned into 1 variance associated with motion of the body and 2 variance reflecting the use of flexible joint combinations that keep the anterior-posterior positions of the head HDPOS and center of mass CMPOS invariant. UCM analysis was performed in the frequency domain in order to link the sensory perturbation to each variance component at different frequencies. As predicted variance related to motion of the body was selectively increased at the 0.2-Hz drive frequency but not at other frequencies of sway for both CMPOS and HDPOS. The dominant effect with the 2.0-Hz visual drive also was limited largely to variance related to motion of the body. How visual information links to multijoint coordination during quiet standing.
Unsupervised Domain Adaptation UDA refers to the problem of learning a model in a target domain where labeled data are not available by leveraging information from annotated data in a source domain. Most deep UDA approaches operate in a single-source single-target scenario i.e. they assume that the source and the target samples arise from a single distribution. However in practice most datasets can be regarded as mixtures of multiple domains. In these cases exploiting traditional single-source single-target methods for learning classification models may lead to poor results. Furthermore it is often difficult to provide the domain labels for all data points i.e. latent domains should be automatically discovered. This paper introduces a novel deep architecture which addresses the problem of UDA by automatically discovering latent domains in visual datasets and exploiting this information to learn robust target classifiers. Specifically our architecture is based on two main components i.e. a side branch that automatically computes the assignment of each sample to its latent domain and novel layers that exploit domain membership information to appropriately align the distribution of the CNN internal feature representations to a reference distribution. We evaluate our approach on publicly available benchmarks showing that it outperforms state-of-the-art domain adaptation methods. Inferring Latent Domains for Unsupervised Deep Domain Adaptation.
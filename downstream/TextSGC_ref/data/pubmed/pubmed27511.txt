Restoring communication in case of aphasia is a key challenge for neurotechnologies. To this end brain-computer strategies can be envisioned to allow artificial speech synthesis from the continuous decoding of neural signals underlying speech imagination. Such speech brain-computer interfaces do not exist yet and their design should consider three key choices that need to be made: the choice of appropriate brain regions to record neural activity from the choice of an appropriate recording technique and the choice of a neural decoding scheme in association with an appropriate speech synthesis method. These key considerations are discussed here in light of 1 the current understanding of the functional neuroanatomy of cortical areas underlying overt and covert speech production 2 the available literature making use of a variety of brain recording techniques to better characterize and address the challenge of decoding cortical speech signals and 3 the different speech synthesis approaches that can be considered depending on the level of speech representation phonetic acoustic or articulatory envisioned to be decoded at the core of a speech BCI paradigm. Key considerations in designing a speech brain-computer interface.
Given that facial features contain a wide range of identification information and cannot be completely represented by a single feature the fusion of multiple features is particularly significant for achieving a robust face recognition performance especially when there is a big difference between the test sets and the training sets. This has been proven in both traditional and deep learning approaches. In this work we proposed a novel method named C2D-CNN color 2-dimensional principal component analysis 2DPCA-convolutional neural network. C2D-CNN combines the features learnt from the original pixels with the image representation learnt by CNN and then makes decision-level fusion which can significantly improve the performance of face recognition. Furthermore a new CNN model is proposed: firstly we introduce a normalization layer in CNN to speed up the network convergence and shorten the training time. Secondly the layered activation function is introduced to make the activation function adaptive to the normalized data. Finally probabilistic max-pooling is applied so that the feature information is preserved to the maximum extent while maintaining feature invariance. Experimental results show that compared with the state-of-the-art method our method shows better performance and solves low recognition accuracy caused by the difference between test and training datasets. Robust Face Recognition Using the Deep C2D-CNN Model Based on Decision-Level Fusion.
We describe and analyze the performance of metric learning systems including deep neural networks DNNs on a new dataset of human visual object shape similarity judgments of naturalistic part-based objects known as "Fribbles". In contrast to previous studies which asked participants to judge similarity when objects or scenes were rendered from a single viewpoint we rendered Fribbles from multiple viewpoints and asked participants to judge shape similarity in a viewpoint-invariant manner. Metrics trained using pixel-based or DNN-based representations fail to explain our experimental data but a metric trained with a viewpoint-invariant part-based representation produces a good fit. We also find that although neural networks can learn to extract the part-based representation-and therefore should be capable of learning to model our data-networks trained with a "triplet loss" function based on similarity judgments do not perform well. We analyze this failure providing a mathematical description of the relationship between the metric learning objective function and the triplet loss function. The poor performance of neural networks appears to be due to the nonconvexity of the optimization problem in network weight space. We conclude that viewpoint insensitivity is a critical aspect of human visual shape perception and that neural network and other machine learning methods will need to learn viewpoint-insensitive representations in order to account for people\s visual object shape similarity judgments. Can machine learning account for human visual object shape similarity judgments?
Accurate and reliable brain tumor segmentation is a critical component in cancer diagnosis treatment planning and treatment outcome evaluation. Build upon successful deep learning techniques a novel brain tumor segmentation method is developed by integrating fully convolutional neural networks FCNNs and Conditional Random Fields CRFs in a unified framework to obtain segmentation results with appearance and spatial consistency. We train a deep learning based segmentation model using 2D image patches and image slices in following steps: 1 training FCNNs using image patches; 2 training CRFs as Recurrent Neural Networks CRF-RNN using image slices with parameters of FCNNs fixed; and 3 fine-tuning the FCNNs and the CRF-RNN using image slices. Particularly we train 3 segmentation models using 2D image patches and slices obtained in axial coronal and sagittal views respectively and combine them to segment brain tumors using a voting based fusion strategy. Our method could segment brain images slice-by-slice much faster than those based on image patches. We have evaluated our method based on imaging data provided by the Multimodal Brain Tumor Image Segmentation Challenge BRATS 2013 BRATS 2015 and BRATS 2016. The experimental results have demonstrated that our method could build a segmentation model with Flair T1c and T2 scans and achieve competitive performance as those built with Flair T1 T1c and T2 scans. A deep learning model integrating FCNNs and CRFs for brain tumor segmentation.
The coupling between perception and action has seldom been explored in sophisticated motor behaviour such as 3D pointing. In this study we investigated how 3D pointing accuracy measured by a depth estimation task could be affected by the target appearing in different visual eccentricities. Specifically we manipulated the visual eccentricity of the target and its depth in virtual reality. Participants wore a head-mounted-display with an integrated eye-tracker and docked a cursor into a target. We adopted a within-participants factorial design with three variables. The first variable is Eccentricity: the location of the target on one of five horizontal eccentricities left far periphery left near periphery foveal right near periphery and right far periphery. The second variable is Depth at three levels and the third variable is Feedback Loop with two levels: open/closed. Eccentricity is refactored into Motion Correspondence between the starting location of the cursor and the target location with four levels: periphery to fovea fovea to periphery periphery to periphery fovea to fovea. The results showed that the pointing accuracy is modulated mainly by the target locations rather than the initial locations of the effector hand. Visible feedback during pointing improved performance. Evaluation of 3D Pointing Accuracy in the Fovea and Periphery in Immersive Head-Mounted Display Environments.
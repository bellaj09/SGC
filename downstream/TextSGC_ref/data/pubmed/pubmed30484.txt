Somatosensation is divided into multiple discrete modalities that we think of separably: e.g. tactile proprioceptive and temperature sensation. However in processes such as hapticsthose modalities all interact. If one intended to artificially generate a sensation that could be used for stereognosis for example it would be crucial to understand these interactions. We are presently examining the relationship between tactile and proprioceptive modalities in this context. In this overview of some of our recent work we show that signals that would normally be attributed to two of these systems separately tactile contact and self-movement interact both perceptually and physiologically in ways that complicate the understanding of haptic processing. In the first study described here we show that a tactile illusion on the fingertips the cutaneous rabbit effect can be abolished by changing the posture of the fingers. We then discuss activity in primary somatosensory cortical neurons illustrating the interrelationship of tactile and postural signals. In this study we used a robot-enhanced virtual environment to show that many neurons in primary somatosensory cortex with cutaneous receptive fields encode elements both of tactile contact and self-motion. We then show the results of studies examining the structure of the process which extracts the spatial location of the hand from proprioceptive signals. The structure of the spatial errors in these maps indicates that the proprioceptive-spatial map is stable but individually constructed.These seemingly disparate studies lead us to suggest that tactile sensation is encoded in a 2-D map but one which undergoes continual dynamic modification by an underlying proprioceptive map. Understanding how the disparate signals that comprise the somatosensory system are processed to produce sensation is an important step in realizing the kind of seamless integration aspired to in neuroprosthetics. Haptic interaction of touch and proprioception: implications for neuroprosthetics.
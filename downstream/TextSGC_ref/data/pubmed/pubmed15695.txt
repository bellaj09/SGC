Online time series prediction is the mainstream method in a wide range of fields ranging from speech analysis and noise cancelation to stock market analysis. However the data often contains many outliers with the increasing length of time series in real world. These outliers can mislead the learned model if treated as normal points in the process of prediction. To address this issue in this paper we propose a robust and adaptive online gradient learning method RoAdam Robust Adam for long short-term memory LSTM to predict time series with outliers. This method tunes the learning rate of the stochastic gradient algorithm adaptively in the process of prediction which reduces the adverse effect of outliers. It tracks the relative prediction error of the loss function with a weighted average through modifying Adam a popular stochastic gradient method algorithm for training deep neural networks. In our algorithm the large value of the relative prediction error corresponds to a small learning rate and vice versa. The experiments on both synthetic data and real time series show that our method achieves better performance compared to the existing methods based on LSTM. Robust and Adaptive Online Time Series Prediction with Long Short-Term Memory.
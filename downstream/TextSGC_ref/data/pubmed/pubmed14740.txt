Salient object detection is undergoing a remarkable development along with the wide usage of deep neural networks. Being trained with a large number of images annotated with strong pixel-level ground-truth masks deep salient object detectors have achieved state-of-the-art performance. However it is expensive and time-consuming to provide pixel-level ground-truth masks for each training image. To address this problem we propose a framework to learn deep salient object detectors without requiring any human annotation. The supervisory signals used in our learning framework are generated through a novel supervision synthesis scheme in which the key insights are "knowledge source transition" and "supervision by fusion". In the proposed learning framework both the external knowledge source and the internal knowledge source are explored to provide informative cues for synthesizing supervision required in our approach while a two-stream fusion mechanism is established to implement the supervision synthesis process. Experiments on four datasets demonstrate that the deep salient object detector trained by our proposed learning framework works well without requiring any human annotated masks which even approaches to its upper-bound obtained under the fully supervised learning fashion. Besides we apply the salient object detector learnt with our proposed framework to weakly supervised semantic segmentation task. Synthesizing Supervision for Learning Deep Saliency Network without Human Annotation.
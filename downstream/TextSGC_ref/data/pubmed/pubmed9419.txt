Artificial neural networks ANNs a popular path towards artificial intelligence have experienced remarkable success via mature models various benchmarks open-source datasets and powerful computing platforms. Spiking neural networks SNNs a category of promising models to mimic the neuronal dynamics of the brain have gained much attention for brain inspired computing and been widely deployed on neuromorphic devices. However for a long time there are ongoing debates and skepticisms about the value of SNNs in practical applications. Except for the low power attribute benefit from the spike-driven processing SNNs usually perform worse than ANNs especially in terms of the application accuracy. Recently researchers attempt to address this issue by borrowing learning methodologies from ANNs such as backpropagation to train high-accuracy SNN models. The rapid progress in this domain continuously produces amazing results with ever-increasing network size whose growing path seems similar to the development of deep learning. Although these ways endow SNNs the capability to approach the accuracy of ANNs the natural superiorities of SNNs and the way to outperform ANNs are potentially lost due to the use of ANN-oriented workloads and simplistic evaluation metrics. In this paper we take the visual recognition task as a case study to answer the questions of "what workloads are ideal for SNNs and how to evaluate SNNs makes sense". We design a series of contrast tests using different types of datasets ANN-oriented and SNN-oriented diverse processing models signal conversion methods and learning algorithms. We propose comprehensive metrics on the application accuracy and the cost of memory & compute to evaluate these models and conduct extensive experiments. We evidence the fact that on ANN-oriented workloads SNNs fail to beat their ANN counterparts; while on SNN-oriented workloads SNNs can fully perform better. We further demonstrate that in SNNs there exists a trade-off between the application accuracy and the execution cost which will be affected by the simulation time window and firing threshold. Based on these abundant analyses we recommend the most suitable model for each scenario. To the best of our knowledge this is the first work using systematical comparisons to explicitly reveal that the straightforward workload porting from ANNs to SNNs is unwise although many works are doing so and a comprehensive evaluation indeed matters. Finally we highlight the urgent need to build a benchmarking framework for SNNs with broader tasks datasets and metrics. Rethinking the performance comparison between SNNS and ANNS.
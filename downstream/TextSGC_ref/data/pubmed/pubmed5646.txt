Real-world applications such as first-person video activity recognition require intelligent edge devices. However size weight and power constraints of the embedded platforms cannot support resource intensive state-of-the-art algorithms. Machine learning lite algorithms such as reservoir computing with shallow 3-layer networks are computationally frugal as only the output layer is trained. By reducing network depth and plasticity reservoir computing minimizes computational power and complexity making the algorithms optimal for edge devices. However as a trade-off for their frugal nature reservoir computing sacrifices computational power compared to state-of-the-art methods. A good compromise between reservoir computing and fully supervised networks are the proposed deep-LSM networks. The deep-LSM is a deep spiking neural network which captures dynamic information over multiple time-scales with a combination of randomly connected layers and unsupervised layers. The deep-LSM processes the captured dynamic information through an attention modulated readout layer to perform classification. We demonstrate that the deep-LSM achieves an average of 84.78% accuracy on the DogCentric video activity recognition task beating state-of-the-art. The deep-LSM also shows up to 91.13% memory savings and up to 91.55% reduction in synaptic operations when compared to similar recurrent neural network models. Based on these results we claim that the deep-LSM is capable of overcoming limitations of traditional reservoir computing while maintaining the low computational cost associated with reservoir computing. Deep Liquid State Machines With Neural Plasticity for Video Activity Recognition.
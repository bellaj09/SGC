Temporal link prediction in dynamic networks has attracted increasing attention recently due to its valuable real-world applications. The primary challenge of temporal link prediction is to capture the spatial-temporal patterns and high nonlinearity of dynamic networks. Inspired by the success of image generation we convert the dynamic network into a sequence of static images and formulate the temporal link prediction as a conditional image generation problem. We propose a novel deep generative framework called NetworkGAN to tackle the challenging temporal link prediction task efficiently which simultaneously models the spatial and temporal features in the dynamic networks via deep learning techniques. The proposed NetworkGAN inherits the advantages of the graph convolutional network GCN the temporal matrix factorization TMF the long short-term memory network LSTM and the generative adversarial network GAN. Specifically an attentive GCN is first designed to automatically learn the spatial features of dynamic networks. Second we propose a TMF enhanced attentive LSTM TMF-LSTM to capture the temporal dependencies and evolutionary patterns of dynamic networks which predicts the network snapshot at next timestamp based on the network snapshots observed at previous timestamps. Furthermore we employ a GAN framework to further refine the performance of temporal link prediction by using a discriminative model to guide the training of the deep generative model i.e. TMF-LSTM in an adversarial process. To verify the effectiveness of the proposed model we conduct extensive experiments on five real-world datasets. Experimental results demonstrate the significant advantages of NetworkGAN compared to other strong competitors. An Advanced Deep Generative Framework for Temporal Link Prediction in Dynamic Networks.
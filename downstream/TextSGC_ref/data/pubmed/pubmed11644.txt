Accurate assessment of cardiac function is crucial for the diagnosis of cardiovascular disease1 screening for cardiotoxicity2 and decisions regarding the clinical management of patients with a critical illness3. However human assessment of cardiac function focuses on a limited sampling of cardiac cycles and has considerable inter-observer variability despite years of training45. Here to overcome this challenge we present a video-based deep\xa0learning algorithm-EchoNet-Dynamic-that surpasses the performance of human experts in the critical tasks of segmenting the left ventricle estimating ejection fraction and assessing cardiomyopathy. Trained on echocardiogram videos our model accurately segments the left ventricle with a Dice similarity coefficient of 0.92 predicts ejection fraction with a mean absolute error of 4.1% and reliably classifies heart failure with reduced ejection fraction area under the curve of 0.97. In an external dataset from another healthcare system EchoNet-Dynamic predicts the ejection fraction with a mean absolute error of 6.0% and classifies heart failure with reduced ejection fraction with an area under the curve of 0.96. Prospective evaluation with repeated human measurements confirms that the model has variance that is comparable to or less than that of human experts. By leveraging information across multiple cardiac cycles our model can rapidly identify subtle changes in ejection fraction is more reproducible than human evaluation and lays the foundation for precise diagnosis of cardiovascular disease in real time. As a resource to promote further innovation we also make publicly available a large dataset of 10030 annotated echocardiogram videos. Video-based AI for beat-to-beat assessment of cardiac function.
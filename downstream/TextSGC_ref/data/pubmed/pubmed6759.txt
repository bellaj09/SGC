Machine learning has several potential uses in medical imaging for semantic labeling of images to improve radiologist workflow and to triage studies for review. The purpose of this study was to 1 develop deep convolutional neural networks DCNNs for automated classification of 2D mammography views determination of breast laterality and assessment and of breast tissue density; and 2 compare the performance of DCNNs on these tasks of varying complexity to each other. We obtained 3034 2D-mammographic images from the Digital Database for Screening Mammography annotated with mammographic view image laterality and breast tissue density. These images were used to train a DCNN to classify images for these three tasks. The DCNN trained to classify mammographic view achieved receiver-operating-characteristic ROC area under the curve AUC of 1. The DCNN trained to classify breast image laterality initially misclassified right and left breasts AUC 0.75; however after discontinuing horizontal flips during data augmentation AUC improved to 0.93 p\xa0<\u20090.0001. Breast density classification proved more difficult with the DCNN achieving 68% accuracy. Automated semantic labeling of 2D mammography is feasible using DCNNs and can be performed with small datasets. However automated classification of differences in breast density is more difficult likely requiring larger datasets. Deep-Learning-Based Semantic Labeling for 2D Mammography and Comparison of Complexity for Machine Learning Tasks.
Cognitive science has long shown interest in expertise in part because prediction and control of expert development would have immense practical value. Most studies in this area investigate expertise by comparing experts with novices. The reliance on contrastive samples in studies of human expertise only yields deep insight into development where differences are important throughout skill acquisition. This reliance may be pernicious where the predictive importance of variables is not constant across levels of expertise. Before the development of sophisticated machine learning tools for data mining larger samples and indeed before such samples were available it was difficult to test the implicit assumption of static variable importance in expertise development. To investigate if this reliance may have imposed critical restrictions on the understanding of complex skill development we adopted an alternative method the online acquisition of telemetry data from a common daily activity for many: video gaming. Using measures of cognitive-motor attentional and perceptual processing extracted from game data from 3360 Real-Time Strategy players at 7 different levels of expertise we identified 12 variables relevant to expertise. We show that the static variable importance assumption is false--the predictive importance of these variables shifted as the levels of expertise increased--and at least in our dataset that a contrastive approach would have been misleading. The finding that variable importance is not static across levels of expertise suggests that large diverse datasets of sustained cognitive-motor performance are crucial for an understanding of expertise in real-world contexts. We also identify plausible cognitive markers of expertise. Video game telemetry as a critical tool in the study of complex skill learning.
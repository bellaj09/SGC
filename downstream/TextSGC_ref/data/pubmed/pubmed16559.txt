The purpose of this study is to evaluate transfer learning with deep convolutional neural networks for the classification of abdominal ultrasound images. Grayscale images from 185 consecutive clinical abdominal ultrasound studies were categorized into 11 categories based on the text annotation specified by the technologist for the image. Cropped images were rescaled to 256\u2009\u2009256 resolution and randomized with 4094 images from 136 studies constituting the training set and 1423 images from 49 studies constituting the test set. The fully connected layers of two convolutional neural networks based on CaffeNet and VGGNet previously trained on the 2012 Large Scale Visual Recognition Challenge data set were retrained on the training set. Weights in the convolutional layers of each network were frozen to serve as fixed feature extractors. Accuracy on the test set was evaluated for each network. A radiologist experienced in abdominal ultrasound also independently classified the images in the test set into the same 11 categories. The CaffeNet network classified 77.3% of the test set images accurately 1100/1423 images with a top-2 accuracy of 90.4% 1287/1423 images. The larger VGGNet network classified 77.9% of the test set accurately 1109/1423 images with a top-2 accuracy of VGGNet was 89.7% 1276/1423 images. The radiologist classified 71.7% of the test set images correctly 1020/1423 images. The differences in classification accuracies between both neural networks and the radiologist were statistically significant p\u2009<\u20090.001. The results demonstrate that transfer learning with convolutional neural networks may be used to construct effective classifiers for abdominal ultrasound images. Transfer Learning with Convolutional Neural Networks for Classification of Abdominal Ultrasound Images.
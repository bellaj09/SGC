We propose multi-atlas learner fusion MLF a framework for rapidly and accurately replicating the highly accurate yet computationally expensive multi-atlas segmentation framework based on fusing local learners. In the largest whole-brain multi-atlas study yet reported multi-atlas segmentations are estimated for a training set of 3464 MR brain images. Using these multi-atlas estimates we 1 estimate a low-dimensional representation for selecting locally appropriate example images and 2 build AdaBoost learners that map a weak initial segmentation to the multi-atlas segmentation result. Thus to segment a new target image we project the image into the low-dimensional space construct a weak initial segmentation and fuse the trained locally selected learners. The MLF framework cuts the runtime on a modern computer from 36 h down to 3-8 min - a 270 speedup - by completely bypassing the need for deformable atlas-target registrations. Additionally we 1 describe a technique for optimizing the weak initial segmentation and the AdaBoost learning parameters 2 quantify the ability to replicate the multi-atlas result with mean accuracies approaching the multi-atlas intra-subject reproducibility on a testing set of 380 images 3 demonstrate significant increases in the reproducibility of intra-subject segmentations when compared to a state-of-the-art multi-atlas framework on a separate reproducibility dataset 4 show that under the MLF framework the large-scale data model significantly improve the segmentation over the small-scale model under the MLF framework and 5 indicate that the MLF framework has comparable performance as state-of-the-art multi-atlas segmentation algorithms without using non-local information. Multi-atlas learner fusion: An efficient segmentation approach for large-scale data.
The precise combination of image sensor and micro-lens array enables light-field cameras to record both angular and spatial information of incoming light therefore one can calculate disparity and depth from one single light-field image captured by one single light-field camera. In turn 3D models of the recorded objects can be recovered which means a 3D measurement system can be built using a light-field camera. However reflective and texture-less areas in light-field images have complicated conditions making it hard to correctly calculate disparity with existing algorithms. To tackle this problem we introduce a novel end-to-end network VommaNet to retrieve multi-scale features from reflective and texture-less regions for accurate disparity estimation. Meanwhile our network has achieved similar or better performance in other regions for both synthetic light-field images and real-world data compared to the state-of-the-art algorithms. Fast and Accurate 3D Measurement Based on Light-Field Camera and Deep Learning.
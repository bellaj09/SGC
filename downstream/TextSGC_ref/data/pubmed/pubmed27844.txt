"Brain-computer interfaces have been proposed as a solution for paralyzed persons to communicate and interact with their environment. However the neural signals used for controlling such prostheses are often noisy and unreliable resulting in a low performance of real-world applications. Here we propose neural signatures of selective visual attention in epidural recordings as a fast reliable and high-performance control signal for brain prostheses. We recorded epidural field potentials with chronically implanted electrode arrays from two macaque monkeys engaged in a shape-tracking task. For single trials we classified the direction of attention to one of two visual stimuli based on spectral amplitude coherence and phase difference in time windows fixed relative to stimulus onset. Classification performances reached up to 99.9% and the information about attentional states could be transferred at rates exceeding 580 bits/min. Good classification can already be achieved in time windows as short as 200 ms. The classification performance changed dynamically over the trial and modulated with the tasks varying demands for attention. For all three signal features the information about the direction of attention was contained in the -band. The most informative feature was spectral amplitude. Together these findings establish a novel paradigm for constructing brain prostheses as for example virtual spelling boards promising a major gain in performance and robustness for human brain-computer interfaces." Toward high performance weakly invasive brain computer interfaces using selective visual attention.
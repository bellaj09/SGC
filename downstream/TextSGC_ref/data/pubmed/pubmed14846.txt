Recently deep convolutional neural networks have achieved significant success in salient object detection. However existing state-of-the-art methods require high-end GPUs to achieve real-time performance which makes it hard to adapt to low cost or portable devices. Although generic network architectures have been proposed to speed up inference on mobile devices they are tailored to the task of image classification or semantic segmentation and struggle to capture intrachannel and interchannel correlations that are essential for contrast modeling in salient object detection. Motivated by the above observations we design a new deep-learning algorithm for fast salient object detection. The proposed algorithm for the first time achieves competitive accuracy and high inference efficiency simultaneously with a single CPU thread. Specifically we propose a novel depthwise nonlocal module DNL which implicitly models contrast via harvesting intrachannel and interchannel correlations in a self-attention manner. In addition we introduce a depthwise nonlocal network architecture that incorporates both DNLs module and inverted residual blocks. The experimental results show that our proposed network attains very competitive accuracy on a wide range of salient object detection datasets while achieving state-of-the-art efficiency among all existing deep-learning-based algorithms. Depthwise Nonlocal Module for Fast Salient Object Detection Using a Single Thread.
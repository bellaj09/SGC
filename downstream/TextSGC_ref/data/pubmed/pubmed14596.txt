Though quite challenging leveraging large-scale unlabeled or partially labeled data in learning systems e.g. model/classifier training has attracted increasing attentions due to its fundamental importance. To address this problem many active learning AL methods have been proposed that employ up-to-date detectors to retrieve representative minority samples according to predefined confidence or uncertainty thresholds. However these AL methods cause the detectors to ignore the remaining majority samples i.e. those with low uncertainty or high prediction confidence. In this paper by developing a principled active sample mining ASM framework we demonstrate that cost-effective mining samples from these unlabeled majority data are a key to train more powerful object detectors while minimizing user effort. Specifically our ASM framework involves a switchable sample selection mechanism for determining whether an unlabeled sample should be manually annotated via AL or automatically pseudolabeled via a novel self-learning process. The proposed process can be compatible with mini-batch-based training i.e. using a batch of unlabeled or partially labeled data as a one-time input for object detection. In this process the detector such as a deep neural network is first applied to the unlabeled samples i.e. object proposals to estimate their labels and output the corresponding prediction confidences. Then our ASM framework is used to select a number of samples and assign pseudolabels to them. These labels are specific to each learning batch based on the confidence levels and additional constraints introduced by the AL process and will be discarded afterward. Then these temporarily labeled samples are employed for network fine-tuning. In addition a few samples with low-confidence predictions are selected and annotated via AL. Notably our method is suitable for object categories that are not seen in the unlabeled data during the learning process. Extensive experiments on two public benchmarks i.e. the PASCAL VOC 2007/2012 data sets clearly demonstrate that our ASM framework can achieve performance comparable to that of the alternative methods but with significantly fewer annotations. Cost-Effective Object Detection: Active Sample Mining With Switchable Selection Criteria.
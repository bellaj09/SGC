The primate visual system achieves remarkable visual object recognition performance even in brief presentations and under changes to object exemplar geometric transformations and background variation a.k.a. core visual object recognition. This remarkable performance is mediated by the representation formed in inferior temporal IT cortex. In parallel recent advances in machine learning have led to ever higher performing models of object recognition using artificial deep neural networks DNNs. It remains unclear however whether the representational performance of DNNs rivals that of the brain. To accurately produce such a comparison a major difficulty has been a unifying metric that accounts for experimental limitations such as the amount of noise the number of neural recording sites and the number of trials and computational limitations such as the complexity of the decoding classifier and the number of classifier training examples. In this work we perform a direct comparison that corrects for these experimental limitations and computational considerations. As part of our methodology we propose an extension of "kernel analysis" that measures the generalization accuracy as a function of representational complexity. Our evaluations show that unlike previous bio-inspired models the latest DNNs rival the representational performance of IT cortex on this visual object recognition task. Furthermore we show that models that perform well on measures of representational performance also perform well on measures of representational similarity to IT and on measures of predicting individual IT multi-unit responses. Whether these DNNs rely on computational mechanisms similar to the primate visual system is yet to be determined but unlike all previous bio-inspired models that possibility cannot be ruled out merely on representational performance grounds. Deep neural networks rival the representation of primate IT cortex for core visual object recognition.
Linear regression quantifies the linear relationship between paired sets of input and output observations. The well known least-squares regression optimizes the performance criterion defined by the residual error but is highly sensitive to uncertainties or perturbations in the observations. Robust least-squares algorithms have been developed to optimize the worst case performance for a given limit on the level of uncertainty but they are applicable only when that limit is known. Herein we present a robust-satisficing approach that maximizes the robustness to uncertainties in the observations while satisficing a critical sub-optimal level of performance. The method emphasizes the trade-off between performance and robustness which are inversely correlated. To resolve the resulting trade-off we introduce a new criterion which assesses the consistency between the observations and the linear model. The proposed criterion determines a unique robust-satisficing regression and reveals the underlying level of uncertainty in the observations with only weak assumptions. These algorithms are demonstrated for the challenging application of linear regression to neural decoding for brain-machine interfaces. The model-consistent robust-satisfying regression provides superior performance for new observations under both similar and different conditions. Robust Satisficing Linear Regression: performance/robustness trade-off and consistency criterion.
Patients with total locked-in syndrome are conscious; however they cannot express themselves because most of their voluntary muscles are paralyzed and many of these patients have lost their eyesight. To improve the quality of life of these patients there is an increasing need for communication-supporting technologies that leverage the remaining senses of the patient along with physiological signals. The auditory steady-state response ASSR is an electro-physiologic response to auditory stimulation that is amplitude-modulated by a specific frequency. By leveraging the phenomenon whereby ASSR is modulated by mind concentration a brain-computer interface paradigm was proposed to classify the selective attention of the patient. In this paper we propose an auditory stimulation method to minimize auditory stress by replacing the monotone carrier with familiar music and natural sounds for an ergonomic system. Piano and violin instrumentals were employed in the music sessions; the sounds of water streaming and cicadas singing were used in the natural sound sessions. Six healthy subjects participated in the experiment. Electroencephalograms were recorded using four electrodes Cz Oz T7 and T8. Seven sessions were performed using different stimuli. The spectral power at 38 and 42Hz and their ratio for each electrode were extracted as features. Linear discriminant analysis was utilized to classify the selections for each subject. In offline analysis the average classification accuracies with a modulation index of 1.0 were 89.67% and 87.67% using music and natural sounds respectively. In online experiments the average classification accuracies were 88.3% and 80.0% using music and natural sounds respectively. Using the proposed method we obtained significantly higher user-acceptance scores while maintaining a high average classification accuracy. Music and natural sounds in an auditory steady-state response based brain-computer interface to increase user acceptance.
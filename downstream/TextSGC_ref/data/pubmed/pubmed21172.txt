"Classification of spoken word-evoked potentials is useful for both neuroscientific and clinical applications including brain-computer interfaces BCIs. By evaluating whether adopting a biology-based structure improves a classifiers accuracy we can investigate the importance of such structure in human brain circuitry and advance BCI performance. In this study we propose a semantic-hierarchical structure for classifying spoken word-evoked cortical responses. The proposed structure decodes the semantic grouping of the words first e.g. a body part vs. a number and then decodes which exact word was heard. The proposed classifier structure exhibited a consistent 10% improvement of classification accuracy when compared with a non-hierarchical structure. Our result provides a tool for investigating the neural representation of semantic hierarchy and the acoustic properties of spoken words in human brains. Our results suggest an improved algorithm for BCIs operated by decoding heard and possibly imagined words." Semantic-hierarchical model improves classification of spoken-word evoked electrocorticography.
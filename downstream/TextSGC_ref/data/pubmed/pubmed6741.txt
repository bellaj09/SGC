Conditional maximum mean discrepancy CMMD can capture the discrepancy between conditional distributions by drawing support from nonlinear kernel functions; thus it has been successfully used for pattern classification. However CMMD does not work well on complex distributions especially when the kernel function fails to correctly characterize the difference between intraclass similarity and interclass similarity. In this paper a new kernel learning method is proposed to improve the discrimination performance of CMMD. It can be operated with deep network features iteratively and thus denoted as KLN for abbreviation. The CMMD loss and an autoencoder AE are used to learn an injective function. By considering the compound kernel that is the injective function with a characteristic kernel the effectiveness of CMMD for data category description is enhanced. KLN can simultaneously learn a more expressive kernel and label prediction distribution; thus it can be used to improve the classification performance in both supervised and semisupervised learning scenarios. In particular the kernel-based similarities are iteratively learned on the deep network features and the algorithm can be implemented in an end-to-end manner. Extensive experiments are conducted on four benchmark datasets including MNIST SVHN CIFAR-10 and CIFAR-100. The results indicate that KLN achieves the state-of-the-art classification performance. Learning Kernel for Conditional Moment-Matching Discrepancy-Based Image Classification.
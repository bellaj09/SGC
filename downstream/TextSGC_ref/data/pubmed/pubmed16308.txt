"Robust cross-subject emotion recognition based on multichannel EEG has always been hard work. In this work we hypothesize that there exist default brain variables across subjects in emotional processes. Hence the states of the latent variables that relate to emotional processing must contribute to building robust recognition models. Specifically we propose to utilize an unsupervised deep generative model e.g. variational autoencoder to determine the latent factors from the multichannel EEG. Through a sequence modeling method we examine the emotion recognition performance based on the learnt latent factors. The performance of the proposed methodology is verified on two public datasets DEAP and SEED and compared with traditional matrix factorization-based ICA and autoencoder-based approaches. Experimental results demonstrate that autoencoder-like neural networks are suitable for unsupervised EEG modeling and our proposed emotion recognition framework achieves an inspiring performance. As far as we know it is the first work that introduces variational autoencoder into multichannel EEG decoding for emotion recognition. We think the approach proposed in this work is not only feasible in emotion recognition but also promising in diagnosing depression Alzheimers disease mild cognitive impairment etc. whose specific latent processes may be altered or aberrant compared with the normal healthy control." Latent Factor Decoding of Multi-Channel EEG for Emotion Recognition Through Autoencoder-Like Neural Networks.
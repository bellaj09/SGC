Recently deep learning has been advancing the state of the art in artificial intelligence to a new level and humans rely on artificial intelligence techniques more than ever. However even with such unprecedented advancements the lack of explanation regarding the decisions made by deep learning models and absence of control over their internal processes act as major drawbacks in critical decision-making processes such as precision medicine and law enforcement. In response efforts are being made to make deep learning interpretable and controllable by humans. This article reviews visual analytics information visualization and machine learning perspectives relevant to this aim and discusses potential challenges and future research directions. Visual Analytics for Explainable Deep Learning.
Previous research in spatial cognition has often relied on simple spatial tasks in static environments in order to draw inferences regarding navigation performance. These tasks are typically divided into categories e.g. egocentric or allocentric that reflect different two-systems theories. Unfortunately this two-systems approach has been insufficient for reliably predicting navigation performance in virtual reality VR. In the present experiment participants were asked to learn and navigate towards goal locations in a virtual city and then perform eight simple spatial tasks in a separate environment. These eight tasks were organised along four orthogonal dimensions static/dynamic perceived/remembered egocentric/allocentric and distance/direction. We employed confirmatory and exploratory analyses in order to assess the relationship between navigation performance and performances on these simple tasks. We provide evidence that a dynamic task i.e. intercepting a moving object is capable of predicting navigation performance in a familiar virtual environment better than several categories of static tasks. These results have important implications for studies on navigation in VR that tend to over-emphasise the role of spatial memory. Given that our dynamic tasks required efficient interaction with the human interface device HID they were more closely aligned with the perceptuomotor processes associated with locomotion than wayfinding. In the future researchers should consider training participants on HIDs using a dynamic task prior to conducting a navigation experiment. Performances on dynamic tasks should also be assessed in order to avoid confounding skill with an HID and spatial knowledge acquisition. Evaluation of a conceptual framework for predicting navigation performance in virtual reality.
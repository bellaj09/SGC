"Though the range of invariance in recognition of novel objects is a basic aspect of human vision its characterization has remained surprisingly elusive. Here we report tolerance to scale and position changes in one-shot learning by measuring recognition accuracy of Korean letters presented in a flash to non-Korean subjects who had no previous experience with Korean letters. We found that humans have significant scale-invariance after only a single exposure to a novel object. The range of translation-invariance is limited depending on the size and position of presented objects. To understand the underlying brain computation associated with the invariance properties we compared experimental data with computational modeling results. Our results suggest that to explain invariant recognition of objects by humans neural network models should explicitly incorporate built-in scale-invariance by encoding different scale channels as well as eccentricity-dependent representations captured by neurons receptive field sizes and sampling density that change with eccentricity. Our psychophysical experiments and related simulations strongly suggest that the human visual system uses a computational strategy that differs in some key aspects from current deep learning architectures being more data efficient and relying more critically on eye-movements." Scale and translation-invariance for novel objects in human vision.
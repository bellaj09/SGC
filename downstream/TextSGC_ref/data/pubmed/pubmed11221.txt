The broad learning system BLS is an emerging approach for effective and efficient modeling of complex systems. The inputs are transferred and placed in the feature nodes and then sent into the enhancement nodes for nonlinear transformation. The structure of a BLS can be extended in a wide sense. Incremental learning algorithms are designed for fast learning in broad expansion. Based on the typical BLSs a novel recurrent BLS RBLS is proposed in this paper. The nodes in the enhancement units of the BLS are recurrently connected for the purpose of capturing the dynamic characteristics of a time series. A sparse autoencoder is used to extract the features from the input instead of the randomly initialized weights. In this way the RBLS retains the merit of fast computing and fits for processing sequential data. Motivated by the idea of "fine-tuning" in deep learning the weights in the RBLS can be updated by conjugate gradient methods if the prediction errors are large. We exhibit the merits of our proposed model on several chaotic time series. Experimental results substantiate the effectiveness of the RBLS. For chaotic benchmark datasets the RBLS achieves very small errors and for the real-world dataset the performance is satisfactory. Recurrent Broad Learning Systems for Time Series Prediction.
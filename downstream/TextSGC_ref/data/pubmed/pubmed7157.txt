Robotic endoscopic systems offer a minimally invasive approach to the examination of internal body structures and their application is rapidly extending to cover the increasing needs for accurate therapeutic interventions. In this context it is essential for such systems to be able to perform measurements such as measuring the distance traveled by a wireless capsule endoscope so as to determine the location of a lesion in the gastrointestinal tract or to measure the size of lesions for diagnostic purposes. In this paper we investigate the feasibility of performing contactless measurements using a computer vision approach based on neural networks. The proposed system integrates a deep convolutional image registration approach and a multilayer feed-forward neural network into a novel architecture. The main advantage of this system with respect to the state-of-the-art ones is that it is more generic in the sense that it is 1 unconstrained by specific models 2 more robust to nonrigid deformations and 3 adaptable to most of the endoscopic systems and environment while enabling measurements of enhanced accuracy. The performance of this system is evaluated under ex vivo conditions using a phantom experimental model and a robotically assisted test bench. The results obtained promise a wider applicability and impact in endoscopy in the era of big data. Deep Endoscopic Visual Measurements.
Tumor histopathology is a crucial step in cancer diagnosis which involves visual inspection of imaging data to detect the presence of tumor cells among healthy tissues. This manual process can be time-consuming error-prone and influenced by the expertise of the pathologist. Recent deep learning methods for image classification and detection using convolutional neural networks CNNs have demonstrated marked improvements in the accuracy of a variety of medical imaging analysis tasks. However most well-established deep learning methods require large annotated training datasets that are specific to the particular problem domain; such datasets are difficult to acquire for histopathology data where visual characteristics differ between different tissue types in addition to the need for precise annotations. In this study we overcome the lack of annotated training dataset in histopathology images of a particular domain by adapting annotated histopathology images from different domains tissue types. The data from other tissue types are used to pre-train CNNs into a shared histopathology domain e.g. stains cellular structures such that it can be further tuned/optimized for a specific tissue type. We evaluated our classification method on publically available datasets of histopathology images; the accuracy and area under the receiver operating characteristic curve AUC of our method was higher than CNNs trained from scratch on limited data accuracy: 84.3% vs. 78.3%; AUC: 0.918 vs. 0.867 suggesting that domain adaptation can be a valuable approach to histopathological images classification. Patch-level Tumor Classification in Digital Histopathology Images with Domain Adapted Deep Learning.
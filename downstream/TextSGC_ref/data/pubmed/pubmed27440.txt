The performance of the event-related potential ERP-based brain-computer interface BCI declines when applying it into the real environment which limits the generality of the BCI. The sound is a common noise in daily life and whether it has influence on this decline is unknown. This study designs a visual-auditory BCI task that requires the subject to focus on the visual interface to output commands and simultaneously count number according to an auditory story. The story is played at three speeds to cause different workloads. Data collected under the same or different workloads are used to train and test classifiers. The results show that when the speed of playing the story increases the amplitudes of P300 and N200 potentials decrease by 0.86 V p = 0.0239 and 0.69 V p = 0.0158 in occipital-parietal area leading to a 5.95% decline p = 0.0101 of accuracy and 9.53 bits/min decline p = 0.0416 of information transfer rate. The classifier that is trained by the high workload data achieves higher accuracy than the one trained by the low workload if using the high workload data to test the performance. The result indicates that the sound could affect the visual ERP-BCI by increasing the workload. The large similarity of the training data and testing data is as important as the amplitudes of the ERP on obtaining high performance which gives us an insight on how make to the ERP-BCI generalized. The Study of Influence of Sound on Visual ERP-Based Brain Computer Interface.
"The challenge of getting machines to understand and interact with natural objects is encountered in important areas such as medicine agriculture and in our case slaughterhouse automation. Recent breakthroughs have enabled the application of Deep Neural Networks DNN directly to point clouds an efficient and natural representation of 3D objects. The potential of these methods has mostly been demonstrated for classification and segmentation tasks involving rigid man-made objects. We present a method based on the successful PointNet architecture for learning to regress correct tool placement from human demonstrations using virtual reality. Our method is applied to a challenging slaughterhouse cutting task which requires an understanding of the local geometry including the shape size and orientation. We propose an intermediate five-Degree of Freedom DoF cutting plane representation a point and a normal vector which eases the demonstration and learning process. A live experiment is conducted in order to unveil issues and begin to understand the required accuracy. Eleven cuts are rated by an expert with 8 / 11 being rated as acceptable. The error on the test set is subsequently reduced through the addition of more training data and improvements to the DNN. The result is a reduction in the average translation from 1.5 cm to 0.8 cm and the orientation error from 4 . 59 to 4 . 48 . The methods generalization capacity is assessed on a similar task from the slaughterhouse and on the very different public LINEMOD dataset for object pose estimation across view points. In both cases the method shows promising results. Code datasets and supplementary materials are available at https://github.com/markpp/PoseFromPointClouds." Cutting Pose Prediction from Point Clouds.
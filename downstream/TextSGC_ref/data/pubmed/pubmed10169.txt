The interest in fisheye cameras has recently risen in the autonomous vehicles field as they are able to reduce the complexity of perception systems while improving the management of dangerous driving situations. However the strong distortion inherent to these cameras makes the usage of conventional computer vision algorithms difficult and has prevented the development of these devices. This paper presents a methodology that provides real-time semantic segmentation on fisheye cameras leveraging only synthetic images. Furthermore we propose some Convolutional Neural NetworksCNN architectures based on Efficient Residual Factorized NetworkERFNet that demonstrate notable skills handling distortion and a new training strategy that improves the segmentation on the image borders. Our proposals are compared to similar state-of-the-art works showing an outstanding performance and tested in an unknown real world scenario using a fisheye camera integrated in an open-source autonomous electric car showing a high domain adaptation capability. Real-Time Semantic Segmentation for Fisheye Urban Driving Images Based on ERFNet.
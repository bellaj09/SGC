Recognition of human actions from digital video is a challenging task due to complex interfering factors in uncontrolled realistic environments. In this paper we propose a learning framework using static dynamic and sequential mixed features to solve three fundamental problems: spatial domain variation temporal domain polytrope and intra- and inter-class diversities. Utilizing a cognitive-based data reduction method and a hybrid "network upon networks" architecture we extract human action representations which are robust against spatial and temporal interferences and adaptive to variations in both action speed and duration. We evaluated our method on the UCF101 and other three challenging datasets. Our results demonstrated a superior performance of the proposed algorithm in human action recognition. ARCH: Adaptive recurrent-convolutional hybrid networks for long-term action recognition.
Deep- and reinforcement-learning techniques have increasingly required large sets of real data to achieve stable convergence and generalization in the context of image-recognition object-detection or motion-control strategies. On this subject the research community lacks robust approaches to overcome unavailable real-world extensive data by means of realistic synthetic-information and domain-adaptation techniques. In this work synthetic-learning strategies have been used for the vision-based autonomous following of a noncooperative multirotor. The complete maneuver was learned with synthetic images and high-dimensional low-level continuous robot states with deep- and reinforcement-learning techniques for object detection and motion control respectively. A novel motion-control strategy for object following is introduced where the camera gimbal movement is coupled with the multirotor motion during the multirotor following. Results confirm that our present framework can be used to deploy a vision-based task in real flight using synthetic data. It was extensively validated in both simulated and real-flight scenarios providing proper results following a multirotor up to 1.3 m/s in simulation and 0.3 m/s in real flights. Vision-Based Multirotor Following Using Synthetic Learning Techniques.
When people scan mental images their response times increase linearly with increases in the distance to be scanned which is generally taken as reflecting the fact that their internal representations incorporate the metric properties of the corresponding objects. In view of this finding we investigated the structural properties of spatial mental images created from nonvisual sources in three groups blindfolded sighted late blind and congenitally blind. In Experiment 1 blindfolded sighted and late blind participants created metrically accurate spatial representations of a small-scale spatial configuration under both verbal and haptic learning conditions. In Experiment 2 late and congenitally blind participants generated accurate spatial mental images after both verbal and locomotor learning of a full-scale navigable space created by an immersive audio virtual reality system whereas blindfolded sighted participants were selectively impaired in their ability to generate precise spatial representations from locomotor experience. These results attest that in the context of a permanent lack of sight encoding spatial information on the basis of the most reliable currently functional system the sensorimotor system is crucial for building a metrically accurate representation of a spatial environment. The results also highlight the potential of spatialized audio-rendering technology for exploring the spatial representations of visually impaired participants. Structural properties of spatial representations in blind people: Scanning images constructed from haptic exploration or from locomotion in a 3-D audio virtual environment.
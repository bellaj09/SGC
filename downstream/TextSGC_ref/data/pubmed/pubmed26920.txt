"The ability of todays robots to autonomously support humans in their daily activities is still limited. To improve this predictive human-machine interfaces HMIs can be applied to better support future interaction between human and machine. To infer upcoming context-based behavior relevant brain states of the human have to be detected. This is achieved by brain reading BR a passive approach for single trial EEG analysis that makes use of supervised machine learning ML methods. In this work we propose that BR is able to detect concrete states of the interacting human. To support this we show that BR detects patterns in the electroencephalogram EEG that can be related to event-related activity in the EEG like the P300 which are indicators of concrete states or brain processes like target recognition processes. Further we improve the robustness and applicability of BR in application-oriented scenarios by identifying and combining most relevant training data for single trial classification and by applying classifier transfer. We show that training and testing i.e. application of the classifier can be carried out on different classes if the samples of both classes miss a relevant pattern. Classifier transfer is important for the usage of BR in application scenarios where only small amounts of training examples are available. Finally we demonstrate a dual BR application in an experimental setup that requires similar behavior as performed during the teleoperation of a robotic arm. Here target recognition processes and movement preparation processes are detected simultaneously. In summary our findings contribute to the development of robust and stable predictive HMIs that enable the simultaneous support of different interaction behaviors." On the applicability of brain reading for predictive human-machine interfaces in robotics.
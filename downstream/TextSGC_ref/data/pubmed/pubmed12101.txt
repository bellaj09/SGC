In recent years various studies have been conducted on the prediction of crime occurrences. This predictive capability is intended to assist in crime prevention by facilitating effective implementation of police patrols. Previous studies have used data from multiple domains such as demographics economics and education. Their prediction models treat data from different domains equally. These methods have problems in crime occurrence prediction such as difficulty in discovering highly nonlinear relationships redundancies and dependencies between multiple datasets. In order to enhance crime prediction models we consider environmental context information such as broken windows theory and crime prevention through environmental design. In this paper we propose a feature-level data fusion method with environmental context based on a deep neural network DNN. Our dataset consists of data collected from various online databases of crime statistics demographic and meteorological data and images in Chicago Illinois. Prior to generating training data we select crime-related data by conducting statistical analyses. Finally we train our DNN which consists of the following four kinds of layers: spatial temporal environmental context and joint feature representation layers. Coupled with crucial data extracted from various domains our fusion DNN is a product of an efficient decision-making process that statistically analyzes data redundancy. Experimental performance results show that our DNN model is more accurate in predicting crime occurrence than other prediction models. Prediction of crime occurrence from multi-modal data using deep learning.
In general development of adequately complex mathematical models such as deep neural networks can be an effective way to improve the accuracy of learning models. However this is achieved at the cost of reduced post-hoc model interpretability because what is learned by the model can become less intelligible and tractable to humans as the model complexity increases. In this paper we target a similarity learning task in the context of image retrieval with a focus on the model interpretability issue. An effective similarity neural network SNN is proposed to offer not only to seek robust retrieval performance but also to achieve satisfactory post-hoc interpretability. The network is designed by linking the neuron architecture with the organization of a concept tree and by formulating neuron operations to pass similarity information between concepts. Various ways of understanding and visualizing what is learned by the SNN neurons are proposed. We also exhaustively evaluate the proposed approach using a number of relevant datasets against a number of state-of-the-art approaches to demonstrate the effectiveness of the proposed network. Our results show that the proposed approach can offer superior performance when compared against state-of-the-art approaches. Neuron visualization results are demonstrated to support the understanding of the trained neurons. An Interpretable Deep Architecture for Similarity Learning Built Upon Hierarchical Concepts.
The evaluation of large amounts of digital image data is of growing importance for biology including for the exploration and monitoring of marine habitats. However only a tiny percentage of the image data collected is evaluated by marine biologists who manually interpret and annotate the image contents which can be slow and laborious. In order to overcome the bottleneck in image annotation two strategies are increasingly proposed: "citizen science" and "machine learning". In this study we investigated how the combination of citizen science to detect objects and machine learning to classify megafauna could be used to automate annotation of underwater images. For this purpose multiple large data sets of citizen science annotations with different degrees of common errors and inaccuracies observed in citizen science data were simulated by modifying "gold standard" annotations done by an experienced marine biologist. The parameters of the simulation were determined on the basis of two citizen science experiments. It allowed us to analyze the relationship between the outcome of a citizen science study and the quality of the classifications of a deep learning megafauna classifier. The results show great potential for combining citizen science with machine learning provided that the participants are informed precisely about the annotation protocol. Inaccuracies in the position of the annotation had the most substantial influence on the classification accuracy whereas the size of the marking and false positive detections had a smaller influence. On the impact of Citizen Science-derived data quality on deep learning based classification in marine images.
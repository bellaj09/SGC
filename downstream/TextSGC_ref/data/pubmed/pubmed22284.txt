Animals continuously rely on sensory feedback to adjust motor commands. In order to study the role of visual feedback in goal-driven navigation we developed a 2D visual virtual reality system for zebrafish larvae. The visual feedback can be set to be similar to what the animal experiences in natural conditions. Alternatively modification of the visual feedback can be used to study how the brain adapts to perturbations. For this purpose we first generated a library of free-swimming behaviors from which we learned the relationship between the trajectory of the larva and the shape of its tail. Then we used this technique to infer the intended displacements of head-fixed larvae and updated the visual environment accordingly. Under these conditions larvae were capable of aligning and swimming in the direction of a whole-field moving stimulus and produced the fine changes in orientation and position required to capture virtual prey. We demonstrate the sensitivity of larvae to visual feedback by updating the visual world in real-time or only at the end of the discrete swimming episodes. This visual feedback perturbation caused impaired performance of prey-capture behavior suggesting that larvae rely on continuous visual feedback during swimming. A 2D virtual reality system for visual goal-driven navigation in zebrafish larvae.
Skin lesion datasets consist predominantly of normal samples with only a small percentage of abnormal ones giving rise to the class imbalance problem. Also skin lesion images are largely similar in overall appearance owing to the low inter-class variability. In this paper we propose a two-stage framework for automatic classification of skin lesion images using adversarial training and transfer learning toward melanoma detection. In the first stage we leverage the inter-class variation of the data distribution for the task of conditional image synthesis by learning the inter-class mapping and synthesizing under-represented class samples from the over-represented ones using unpaired image-to-image translation. In the second stage we train a deep convolutional neural network for skin lesion classification using the original training set combined with the newly synthesized under-represented class samples. The training of this classifier is carried out by minimizing the focal loss function which assists the model in learning from hard examples while down-weighting the easy ones. Experiments conducted on a dermatology image benchmark demonstrate the superiority of our proposed approach over several standard baseline methods achieving significant performance improvements. Interestingly we show through feature visualization and analysis that our method leads to context based lesion assessment that can reach an expert dermatologist level. Melanoma detection using adversarial training and deep transfer learning.
The recognition performance of visual recognition systems is highly dependent on extracting and representing the discriminative characteristics of image data. Convolutional neural networks CNNs have shown unprecedented success in a variety of visual recognition tasks due to their capability to provide in-depth representations exploiting visual image features of appearance color and texture. This paper presents a novel system for ear recognition based on ensembles of deep CNN-based models and more specifically the Visual Geometry Group VGG-like network architectures for extracting discriminative deep features from ear images. We began by training different networks of increasing depth on ear images with random weight initialization. Then we examined pretrained models as feature extractors as well as fine-tuning them on ear images. After that we built ensembles of the best models to further improve the recognition performance. We evaluated the proposed ensembles through identification experiments using ear images acquired under controlled and uncontrolled conditions from mathematical analysis of images AMI AMI cropped AMIC introduced here and West Pomeranian University of Technology WPUT ear datasets. The experimental results indicate that our ensembles of models yield the best performance with significant improvements over the recently published results. Moreover we provide visual explanations of the learned features by highlighting the relevant image regions utilized by the models for making decisions or predictions. Ensembles of Deep Learning Models and Transfer Learning for Ear Recognition.
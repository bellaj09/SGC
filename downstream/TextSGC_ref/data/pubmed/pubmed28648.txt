Several recent studies demonstrate the possibility of using user initiated covert speech mental tasks in brain computer interfaces with varying degrees of success but details of the best frequency features had not been investigated. In this work ten volunteers in the age range of 22-70 years participated in the experiment. Eight of them were neurologically healthy one user was dyslexic and another was autistic. The four words "back" "forward" "left" and "right" were shortened into "BA" "FO" "LE" and "RY" which are phonetically dissimilar and cognitively relevant directional commands. Participants were asked to covertly speak each as soon as the letters appeared on a screen. Volunteers completed five recording runs. During each run the four words were presented in random succession to avoid sequence bias. The recorded EEG data from the ten users were analysed to discover the best features within a Gabor Transform of the signals i.e. those yielding the highest word-pair classification accuracy for this specific type of linguistic mental activity. Using this BCI suitable class separability of covert speech tasks is confirmed for all including disabled users with consistently high classification accuracy from 72% to 88% in all cases. Like motor imagery tasks Alpha and Beta band activity were found to contain 12% and 31% of the most important features respectively. Gamma band activity which indicates high mental functions contains 57% of the most important features in this study. The contribution of different frequency bands in class separability of covert speech tasks for BCIs.
This paper addresses issues of brain tumor glioma grading from multi-sensor images. Different types of scanners or sensors like enhanced T1-MRI T2-MRI and FLAIR show different contrast and are sensitive to different brain tissues and fluid regions. Most existing works use 3D brain images from single sensor. In this paper we propose a novel multistream deep Convolutional Neural Network CNN architecture that extracts and fuses the features from multiple sensors for glioma tumor grading/subcategory grading. The main contributions of the paper are: a propose a novel multistream deep CNN architecture for glioma grading; b apply sensor fusion from T1-MRI T2-MRI and/or FLAIR for enhancing performance through feature aggregation; c mitigate overfitting by using 2D brain image slices in combination with 2D image augmentation. Two datasets were used for our experiments one for classifying low/high grade gliomas another for classifying glioma with/without 1p19q codeletion. Experiments using the proposed scheme have shown good results with test accuracy of 90.87% for former case and 89.39 % for the latter case. Comparisons with several existing methods have provided further support to the proposed scheme. keywords: brain tumor classification glioma 1p19q codeletion glioma grading deep learning multi-stream convolutional neural networks sensor fusion T1-MR image T2-MR image FLAIR. Deep Learning and Multi-Sensor Fusion for Glioma Classification Using Multistream 2D Convolutional Networks.
Realizing the decoding of brain signals into control commands brain-computer interfaces BCI aim to establish an alternative communication pathway for locked-in patients. In contrast to most visual BCI approaches which use event-related potentials ERP of the electroencephalogram auditory BCI systems are challenged with ERP responses which are less class-discriminant between attended and unattended stimuli. Furthermore these auditory approaches have more complex interfaces which imposes a substantial workload on their users. Aiming for a maximally user-friendly spelling interface this study introduces a novel auditory paradigm: "CharStreamer". The speller can be used with an instruction as simple as "please attend to what you want to spell". The stimuli of CharStreamer comprise 30 spoken sounds of letters and actions. As each of them is represented by the sound of itself and not by an artificial substitute it can be selected in a one-step procedure. The mental mapping effort sound stimuli to actions is thus minimized. Usability is further accounted for by an alphabetical stimulus presentation: contrary to random presentation orders the user can foresee the presentation time of the target letter sound. Healthy normal hearing users n\u200a=\u200a10 of the CharStreamer paradigm displayed ERP responses that systematically differed between target and non-target sounds. Class-discriminant features however varied individually from the typical N1-P2 complex and P3 ERP components found in control conditions with random sequences. To fully exploit the sequential presentation structure of CharStreamer novel data analysis approaches and classification methods were introduced. The results of online spelling tests showed that a competitive spelling speed can be achieved with CharStreamer. With respect to user rating it clearly outperforms a control setup with random presentation sequences. Towards user-friendly spelling with an auditory brain-computer interface: the CharStreamer paradigm.
Laryngeal endoscopy is one of the primary diagnostic tools for laryngeal disorders. The main techniques are videostroboscopy and lately high-speed video endoscopy. Unfortunately due to the restricting anatomy of the larynx and technical limitations of the recording equipment many videos suffer from insufficient illumination which complicates clinical examination and analysis. This work presents an approach to enhance low-light images from high-speed video endoscopy using a convolutional neural network. We introduce a new technique to generate realistically darkened training samples using Perlin noise. Extensive data augmentation is employed to cope with the limited training data allowing training with just 55 videos. The approach is compared against four state-of-the-art low-light enhancement methods and statistically significantly outperforms each on a no-reference NIQE and two full-reference PSNR SSIM image quality metrics. The presented approach can be run on consumer-grade hardware and is thereby directly applicable in a clinical context. It is likely transferable to similar techniques such as videostroboscopy. Graphical Abstract The basic setup for training and employing an improved fully convolutional U-Net neural network to predict a brightness map used to enhance the lighting of ill-lit endoscopic high-speed videos - Artificially darkened training data are created using Perlin noise to allow region-specific darkening. Low-light image enhancement of high-speed endoscopic videos using a convolutional neural network.
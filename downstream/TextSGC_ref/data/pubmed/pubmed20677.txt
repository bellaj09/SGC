The purpose of this study is to classify EEG data on imagined speech in a single trial. We recorded EEG data while five subjects imagined different vowels /a/ /e/ /i/ /o/ and /u/. We divided each single trial dataset into thirty segments and extracted features mean variance standard deviation and skewness from all segments. To reduce the dimension of the feature vector we applied a feature selection algorithm based on the sparse regression model. These features were classified using a support vector machine with a radial basis function kernel an extreme learning machine and two variants of an extreme learning machine with different kernels. Because each single trial consisted of thirty segments our algorithm decided the label of the single trial by selecting the most frequent output among the outputs of the thirty segments. As a result we observed that the extreme learning machine and its variants achieved better classification rates than the support vector machine with a radial basis function kernel and linear discrimination analysis. Thus our results suggested that EEG responses to imagined speech could be successfully classified in a single trial using an extreme learning machine with a radial basis function and linear kernel. This study with classification of imagined speech might contribute to the development of silent speech BCI systems. Vowel Imagery Decoding toward Silent Speech BCI Using Extreme Learning Machine with Electroencephalogram.
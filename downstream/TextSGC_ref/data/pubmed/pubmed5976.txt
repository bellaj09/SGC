DICOM header information is frequently used to classify medical image types; however if a header is missing fields or contains incorrect data the utility is limited. To expedite image classification we trained convolutional neural networks CNNs in two classification tasks for thoracic radiographic views obtained from dual-energy studies: a\xa0distinguishing between frontal lateral soft tissue and bone images and b\xa0distinguishing between posteroanterior PA or anteroposterior AP chest radiographs. CNNs with AlexNet architecture were trained from scratch. 1910 manually classified radiographs were used for training the network to accomplish task a then tested with an independent test set 3757 images. Frontal radiographs from the two datasets were combined to train a network to accomplish task b; tested using an independent test set of 1000 radiographs. ROC analysis was performed for each trained CNN with area under the curve AUC as a performance metric. Classification between frontal images AP/PA and other image types yielded an AUC of 0.997 95% confidence interval CI: 0.996 0.998. Classification between PA and AP radiographs resulted in an AUC of 0.973 95% CI: 0.961 0.981. CNNs were able to rapidly classify thoracic radiographs with high accuracy thus potentially contributing to effective and efficient workflow. Deep convolutional neural networks in the classification of dual-energy thoracic radiographic views for efficient workflow: analysis on over 6500 clinical radiographs.
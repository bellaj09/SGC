Brain-computer interfaces that directly decode speech could restore communication to locked-in individuals. However decoding speech from brain signals still faces many challenges. We investigated decoding of phonemes - the smallest separable parts of speech - from ECoG signals during word production. We expanded on previous efforts to identify specific phoneme by identifying phonemes by where in the word they were formed. We evaluated how the context of phonemes in words affects classification results using linear discriminant analysis. The decoding accuracy of our linear classifier indicated the degree to which the context of a phoneme can be determined from the cortical signal significantly greater than chance. Further we identified the spectrotemporal features that contributed most to successful decoding of phonemic classes. Finally we discuss how this can augment speech decoding for neural interfaces. Cortical encoding of phonemic context during word production.
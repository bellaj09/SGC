Recent years have witnessed the success of deep learning methods in human activity recognition HAR. The longstanding shortage of labeled activity data inherently calls for a plethora of semisupervised learning methods and one of the most challenging and common issues with semisupervised learning is the imbalanced distribution of labeled data over classes. Although the problem has long existed in broad real-world HAR applications it is rarely explored in the literature. In this paper we propose a semisupervised deep model for imbalanced activity recognition from multimodal wearable sensory data. We aim to address not only the challenges of multimodal sensor data e.g. interperson variability and interclass similarity but also the limited labeled data and class-imbalance issues simultaneously. In particular we propose a pattern-balanced semisupervised framework to extract and preserve diverse latent patterns of activities. Furthermore we exploit the independence of multi-modalities of sensory data and attentively identify salient regions that are indicative of human activities from inputs by our recurrent convolutional attention networks. Our experimental results demonstrate that the proposed model achieves a competitive performance compared to a multitude of state-of-the-art methods both semisupervised and supervised ones with 10% labeled training data. The results also show the robustness of our method over imbalanced small training data sets. A Semisupervised Recurrent Convolutional Attention Model for Human Activity Recognition.
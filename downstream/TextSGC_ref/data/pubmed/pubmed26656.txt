Machine learning techniques are increasingly used in neuroscience to classify brain signals. Decoding performance is reflected by how much the classification results depart from the rate achieved by purely random classification. In a 2-class or 4-class classification problem the chance levels are thus 50% or 25% respectively. However such thresholds hold for an infinite number of data samples but not for small data sets. While this limitation is widely recognized in the machine learning field it is unfortunately sometimes still overlooked or ignored in the emerging field of brain signal classification. Incidentally this field is often faced with the difficulty of low sample size. In this study we demonstrate how applying signal classification to Gaussian random signals can yield decoding accuracies of up to 70% or higher in two-class decoding with small sample sets. Most importantly we provide a thorough quantification of the severity and the parameters affecting this limitation using simulations in which we manipulate sample size class number cross-validation parameters k-fold leave-one-out and repetition number and classifier type Linear-Discriminant Analysis Nave Bayesian and Support Vector Machine. In addition to raising a red flag of caution we illustrate the use of analytical and empirical solutions binomial formula and permutation tests that tackle the problem by providing statistical significance levels p-values for the decoding accuracy taking sample size into account. Finally we illustrate the relevance of our simulations and statistical tests on real brain data by assessing noise-level classifications in Magnetoencephalography MEG and intracranial EEG iEEG baseline recordings. Exceeding chance level by chance: The caveat of theoretical chance levels in brain signal classification and statistical assessment of decoding accuracy.
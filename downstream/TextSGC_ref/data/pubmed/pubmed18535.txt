Despite decades of societal investment in artificial learning systems truly "intelligent" systems have yet to be realized. These traditional models are based on input-output pattern optimization and/or cognitive production rule modeling. One response has been social robotics using the interaction of human and robot to capture important cognitive dynamics such as cooperation and emotion; to date these systems still incorporate traditional learning algorithms. More recently investigators are focusing on the core assumptions of the brain "algorithm" itself-trying to replicate uniquely "neuromorphic" dynamics such as action potential spiking and synaptic learning. Only now are large-scale neuromorphic models becoming feasible due to the availability of powerful supercomputers and an expanding supply of parameters derived from research into the brain\s interdependent electrophysiological metabolomic and genomic networks. Personal computer technology has also led to the acceptance of computer-generated humanoid images or "avatars" to represent intelligent actors in virtual realities. In a recent paper we proposed a method of virtual neurorobotics VNR in which the approaches above social-emotional robotics neuromorphic brain architectures and virtual reality projection are hybridized to rapidly forward-engineer and develop increasingly complex intrinsically intelligent systems. In this paper we synthesize our research and related work in the field and provide a framework for VNR with wider implications for research and practical applications. Framework and implications of virtual neurorobotics.
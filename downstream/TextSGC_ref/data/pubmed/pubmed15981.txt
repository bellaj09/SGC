"Convolutional neural networks CNNs have become the architecture of choice for visual recognition tasks. However these models are perceived as black boxes since there is a lack of understanding of the learned behavior from the underlying task of interest. This lack of transparency is a serious drawback particularly in applications involving medical screening and diagnosis since poorly understood model behavior could adversely impact subsequent clinical decision-making. Recently researchers have begun working on this issue and several methods have been proposed to visualize and understand the behavior of these models. We highlight the advantages offered through visualizing and understanding the weights saliencies class activation maps and region of interest localizations in customized CNNs applied to the challenge of classifying parasitized and uninfected cells to aid in malaria screening. We provide an explanation for the models classification decisions. We characterize evaluate and statistically validate the performance of different customized CNNs keeping every training subjects data separate from the validation set." Understanding the learned behavior of customized convolutional neural networks toward malaria parasite detection in thin blood smear images.
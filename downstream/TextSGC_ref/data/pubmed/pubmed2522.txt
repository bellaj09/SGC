Robust efficient and low-cost networks are advantageous in both biological and engineered systems. During neural network development in the brain synapses are massively over-produced and then pruned-back over time. This strategy is not commonly used when designing engineered networks since adding connections that will soon be removed is considered wasteful. Here we show that for large distributed routing networks network function is markedly enhanced by hyper-connectivity followed by aggressive pruning and that the global rate of pruning a developmental parameter not previously studied by experimentalists plays a critical role in optimizing network structure. We first used high-throughput image analysis techniques to quantify the rate of pruning in the mammalian neocortex across a broad developmental time window and found that the rate is decreasing over time. Based on these results we analyzed a model of computational routing networks and show using both theoretical analysis and simulations that decreasing rates lead to more robust and efficient networks compared to other rates. We also present an application of this strategy to improve the distributed design of airline networks. Thus inspiration from neural network formation suggests effective ways to design distributed networks across several domains. Decreasing-Rate Pruning Optimizes the Construction of Efficient and Robust Distributed Networks.
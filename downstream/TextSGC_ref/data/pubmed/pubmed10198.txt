"An unmanned aerial vehicle UAV equipped with global positioning systems GPS can provide direct georeferenced imagery mapping an area with high resolution. So far the major difficulty in wildfire image classification is the lack of unified identification marks the fire features of color shape texture smoke flame or both and background can vary significantly from one scene to another. Deep learning e.g. DCNN for Deep Convolutional Neural Network is very effective in high-level feature learning however a substantial amount of training images dataset is obligatory in optimizing its weights value and coefficients. In this work we proposed a new saliency detection algorithm for fast location and segmentation of core fire area in aerial images. As the proposed method can effectively avoid feature loss caused by direct resizing; it is used in data augmentation and formation of a standard fire image dataset UAV_Fire. A 15-layered self-learning DCNN architecture named Fire_Net is then presented as a self-learning fire feature exactor and classifier. We evaluated different architectures and several key parameters drop out ratio batch size etc. of the DCNN model regarding its validation accuracy. The proposed architecture outperformed previous methods by achieving an overall accuracy of 98%. Furthermore Fire_Net guarantied an average processing speed of 41.5 ms per image for real-time wildfire inspection. To demonstrate its practical utility Fire_Net is tested on 40 sampled images in wildfire news reports and all of them have been accurately identified." Saliency Detection and Deep Learning-Based Wildfire Identification in UAV Imagery.
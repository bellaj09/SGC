"Artificial Intelligence is exponentially increasing its impact on healthcare. As deep learning is mastering computer vision tasks its application to digital pathology is natural with the promise of aiding in routine reporting and standardizing results across trials. Deep learning features inferred from digital pathology scans can improve validity and robustness of current clinico-pathological features up to identifying novel histological patterns e.g. from tumor infiltrating lymphocytes. In this study we examine the issue of evaluating accuracy of predictive models from deep learning features in digital pathology as an hallmark of reproducibility. We introduce the DAPPER framework for validation based on a rigorous Data Analysis Plan derived from the FDAs MAQC project designed to analyze causes of variability in predictive biomarkers. We apply the framework on models that identify tissue of origin on 787 Whole Slide Images from the Genotype-Tissue Expression GTEx project. We test three different deep learning architectures VGG ResNet Inception as feature extractors and three classifiers a fully connected multilayer Support Vector Machine and Random Forests and work with four datasets 5 10 20 or 30 classes for a total of 53 000 tiles at 512  512 resolution. We analyze accuracy and feature stability of the machine learning classifiers also demonstrating the need for diagnostic tests e.g. random labels to identify selection bias and risks for reproducibility. Further we use the deep features from the VGG model from GTEx on the KIMIA24 dataset for identification of slide of origin 24 classes to train a classifier on 1 060 annotated tiles and validated on 265 unseen ones. The DAPPER software including its deep learning pipeline and the Histological Imaging-Newsy Tiles HINT benchmark dataset derived from GTEx is released as a basis for standardization and validation initiatives in AI for digital pathology." Evaluating reproducibility of AI algorithms in digital pathology with DAPPER.
Recent advancements in deep learning have shown exciting promise in the urban street scene segmentation. However many objects such as poles and sign symbols are relatively small and they usually cannot be accurately segmented since the larger objects usually contribute more to the segmentation loss. In this paper we propose a new boundary-based metric that measures the level of spatial adjacency between each pair of object classes and find that this metric is robust against object size induced biases. We develop a new method to enforce this metric into the segmentation loss. We propose a network which starts with a segmentation network followed by a new encoder to compute the proposed boundary-based metric and then trains this network in an end-to-end fashion. In deployment we only use the trained segmentation network without the encoder to segment new unseen images. Experimentally we evaluate the proposed method using CamVid and CityScapes datasets and achieve a favorable overall performance improvement and a substantial improvement in segmenting small objects. Small Object Sensitive Segmentation of Urban Street Scene with Spatial Adjacency Between Object Classes.
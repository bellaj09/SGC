Explicit structural inference is one key point to improve the accuracy of scene parsing. Meanwhile adversarial training method is able to reinforce spatial contiguity in output segmentations. To take both advantages of the structural learning and adversarial training simultaneously we propose a novel deep learning network architecture called Structural Inference Embedded Adversarial Networks SIEANs for pixel-wise scene labeling. The generator of our SIEANs a novel designed scene parsing network makes full use of convolutional neural networks and long short-term memory networks to learn the global contextual information of objects in four different directions from RGB-D images which is able to describe the three-dimensional spatial distributions of objects in a more comprehensive and accurate way. To further improve the performance we explore the adversarial training method to optimize the generator along with a discriminator which can not only detect and correct higher-order inconsistencies between the predicted segmentations and corresponding ground truths but also exploit full advantages of the generator by fine-tuning its parameters so as to obtain higher consistencies. The experimental results demonstrate that our proposed SIEANs is able to achieve a better performance on PASCAL VOC 2012 SIFT FLOW PASCAL Person-Part Cityscapes Stanford Background NYUDv2 and SUN-RGBD datasets compared to the most of state-of-the-art methods. Structural inference embedded adversarial networks for scene parsing.
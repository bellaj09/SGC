Humans experience the self as localized within their body. This aspect of bodily self-consciousness can be experimentally manipulated by exposing individuals to conflicting multisensory input or can be abnormal following focal brain injury. Recent technological developments helped to unravel some of the mechanisms underlying multisensory integration and self-location but the neural underpinnings are still under investigation and the manual application of stimuli resulted in large variability difficult to control. This paper presents the development and evaluation of an MR-compatible stroking device capable of presenting moving tactile stimuli to both legs and the back of participants lying on a scanner bed while acquiring functional neuroimaging data. The platform consists of four independent stroking devices with a travel of 16-20 cm and a maximum stroking velocity of 15 cm/s actuated over non-magnetic ultrasonic motors. Complemented with virtual reality this setup provides a unique research platform allowing to investigate multisensory integration and its effects on self-location under well-controlled experimental conditions. The MR-compatibility of the system was evaluated in both a 3 and a 7 Tesla scanner and showed negligible interference with brain imaging. In a preliminary study using a prototype device with only one tactile stimulator fMRI data acquired on 12 healthy participants showed visuo-tactile synchrony-related and body-specific modulations of the brain activity in bilateral temporoparietal cortex. Neuroscience robotics to investigate multisensory integration and bodily awareness.
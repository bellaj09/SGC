Cognitive neuroscience has seen rapid growth in the size and complexity of data recorded from the human brain as well as in the computational tools available to analyze this data. This data explosion has resulted in an increased use of multivariate model-based methods for asking neuroscience questions allowing scientists to investigate multiple hypotheses with a single dataset to use complex time-varying stimuli and to study the human brain under more naturalistic conditions. These tools come in the form of "Encoding" models in which stimulus features are used to model brain activity and "Decoding" models in which neural features are used to generated a stimulus output. Here we review the current state of encoding and decoding models in cognitive electrophysiology and provide a practical guide toward conducting experiments and analyses in this emerging field. Our examples focus on using linear models in the study of human language and audition. We show how to calculate auditory receptive fields from natural sounds as well as how to decode neural recordings to predict speech. The paper aims to be a useful tutorial to these approaches and a practical introduction to using machine learning and applied statistics to build models of neural activity. The data analytic approaches we discuss may also be applied to other sensory modalities motor systems and cognitive systems and we cover some examples in these areas. In addition a collection of Jupyter notebooks is publicly available as a complement to the material covered in this paper providing code examples and tutorials for predictive modeling in python. The aim is to provide a practical understanding of predictive modeling of human brain data and to propose best-practices in conducting these analyses. Encoding and Decoding Models in Cognitive Electrophysiology.
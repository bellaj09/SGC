Current neural networks for predictions of molecular properties use quantum chemistry only as a source of training data. This paper explores models that use quantum chemistry as an integral part of the prediction process. This is done by implementing self-consistent-charge Density-Functional-Tight-Binding DFTB theory as a layer for use in deep learning models. The DFTB layer takes as input Hamiltonian matrix elements generated from earlier layers and produces as output electronic properties from self-consistent field solutions of the corresponding DFTB Hamiltonian. Backpropagation enables efficient training of the model to target electronic properties. Two types of input to the DFTB layer are explored splines and feed-forward neural networks. Because overfitting can cause models trained on smaller molecules to perform poorly on larger molecules regularizations are applied that penalize nonmonotonic behavior and deviation of the Hamiltonian matrix elements from those of the published DFTB model used to initialize the model. The approach is evaluated on 15\u202f700 hydrocarbons by comparing the root-mean-square error in energy and dipole moment on test molecules with eight heavy atoms to the error from the initial DFTB model. When trained on molecules with up to seven heavy atoms the spline model reduces the test error in energy by 60% and in dipole moments by 42%. The neural network model performs somewhat better with error reductions of 67% and 59% respectively. Training on molecules with up to four heavy atoms reduces performance with both the spline and neural net models reducing the test error in energy by about 53% and in dipole by about 25%. A Density Functional Tight Binding Layer for Deep Learning of Chemical Hamiltonians.
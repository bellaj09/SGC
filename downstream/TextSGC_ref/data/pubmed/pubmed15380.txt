There is good evidence that simple animals such as bees use view-based strategies to return to a familiar location whereas humans might use a 3-D reconstruction to achieve the same goal. Assuming some noise in the storage and retrieval process these two types of strategy give rise to different patterns of predicted errors in homing. We describe an experiment that can help distinguish between these models. Participants wore a head-mounted display to carry out a homing task in immersive virtual reality. They viewed three long thin vertical poles and had to remember where they were in relation to the poles before being transported virtually to a new location in the scene from where they had to walk back to the original location. The experiment was conducted in both a rich-cue scene a furnished room and a sparse scene no background and no floor or ceiling. As one would expect in a rich-cue environment the overall error was smaller and in this case the ability to separate the models was reduced. However for the sparse-cue environment the view-based model outperforms the reconstruction-based model. Specifically the likelihood of the experimental data is similar to the likelihood of samples drawn from the view-based model but assessed under both models and this is not true for samples drawn from the reconstruction-based model. Comparison of view-based and reconstruction-based models of human navigational strategy.
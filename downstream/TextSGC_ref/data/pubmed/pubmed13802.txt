How to effectively retrieve desired 3D models with simple queries is a long-standing problem in computer vision community. The model-based approach is quite straightforward but nontrivial since people could not always have the desired 3D query model available by side. Recently large amounts of wide-screen electronic devices are prevail in our daily lives which makes the sketch-based 3D shape retrieval a promising candidate due to its simpleness and efficiency. The main challenge of sketch-based approach is the huge modality gap between sketch and 3D shape. In this paper we proposed a novel deep correlated holistic metric learning DCHML method to mitigate the discrepancy between sketch and 3D shape domains. The proposed DCHML trains two distinct deep neural networks one for each domain jointly which learns two deep nonlinear transformations to map features from both domains into a new feature space. The proposed loss including discriminative loss and correlation loss aims to increase the discrimination of features within each domain as well as the correlation between different domains. In the new feature space the discriminative loss minimizes the intra-class distance of the deep transformed features and maximizes the inter-class distance of the deep transformed features to a large margin within each domain while the correlation loss focused on mitigating the distribution discrepancy across different domains. Different from existing deep metric learning methods only with loss at the output layer our proposed DCHML is trained with loss at both hidden layer and output layer to further improve the performance by encouraging features in the hidden layer also with desired properties. Our proposed method is evaluated on three benchmarks including 3D Shape Retrieval Contest 2013 2014 and 2016 benchmarks and the experimental results demonstrate the superiority of our proposed method over the state-of-the-art methods. Deep Correlated Holistic Metric Learning for Sketch-Based 3D Shape Retrieval.
Live-cell imaging has opened an exciting window into the role cellular heterogeneity plays in dynamic living systems. A major critical challenge for this class of experiments is the problem of image segmentation or determining which parts of a microscope image correspond to which individual cells. Current approaches require many hours of manual curation and depend on approaches that are difficult to share between labs. They are also unable to robustly segment the cytoplasms of mammalian cells. Here we show that deep convolutional neural networks a supervised machine learning method can solve this challenge for multiple cell types across the domains of life. We demonstrate that this approach can robustly segment fluorescent images of cell nuclei as well as phase images of the cytoplasms of individual bacterial and mammalian cells from phase contrast images without the need for a fluorescent cytoplasmic marker. These networks also enable the simultaneous segmentation and identification of different mammalian cell types grown in co-culture. A quantitative comparison with prior methods demonstrates that convolutional neural networks have improved accuracy and lead to a significant reduction in curation time. We relay our experience in designing and optimizing deep convolutional neural networks for this task and outline several design rules that we found led to robust performance. We conclude that deep convolutional neural networks are an accurate method that require less curation time are generalizable to a multiplicity of cell types from bacteria to mammalian cells and expand live-cell imaging capabilities to include multi-cell type systems. Deep Learning Automates the Quantitative Analysis of Individual Cells in Live-Cell Imaging Experiments.
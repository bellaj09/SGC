We propose a new combination of deep belief networks and sparse manifold learning strategies for the 2D segmentation of non-rigid visual objects. With this novel combination we aim to reduce the training and inference complexities while maintaining the accuracy of machine learning-based non-rigid segmentation methodologies. Typical non-rigid object segmentation methodologies divide the problem into a rigid detection followed by a non-rigid segmentation where the low dimensionality of the rigid detection allows for a robust training i.e. a training that does not require a vast amount of annotated images to estimate robust appearance and shape models and a fast search process during inference. Therefore it is desirable that the dimensionality of this rigid transformation space is as small as possible in order to enhance the advantages brought by the aforementioned division of the problem. In this paper we propose the use of sparse manifolds to reduce the dimensionality of the rigid detection space. Furthermore we propose the use of deep belief networks to allow for a training process that can produce robust appearance models without the need of large annotated training sets. We test our approach in the segmentation of the left ventricle of the heart from ultrasound images and lips from frontal face images. Our experiments show that the use of sparse manifolds and deep belief networks for the rigid detection stage leads to segmentation results that are as accurate as the current state of the art but with lower search complexity and training processes that require a small amount of annotated training data. Deep Learning on Sparse Manifolds for Faster Object Segmentation.
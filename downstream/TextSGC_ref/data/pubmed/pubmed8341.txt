Instance transfer approaches consider source and target data together during the training process and borrow examples from the source domain to augment the training data when there is limited or no label in the target domain. Among them boosting-based transfer learning methods e.g. TrAdaBoost are most widely used. When dealing with more complex data we may consider the more complex hypotheses e.g. a decision tree with deeper layers. However with the fixed and high complexity of the hypotheses TrAdaBoost and its variants may face the overfitting problems. Even worse in the transfer learning scenario a decision tree with deep layers may overfit different distribution data in the source domain. In this paper we propose a new instance transfer learning method i.e. Deep Decision Tree Transfer Boosting DTrBoost whose weights are learned and assigned to base learners by minimizing the data-dependent learning bounds across both source and target domains in terms of the Rademacher complexities. This guarantees that we can learn decision trees with deep layers without overfitting. The theorem proof and experimental results indicate the effectiveness of our proposed method. Deep Decision Tree Transfer Boosting.
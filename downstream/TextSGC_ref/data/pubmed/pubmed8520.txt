The segmentation of buildings in remote-sensing RS images plays an important role in monitoring landscape changes. Quantification of these changes can be used to balance economic and environmental benefits and most importantly to support the sustainable urban development. Deep learning has been upgrading the techniques for RS image analysis. However it requires a large-scale data set for hyper-parameter optimization. To address this issue the concept of "one view per city" is proposed and it explores the use of one RS image for parameter settings with the purpose of handling the rest images of the same city by the trained model. The proposal of this concept comes from the observation that buildings of a same city in single-source RS images demonstrate similar intensity distributions. To verify the feasibility a proof-of-concept study is conducted and five fully convolutional networks are evaluated on five cities in the Inria Aerial Image Labeling database. Experimental results suggest that the concept can be explored to decrease the number of images for model training and it enables us to achieve competitive performance in buildings segmentation with decreased time consumption. Based on model optimization and universal image representation it is full of potential to improve the segmentation performance to enhance the generalization capacity and to extend the application of the concept in RS image analysis. One View Per City for Buildings Segmentation in Remote-Sensing Images via Fully Convolutional Networks: A Proof-of-Concept Study.
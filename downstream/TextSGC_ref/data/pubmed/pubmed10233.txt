We propose a new deep learning approach for medical imaging that copes with the problem of a small training set the main bottleneck of deep learning and apply it for classification of healthy and cancer cell lines acquired by quantitative phase imaging. The proposed method called transferring of pre-trained generative adversarial network TOP-GAN is hybridization between transfer learning and generative adversarial networks GANs. Healthy cells and cancer cells of different metastatic potential have been imaged by low-coherence off-axis holography. After the acquisition the optical path delay maps of the cells are extracted and directly used as inputs to the networks. In order to cope with the small number of classified images we use GANs to train a large number of unclassified images from another cell type sperm cells. After this preliminary training we change the last layers of the network and design automatic classifiers for the correct cell type healthy/primary cancer/metastatic cancer with 90-99% accuracies although small training sets of down to several images are used. These results are better in comparison to other classic methods that aim at coping with the same problem of a small training set. We believe that our approach makes the combination of holographic microscopy and deep learning networks more accessible to the medical field by enabling a rapid automatic and accurate classification in stain-free imaging flow cytometry. Furthermore our approach is expected to be applicable to many other medical image classification tasks suffering from a small training set. TOP-GAN: Stain-free cancer cell classification using deep learning with a small training set.
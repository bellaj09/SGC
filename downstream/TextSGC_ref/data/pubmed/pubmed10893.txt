"Complementary Learning Systems CLS theory suggests that the brain uses a neocortical and a hippocampal learning system to achieve complex behaviour. These two systems are complementary in that the neocortical system relies on slow learning of distributed representations while the hippocampal system relies on fast learning of pattern-separated representations. Both of these systems project to the striatum which is a key neural structure in the brains implementation of Reinforcement Learning RL. Current deep RL approaches share similarities with a neocortical system because they slowly learn distributed representations through backpropagation in Deep Neural Networks DNNs. An ongoing criticism of such approaches is that they are data inefficient and lack flexibility. CLS theory suggests that the addition of a hippocampal system could address these criticisms. In the present study we propose a novel algorithm known as Complementary Temporal Difference Learning CTDL which combines a DNN with a Self-Organizing Map SOM to obtain the benefits of both a neocortical and a hippocampal system. Key features of CTDL include the use of Temporal Difference TD error to update a SOM and the combination of a SOM and DNN to calculate action values. We evaluate CTDL on Grid World Cart-Pole and Continuous Mountain Car tasks and show several benefits over the classic Deep Q-Network DQN approach. These results demonstrate 1 the utility of complementary learning systems for the evaluation of actions 2 that the TD error signal is a useful form of communication between the two systems and 3 that our approach extends to both discrete and continuous state and action spaces." A complementary learning systems approach to temporal difference learning.
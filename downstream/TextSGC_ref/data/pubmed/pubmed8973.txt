The explosive increase of biomedical literature has made information extraction an increasingly important tool for biomedical research. A fundamental task is the recognition of biomedical named entities in text BNER such as genes/proteins diseases and species. Recently a domain-independent method based on deep learning and statistical word embeddings called long short-term memory network-conditional random field LSTM-CRF has been shown to outperform state-of-the-art entity-specific BNER tools. However this method is dependent on gold-standard corpora GSCs consisting of hand-labeled entities which tend to be small but highly reliable. An alternative to GSCs are silver-standard corpora SSCs which are generated by harmonizing the annotations made by several automatic annotation systems. SSCs typically contain more noise than GSCs but have the advantage of containing many more training examples. Ideally these corpora could be combined to achieve the benefits of both which is an opportunity for transfer learning. In this work we analyze to what extent transfer learning improves upon state-of-the-art results for BNER. Transfer learning for biomedical named entity recognition with neural networks.
Facial expression is central to human experience but most previous databases and studies are limited to posed facial behavior under controlled conditions. In this paper we present a novel facial expression database Real-world Affective Face Database RAF-DB which contains approximately 30 000 facial images with uncontrolled poses and illumination from thousands of individuals of diverse ages and races. During the crowdsourcing annotation each image is independently labeled by approximately 40 annotators. An expectation-maximization algorithm is developed to reliably estimate the emotion labels which reveals that real-world faces often express compound or even mixture emotions. A cross-database study between RAF-DB and CK+ database further indicates that the action units of real-world emotions are much more diverse than or even deviate from those of laboratory-controlled emotions. To address the recognition of multi-modal expressions in the wild we propose a new deep locality-preserving convolutional neural network DLP-CNN method that aims to enhance the discriminative power of deep features by preserving the locality closeness while maximizing the inter-class scatter. Benchmark experiments on 7-class basic expressions and 11-class compound expressions as well as additional experiments on CK+ MMI and SFEW 2.0 databases show that the proposed DLP-CNN outperforms the state-of-the-art handcrafted features and deep learning-based methods for expression recognition in the wild. To promote further study we have made the RAF database benchmarks and descriptor encodings publicly available to the research community. Reliable Crowdsourcing and Deep Locality-Preserving Learning for Unconstrained Facial Expression Recognition.
Recent trends in image understanding have pushed for scene understanding models that jointly reason about various tasks such as object detection scene recognition shape analysis contextual reasoning and local appearance based classifiers. In this work we are interested in understanding the roles of these different tasks in improved scene understanding in particular semantic segmentation object detection and scene recognition. Towards this goal we "plug-in" human subjects for each of the various components in a conditional random field model. Comparisons among various hybrid human-machine CRFs give us indications of how much "head room" there is to improve scene understanding by focusing research efforts on various individual tasks. Human-Machine CRFs for Identifying Bottlenecks in Scene Understanding.
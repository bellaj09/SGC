Accurate medical image segmentation is essential for diagnosis surgical planning and many other applications. Convolutional Neural Networks CNNs have become the state-of-the-art automatic segmentation methods. However fully automatic results may still need to be refined to become accurate and robust enough for clinical use. We propose a deep learning-based interactive segmentation method to improve the results obtained by an automatic CNN and to reduce user interactions during refinement for higher accuracy. We use one CNN to obtain an initial automatic segmentation on which user interactions are added to indicate mis-segmentations. Another CNN takes as input the user interactions with the initial segmentation and gives a refined result. We propose to combine user interactions with CNNs through geodesic distance transforms and propose a resolution-preserving network that gives a better dense prediction. In addition we integrate user interactions as hard constraints into a back-propagatable Conditional Random Field. We validated the proposed framework in the context of 2D placenta segmentation from fetal MRI and 3D brain tumor segmentation from FLAIR images. Experimental results show our method achieves a large improvement from automatic CNNs and obtains comparable and even higher accuracy with fewer user interventions and less time compared with traditional interactive methods. DeepIGeoS: A Deep Interactive Geodesic Framework for Medical Image Segmentation.
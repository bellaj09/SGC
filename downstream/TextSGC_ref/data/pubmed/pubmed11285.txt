"Automatic food image recognition systems are alleviating the process of food-intake estimation and dietary assessment. However due to the nature of food images their recognition is a particularly challenging task which is why traditional approaches in the field have achieved a low classification accuracy. Deep neural networks have outperformed such solutions and we present a novel approach to the problem of food and drink image detection and recognition that uses a newly-defined deep convolutional neural network architecture called NutriNet. This architecture was tuned on a recognition dataset containing 225953 512  512 pixel images of 520 different food and drink items from a broad spectrum of food groups on which we achieved a classification accuracy of 86 . 72 %  along with an accuracy of 94 . 47 % on a detection dataset containing 130  517 images. We also performed a real-world test on a dataset of self-acquired images combined with images from Parkinsons disease patients all taken using a smartphone camera achieving a top-five accuracy of 55 %  which is an encouraging result for real-world images. Additionally we tested NutriNet on the University of Milano-Bicocca 2016 UNIMIB2016 food image dataset on which we improved upon the provided baseline recognition result. An online training component was implemented to continually fine-tune the food and drink recognition model on new images. The model is being used in practice as part of a mobile app for the dietary assessment of Parkinsons disease patients." NutriNet: A Deep Learning Food and Drink Image Recognition System for Dietary Assessment.
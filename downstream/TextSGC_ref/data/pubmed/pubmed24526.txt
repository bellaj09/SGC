Previous studies have shown that audiovisual integration improves identification performance and enhances neural activity in heteromodal brain areas for example the posterior superior temporal sulcus/middle temporal gyrus pSTS/MTG. Furthermore it has also been demonstrated that attention plays an important role in crossmodal integration. In this study we considered crossmodal integration in audiovisual facial perception and explored its effect on the neural representation of features. The audiovisual stimuli in the experiment consisted of facial movie clips that could be classified into 2 gender categories male vs. female or 2 emotion categories crying vs. laughing. The visual/auditory-only stimuli were created from these movie clips by removing the auditory/visual contents. The subjects needed to make a judgment about the gender/emotion category for each movie clip in the audiovisual visual-only or auditory-only stimulus condition as functional magnetic resonance imaging fMRI signals were recorded. The neural representation of the gender/emotion feature was assessed using the decoding accuracy and the brain pattern-related reproducibility indices obtained by a multivariate pattern analysis method from the fMRI data. In comparison to the visual-only and auditory-only stimulus conditions we found that audiovisual integration enhanced the neural representation of task-relevant features and that feature-selective attention might play a role of modulation in the audiovisual integration. Crossmodal integration enhances neural representation of task-relevant features in audiovisual face perception.
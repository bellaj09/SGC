In radiation therapy the accurate delineation of gross tumor volume GTV is crucial for treatment planning. However it is challenging for head and neck cancer HNC due to the morphology complexity of various organs in the head low targets to background contrast and potential artifacts on conventional planning CT images. Thus manual delineation of GTV on anatomical images is extremely time consuming and suffers from inter-observer variability that leads to planning uncertainty. With the wide use of PET/CT imaging in oncology complementary functional and anatomical information can be utilized for tumor contouring and bring a significant advantage for radiation therapy planning. In this study by taking advantage of multi-modality PET and CT images we propose an automatic GTV segmentation framework based on deep learning for HNC. The backbone of this segmentation framework is based on 3D convolution with dense connections which enables a better information propagation and takes full advantage of the features extracted from multi-modality input images. We evaluate our proposed framework on a dataset including 250 HNC patients. Each patient receives both planning CT and PET/CT imaging before radiation therapy RT. Manually delineated GTV contours by radiation oncologists are used as ground truth in this study. To further investigate the advantage of our proposed Dense-Net framework we also compared with the framework using 3D U-Net which is the state-of-the-art in segmentation tasks. Meanwhile for each frame the performance comparison between single modality input PET or CT image and multi-modality input both PET/CT is conducted. Dice coefficient mean surface distance MSD 95th-percentile Hausdorff distance HD95 and displacement of mass centroid DMC are calculated for quantitative evaluation. The dataset is split into train 140 patients validation 35 patients and test 75 patients groups to optimize the network. Based on the results on independent test group our proposed multi-modality Dense-Net Dice 0.73 shows better performance than the compared network Dice 0.71. Furthermore the proposed Dense-Net structure has less trainable parameters than the 3D U-Net which reduces the prediction variability. In conclusion our proposed multi-modality Dense-Net can enable satisfied GTV segmentation for HNC using multi-modality images and yield superior performance than conventional methods. Our proposed method provides an automatic fast and consistent solution for GTV segmentation and shows potentials to be generally applied for radiation therapy planning of a variety of cancer e.g. lung sarcoma liver and so on. Gross tumor volume segmentation for head and neck cancer radiotherapy using deep dense multi-modality network.
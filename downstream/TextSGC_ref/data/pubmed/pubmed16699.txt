Medical image analysis remains a challenging application area for artificial intelligence. When applying machine learning obtaining ground-truth labels for supervised learning is more difficult than in many more common applications of machine learning. This is especially so for datasets with abnormalities as tissue types and the shapes of the organs in these datasets differ widely. However organ detection in such an abnormal dataset may have many promising potential real-world applications such as automatic diagnosis automated radiotherapy planning and medical image retrieval where new multimodal medical images provide more information about the imaged tissues for diagnosis. Here we test the application of deep learning methods to organ identification in magnetic resonance medical images with visual and temporal hierarchical features learned to categorize object classes from an unlabeled multimodal DCE-MRI dataset so that only a weakly supervised training is required for a classifier. A probabilistic patch-based method was employed for multiple organ detection with the features learned from the deep learning model. This shows the potential of the deep learning model for application to medical images despite the difficulty of obtaining libraries of correctly labeled training datasets and despite the intrinsic abnormalities present in patient datasets. Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data.
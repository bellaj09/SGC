Accurate two-dimensional to three-dimensional 2-D/3-D registration of preoperative 3-D data and intraoperative 2-D x-ray images is a key enabler for image-guided therapy. Recent advances in 2-D/3-D registration formulate the problem as a learning-based approach and exploit the modeling power of convolutional neural networks CNN to significantly improve the accuracy and efficiency of 2-D/3-D registration. However for surgery-related applications collecting a large clinical dataset with accurate annotations for training can be very challenging or impractical. Therefore deep learning-based 2-D/3-D registration methods are often trained with synthetically generated data and a performance gap is often observed when testing the trained model on clinical data. We propose a pairwise domain adaptation PDA module to adapt the model trained on source domain i.e. synthetic data to target domain i.e. clinical data by learning domain invariant features with only a few paired real and synthetic data. The PDA module is designed to be flexible for different deep learning-based 2-D/3-D registration frameworks and it can be plugged into any pretrained CNN model such as a simple Batch-Norm layer. The proposed PDA module has been quantitatively evaluated on two clinical applications using different frameworks of deep networks demonstrating its significant advantages of generalizability and flexibility for 2-D/3-D medical image registration when a small number of paired real-synthetic data can be obtained. Pairwise domain adaptation module for CNN-based 2-D/3-D registration.
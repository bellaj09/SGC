"In recent years image databases are growing at exponential rates making their management indexing and retrieval very challenging. Typical image retrieval systems rely on sample images as queries. However in the absence of sample query images hand-drawn sketches are also used. The recent adoption of touch screen input devices makes it very convenient to quickly draw shaded sketches of objects to be used for querying image databases. This paper presents a mechanism to provide access to visual information based on users hand-drawn partially colored sketches using touch screen devices. A key challenge for sketch-based image retrieval systems is to cope with the inherent ambiguity in sketches due to the lack of colors textures shading and drawing imperfections. To cope with these issues we propose to fine-tune a deep convolutional neural network CNN using augmented dataset to extract features from partially colored hand-drawn sketches for query specification in a sketch-based image retrieval framework. The large augmented dataset contains natural images edge maps hand-drawn sketches de-colorized and de-texturized images which allow CNN to effectively model visual contents presented to it in a variety of forms. The deep features extracted from CNN allow retrieval of images using both sketches and full color images as queries. We also evaluated the role of partial coloring or shading in sketches to improve the retrieval performance. The proposed method is tested on two large datasets for sketch recognition and sketch-based image retrieval and achieved better classification and retrieval performance than many existing methods." Data augmentation-assisted deep learning of hand-drawn partially colored sketches for visual search.
"Ensuring correct radiograph view labeling is important for machine learning algorithm development and quality control of studies obtained from multiple facilities. The purpose of this study was to develop and test the performance of a deep convolutional neural network DCNN for the automated classification of frontal chest radiographs CXRs into anteroposterior AP or posteroanterior PA views. We obtained 112120 CXRs from the NIH ChestX-ray14 database a publicly available CXR database performed in adult 106179 95% and pediatric 5941 5% patients consisting of 44810 40% AP and 67310 60% PA views. CXRs were used to train validate and test the ResNet-18 DCNN for classification of radiographs into anteroposterior and posteroanterior views. A second DCNN was developed in the same manner using only the pediatric CXRs 2885 49% AP and 3056 51% PA. Receiver operating characteristic ROC curves with area under the curve AUC and standard diagnostic measures were used to evaluate the DCNNs performance on the test dataset. The DCNNs trained on the entire CXR dataset and pediatric CXR dataset had AUCs of 1.0 and 0.997 respectively and accuracy of 99.6% and 98% respectively for distinguishing between AP and PA CXR. Sensitivity and specificity were 99.6% and 99.5% respectively for the DCNN trained on the entire dataset and 98% for both sensitivity and specificity for the DCNN trained on the pediatric dataset. The observed difference in performance between the two algorithms was not statistically significant p\u2009=\u20090.17. Our DCNNs have high accuracy for classifying AP/PA orientation of frontal CXRs with only slight reduction in performance when the training dataset was reduced by 95%. Rapid classification of CXRs by the DCNN can facilitate annotation of large image datasets for machine learning and quality assurance purposes." Deep Learning Method for Automated Classification of Anteroposterior and Posteroanterior Chest Radiographs.
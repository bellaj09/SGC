While deep learning methods have demonstrated performance comparable to human readers in tasks such as computer-aided diagnosis these models are difficult to interpret do not incorporate prior domain knowledge and are often considered as a "black-box." The lack of model interpretability hinders them from being fully understood by end users such as radiologists. In this paper we present a novel interpretable deep hierarchical semantic convolutional neural network HSCNN to predict whether a given pulmonary nodule observed on a computed tomography CT scan is malignant. Our network provides two levels of output: 1 low-level semantic features; and 2 a high-level prediction of nodule malignancy. The low-level outputs reflect diagnostic features often reported by radiologists and serve to explain how the model interprets the images in an expert-interpretable manner. The information from these low-level outputs along with the representations learned by the convolutional layers are then combined and used to infer the high-level output. This unified architecture is trained by optimizing a global loss function including both low- and high-level tasks thereby learning all the parameters within a joint framework. Our experimental results using the Lung Image Database Consortium LIDC show that the proposed method not only produces interpretable lung cancer predictions but also achieves significantly better results compared to using a 3D CNN alone. An Interpretable Deep Hierarchical Semantic Convolutional Neural Network for Lung Nodule Malignancy Classification.
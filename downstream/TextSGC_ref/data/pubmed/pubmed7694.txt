Targeted prostate biopsy incorporating multi-parametric magnetic resonance imaging mp-MRI and its registration with ultrasound is currently the state-of-the-art in prostate cancer diagnosis. The registration process in most targeted biopsy systems today relies heavily on accurate segmentation of ultrasound images. Automatic or semi-automatic segmentation is typically performed offline prior to the start of the biopsy procedure. In this paper we present a deep neural network based real-time prostate segmentation technique during the biopsy procedure hence paving the way for dynamic registration of mp-MRI and ultrasound data. In addition to using convolutional networks for extracting spatial features the proposed approach employs recurrent networks to exploit the temporal information among a series of ultrasound images. One of the key contributions in the architecture is to use residual convolution in the recurrent networks to improve optimization. We also exploit recurrent connections within and across different layers of the deep networks to maximize the utilization of the temporal information. Furthermore we perform dense and sparse sampling of the input ultrasound sequence to make the network robust to ultrasound artifacts. Our architecture is trained on 2238 labeled transrectal ultrasound images with an additional 637 and 1017 unseen images used for validation and testing respectively. We obtain a mean Dice similarity coefficient of 93% a mean surface distance error of 1.10\xa0mm and a mean Hausdorff distance error of 3.0\xa0mm. A comparison of the reported results with those of a state-of-the-art technique indicates statistically significant improvement achieved by the proposed approach. A deep learning approach for real time prostate segmentation in freehand ultrasound guided biopsy.
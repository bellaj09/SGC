In-air signature is a new modality which is essential for user authentication and access control in noncontact mode and has been actively studied in recent years. However it has been treated as a conventional online signature which is essentially a 2D spatial representation. Notably this modality bears a lot more potential due to an important hidden depth feature. Existing methods for in-air signature verification neither capture this unique depth feature explicitly nor fully explore its potential in verification. Moreover these methods are based on heuristic approaches for fingertip or hand palm center detection which are not feasible in practice. Inspired by the great progress in deep-learning-based hand pose estimation we propose a real-time in-air signature acquisition method which estimates hand joint positions in 3D using a single depth image. The predicted 3D position of fingertip is recorded for each frame. We present four different implementations of a verification module which are based on the extracted depth and spatial features. An ablation study was performed to explore the impact of the depth feature in particular. For matching we employed the most commonly used multidimensional dynamic time warping MD-DTW algorithm. We created a new database which contains 600 signatures recorded from 15 different subjects. Extensive evaluations were performed on our database. Our method called 3DAirSig achieved an equal error rate EER of 0 . 46 %. Experiments showed that depth itself is an important feature which is sufficient for in-air signature verification. The dataset will be publicly available https://goo.gl/yFdfdL. 3DAirSig: A Framework for Enabling In-Air Signatures Using a Multi-Modal Depth Sensor.
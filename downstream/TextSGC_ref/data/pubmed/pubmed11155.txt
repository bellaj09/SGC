We present deep-learning-enabled super-resolution across different fluorescence microscopy modalities. This data-driven approach does not require numerical modeling of the imaging process or the estimation of a point-spread-function and is based on training a generative adversarial network GAN to transform diffraction-limited input images into super-resolved ones. Using this framework we improve the resolution of wide-field images acquired with low-numerical-aperture objectives matching the resolution that is acquired using high-numerical-aperture objectives. We also demonstrate cross-modality super-resolution transforming confocal microscopy images to match the resolution acquired with a stimulated emission depletion STED microscope. We further demonstrate that total internal reflection fluorescence TIRF microscopy images of subcellular structures within cells and tissues can be transformed to match the results obtained with a TIRF-based structured illumination microscope. The deep network rapidly outputs these super-resolved images without any iterations or parameter search and could serve to democratize super-resolution imaging. Deep learning enables cross-modality super-resolution in fluorescence microscopy.
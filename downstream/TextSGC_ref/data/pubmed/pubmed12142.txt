Domain adaptation is becoming increasingly important for learning systems in recent years especially with the growing diversification of data domains in real-world applications such as the genetic data from various sequencing platforms and video feeds from multiple surveillance cameras. Traditional domain adaptation approaches target to design transformations for each individual domain so that the twisted data from different domains follow an almost identical distribution. In many applications however the data from diversified domains are simply dumped to an archive even without clear domain labels. In this article we discuss the possibility of learning domain adaptations even when the data does not contain domain labels. Our solution is based on our new model named domain adaption using cross-domain homomorphism DACH in short to identify intrinsic homomorphism hidden in mixed data from all domains. DACH is generally compatible with existing deep learning frameworks enabling the generation of nonlinear features from the original data domains. Our theoretical analysis not only shows the universality of the homomorphism but also proves the convergence of DACH for significant homomorphism structures over the data domains is preserved. Empirical studies on real-world data sets validate the effectiveness of DACH on merging multiple data domains for joint machine learning tasks and the scalability of our algorithm to domain dimensionality. DACH: Domain Adaptation Without Domain Information.
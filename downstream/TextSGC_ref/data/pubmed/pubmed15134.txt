Clinical text de-identification enables collaborative research while protecting patient privacy and confidentiality; however concerns persist about the reduction in the utility of the de-identified text for information extraction and machine learning tasks. In the context of a deep learning experiment to detect altered mental status in emergency department provider notes we tested several classifiers on clinical notes in their original form and on their automatically de-identified counterpart. We tested both traditional bag-of-words based machine learning models as well as word-embedding based deep learning models. We evaluated the models on 1113 history of present illness notes. A total of 1795 protected health information tokens were replaced in the de-identification process across all notes. The deep learning models had the best performance with accuracies of 95% on both original and de-identified notes. However there was no significant difference in the performance of any of the models on the original vs. the de-identified notes. Impact of De-Identification on Clinical Text Classification Using Traditional and Deep Learning Classifiers.